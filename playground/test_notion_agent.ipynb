{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86796947-9143-4dba-839e-1678c7503550",
   "metadata": {},
   "source": [
    "# Test Notion Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa334fe-9310-4b79-907f-53d57c365b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82d229a-6f1b-4ee4-b30a-eeb6b865ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notion_agent import ChatBot\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f68a6d4-946e-4be5-9c0e-2b30d7189755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)\n",
    "\n",
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b4073d-426a-4314-859b-8f26b68cdf97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 259 tensors from /Users/fred/Documents/models/Qwen-7B-Chat.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen\n",
      "llama_model_loader: - kv   1:                               general.name str              = Qwen\n",
      "llama_model_loader: - kv   2:                        qwen.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                           qwen.block_count u32              = 32\n",
      "llama_model_loader: - kv   4:                      qwen.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                   qwen.feed_forward_length u32              = 22016\n",
      "llama_model_loader: - kv   6:                        qwen.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv   7:                  qwen.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                  qwen.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:      qwen.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  11:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  12:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  14:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  16:            tokenizer.ggml.unknown_token_id u32              = 151643\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q4_K:  113 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 293/151936 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 22016\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.72 B\n",
      "llm_load_print_meta: model size       = 4.56 GiB (5.07 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen\n",
      "llm_load_print_meta: BOS token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: EOS token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: UNK token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: LF token         = 148848 'ÄĬ'\n",
      "llm_load_tensors: ggml ctx size =    0.20 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4666.59 MiB, ( 4666.66 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4450.41 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4666.59 MiB\n",
      ".....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  2048.00 MiB, ( 6716.22 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  2048.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    80.04 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1248.02 MiB, ( 7964.23 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1248.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1251.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.ggml.unknown_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'qwen.attention.head_count': '32', 'qwen.rope.freq_base': '10000.000000', 'tokenizer.ggml.bos_token_id': '151643', 'qwen.feed_forward_length': '22016', 'qwen.attention.layer_norm_rms_epsilon': '0.000001', 'qwen.embedding_length': '4096', 'qwen.rope.dimension_count': '128', 'qwen.context_length': '32768', 'qwen.block_count': '32', 'general.name': 'Qwen', 'general.architecture': 'qwen'}\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+'Qwen-7B-Chat.Q4_K_M.gguf',\n",
    "    name='Qwen/Qwen-7B-Chat', \n",
    "    **_CONFIGS['llm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079268aa-2ea3-437f-8fdd-69ecefe02e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ChatBot(llm, _CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7935f03-1e47-49f7-a8fb-81698f19fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.invoke(\"你是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233d6bb-86cd-4696-8da7-90b0a985d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(_CONFIGS['attributes'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688be57-40b9-4f7f-8059-4f8afe7d68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([x['name'] for x in _CONFIGS['redis_schema']['text']] + [x['name'] for x in _CONFIGS['redis_schema']['numeric']]) == set(_CONFIGS['attributes'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28eeaed-728c-4fa9-9744-15b27ee71859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from notion_agent import SelfQueryAgent\n",
    "\n",
    "s = SelfQueryAgent(llm, _CONFIGS, _TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19a2e61-1677-4447-a7ae-a732c2afb0b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 4:prompt:FewShotPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 4:prompt:FewShotPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"Your goal is to structure the user's query to match the request schema provided below.\\n\\n\\n\\n<< Structured Request Schema >>\\n\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n\\n\\n```json\\n\\n{\\n\\n    \\\"query\\\": string \\\\ text string to compare to document contents\\n\\n    \\\"filter\\\": string \\\\ logical condition statement for filtering documents\\n\\n}\\n\\n```\\n\\n\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\n\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\n\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\n\\nMake sure that filters only use format `YYYYMMDD` when handling date data typed values.\\n\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\n\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \\\"NO_FILTER\\\" for the filter value.\\n\\nMake sure that filters only refer to attributes that exist in the data source. Available attributes: ['author', 'date_start', 'date_end', 'id', 'name', 'source', 'tags']. Don't make up other attributes.\\n\\n\\n\\n<<Data Source>>\\n\\n```json\\n\\n{\\n    \\\"content\\\": \\\"文章\\\",\\n    \\\"attributes\\\": {\\n        \\\"author\\\": {\\n            \\\"description\\\": \\\"本篇文章的作者\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"date_start\\\": {\\n            \\\"description\\\": \\\"文章被创建的时间，格式是YYYYMMDD\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"date_end\\\": {\\n            \\\"description\\\": \\\"文章被完成的时间，格式是YYYYMMDD\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"id\\\": {\\n            \\\"description\\\": \\\"文章的id\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"name\\\": {\\n            \\\"description\\\": \\\"文章的名字\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"source\\\": {\\n            \\\"description\\\": \\\"文章的来源，这里的文章取自若干不同数据库\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"tags\\\": {\\n            \\\"description\\\": \\\"文章的标签，可能代表它的风格、题材、来源，或者系列\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        }\\n    }\\n}\\n\\n```\\n\\n\\n<< Example 1. >>\\nUser Query:\\n谁是王尔德？仅从“小说”中找答案。\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"谁是王尔德？\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"小说\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nUser Query:\\n请从三岛由纪夫的小说找到下文相关片段：“我们之所以突然变得残暴”的后面是什么？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"我们之所以突然变得残暴\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"),  like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"三岛由纪夫\\\\\\\"), like(\\\\\\\"author\\\\\\\", \\\\\\\"三岛由纪夫\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nUser Query:\\n《天使与昆虫》是哪位作家的作品？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"天使与昆虫\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 4. >>\\nUser Query:\\n道连是哪本小说中出现的人物？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"道连\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"小说\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 5. >>\\nUser Query:\\n本多是王尔德笔下的人物吗？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"本多\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"王尔德\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"王尔德\\\\\\\")， like(\\\\\\\"name\\\\\\\", \\\\\\\"王尔德\\\\\\\"), like(\\\\\\\"author\\\\\\\", \\\\\\\"王尔德\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 6. >>\\nUser Query:\\n我在2019年到2022年间写过多少游记？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"游记\\\",\\n    \\\"filter\\\": \\\"and(eq(\\\\\\\"source\\\\\\\", \\\\\\\"写作\\\\\\\"), gt(\\\\\\\"date_start\\\\\\\", 20190101), lt(\\\\\\\"date_start\\\\\\\", 20221231))\\\"\\n}\\n```\\n\\n\\n<< Example 7. >>\\nUser Query:\\n美国有多少个州？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"\\\",\\n    \\\"filter\\\": \\\"NO_FILTER\\\"\\n}\\n```\\n\\n\\n<< Example 8. >>\\nUser Query:\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\nStructured Request:\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 5:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Your goal is to structure the user's query to match the request schema provided below.\\n\\n\\n\\n<< Structured Request Schema >>\\n\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n\\n\\n```json\\n\\n{\\n\\n    \\\"query\\\": string \\\\ text string to compare to document contents\\n\\n    \\\"filter\\\": string \\\\ logical condition statement for filtering documents\\n\\n}\\n\\n```\\n\\n\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\n\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\n\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\n\\nMake sure that filters only use format `YYYYMMDD` when handling date data typed values.\\n\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\n\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \\\"NO_FILTER\\\" for the filter value.\\n\\nMake sure that filters only refer to attributes that exist in the data source. Available attributes: ['author', 'date_start', 'date_end', 'id', 'name', 'source', 'tags']. Don't make up other attributes.\\n\\n\\n\\n<<Data Source>>\\n\\n```json\\n\\n{\\n    \\\"content\\\": \\\"文章\\\",\\n    \\\"attributes\\\": {\\n        \\\"author\\\": {\\n            \\\"description\\\": \\\"本篇文章的作者\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"date_start\\\": {\\n            \\\"description\\\": \\\"文章被创建的时间，格式是YYYYMMDD\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"date_end\\\": {\\n            \\\"description\\\": \\\"文章被完成的时间，格式是YYYYMMDD\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"id\\\": {\\n            \\\"description\\\": \\\"文章的id\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"name\\\": {\\n            \\\"description\\\": \\\"文章的名字\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"source\\\": {\\n            \\\"description\\\": \\\"文章的来源，这里的文章取自若干不同数据库\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"tags\\\": {\\n            \\\"description\\\": \\\"文章的标签，可能代表它的风格、题材、来源，或者系列\\\",\\n            \\\"type\\\": \\\"string\\\"\\n        }\\n    }\\n}\\n\\n```\\n\\n\\n<< Example 1. >>\\nUser Query:\\n谁是王尔德？仅从“小说”中找答案。\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"谁是王尔德？\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"小说\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nUser Query:\\n请从三岛由纪夫的小说找到下文相关片段：“我们之所以突然变得残暴”的后面是什么？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"我们之所以突然变得残暴\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"),  like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"三岛由纪夫\\\\\\\"), like(\\\\\\\"author\\\\\\\", \\\\\\\"三岛由纪夫\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nUser Query:\\n《天使与昆虫》是哪位作家的作品？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"天使与昆虫\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"天使与昆虫\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 4. >>\\nUser Query:\\n道连是哪本小说中出现的人物？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"道连\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"小说\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"小说\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 5. >>\\nUser Query:\\n本多是王尔德笔下的人物吗？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"本多\\\",\\n    \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"王尔德\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"王尔德\\\\\\\")， like(\\\\\\\"name\\\\\\\", \\\\\\\"王尔德\\\\\\\"), like(\\\\\\\"author\\\\\\\", \\\\\\\"王尔德\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 6. >>\\nUser Query:\\n我在2019年到2022年间写过多少游记？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"游记\\\",\\n    \\\"filter\\\": \\\"and(eq(\\\\\\\"source\\\\\\\", \\\\\\\"写作\\\\\\\"), gt(\\\\\\\"date_start\\\\\\\", 20190101), lt(\\\\\\\"date_start\\\\\\\", 20221231))\\\"\\n}\\n```\\n\\n\\n<< Example 7. >>\\nUser Query:\\n美国有多少个州？\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"\\\",\\n    \\\"filter\\\": \\\"NO_FILTER\\\"\\n}\\n```\\n\\n\\n<< Example 8. >>\\nUser Query:\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\nStructured Request:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8673.91 ms\n",
      "llama_print_timings:      sample time =      93.09 ms /   256 runs   (    0.36 ms per token,  2749.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8672.29 ms /  1147 tokens (    7.56 ms per token,   132.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13514.22 ms /   255 runs   (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:       total time =   23946.50 ms /  1402 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 5:llm:LlamaCpp] [23.96s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{  \\n     \\\"query\\\": \\\"请告诉四姐妹\\\",  \\n     \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"诗\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"诗\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"诗\\\\\\\"))\\\"  \\n}\\n```[PAD151645]\\n[PAD151644]'t be able to solve this[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 6:parser:StructuredQueryOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"```json\\n{  \\n     \\\"query\\\": \\\"请告诉四姐妹\\\",  \\n     \\\"filter\\\": \\\"or(like(\\\\\\\"source\\\\\\\", \\\\\\\"诗\\\\\\\"), like(\\\\\\\"tags\\\\\\\", \\\\\\\"诗\\\\\\\"), like(\\\\\\\"name\\\\\\\", \\\\\\\"诗\\\\\\\"))\\\"  \\n}\\n```[PAD151645]\\n[PAD151644]'t be able to solve this[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence > 6:parser:StructuredQueryOutputParser] [60ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"not_implemented\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"chains\",\n",
      "    \"query_constructor\",\n",
      "    \"ir\",\n",
      "    \"StructuredQuery\"\n",
      "  ],\n",
      "  \"repr\": \"StructuredQuery(query='请告诉四姐妹', filter=Operation(operator=<Operator.OR: 'or'>, arguments=[Comparison(comparator=<Comparator.LIKE: 'like'>, attribute='source', value='诗'), Comparison(comparator=<Comparator.LIKE: 'like'>, attribute='tags', value='诗'), Comparison(comparator=<Comparator.LIKE: 'like'>, attribute='name', value='诗')]), limit=None)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:retriever:Retriever > 3:chain:RunnableSequence] [24.04s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 7:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\",\n",
      "  \"context\": \"《四姐妹》\\n\\n荒凉的山冈上站着四姐妹\\n所有的风只向她们吹\\n所有的日子都为她们破碎\\n\\n空气中的一棵麦子\\n高举到我的头顶\\n我身在这荒凉的山冈\\n怀念我空空的房间，落满灰尘\\n\\n我爱过的这糊涂的四姐妹啊\\n光芒四射的四姐妹\\n夜里我头枕卷册和神州\\n想起蓝色远方的四姐妹\\n我爱过的这糊涂的四姐妹啊\\n像爱着我亲手写下的四首诗\\n我的美丽的结伴而行的四姐妹\\n比命运女神还要多出一个\\n赶着美丽苍白的奶牛 走向月亮形的山峰\\n\\n到了二月，你是从哪里来的\\n天上滚过春天的雷，你是从哪里来的\\n不和陌生人一起来\\n不和运货马车一起来\\n不和鸟群一起来\\n\\n四姐妹抱着这一棵\\n一棵空气中的麦子\\n抱着昨天的大雪，今天的雨水\\n明日的粮食与灰烬\\n这是绝望的麦子\\n\\n请告诉四姐妹：这是绝望的麦子\\n永远是这样\\n风后面是风\\n天空上面是天空\\n道路前面还是道路。\\n\\n\\n《面朝大海，春暖花开》\\n\\n从明天起，做一个幸福的人\\n喂马、劈柴，周游世界\\n从明天起，关心粮食和蔬菜\\n我有一所房子，面朝大海，春暖花开\\n\\n从明天起，和每一个亲人通信\\n告诉他们我的幸福\\n那幸福的闪电告诉我的\\n我将告诉每一个人\\n\\n给每一条河每一座山取一个温暖的名字\\n陌生人，我也为你祝福\\n愿你有一个灿烂的前程\\n愿你有情人终成眷属\\n愿你在尘世获得幸福\\n我只愿面朝大海，春暖花开\\n\\n\\n《日光》\\n\\n梨花\\n在土墙上滑动\\n牛铎声声\\n大婶拉过两位小堂弟\\n站在我面前\\n像两截黑炭\\n\\n日光其实很强\\n一种万物生长的鞭子和血！\\n\\n\\n《思念前生》\\n\\n庄子在水中洗手\\n洗完了手, 手掌上一片寂静\\n庄子在水中洗身\\n身子是一匹布\\n那布上粘满了\\n水面上漂来漂去的声音\\n\\n庄子想混入\\n凝望月亮的野兽\\n骨头一寸一寸\\n在肚脐上下\\n象树枝一样长着\\n\\n也许庄子就是我\\n摸一摸树皮\\n开始对自己的身子\\n亲切\\n亲切又苦恼\\n月亮触到我\\n仿佛我是光着身子\\n光着身子\\n进出\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 7:chain:LLMChain > 8:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给定以下问题和资料，如果资料与问题相关，请回答“是”；如果资料与问题不相关，则回答“否”。请依据事实逐步推理并给出确切理由。\\n\\n\\n\\n<< 例1 >>\\n\\n\\n\\n问题：\\n\\n中华人民共和国成立时间是？\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。资料是关于孔子的，孔子与中华人民共和国的成立时间无关。\\n\\n\\n\\n\\n\\n<< 例2 >>\\n\\n\\n\\n问题：\\n\\n李白和杜甫相识吗？\\n\\n\\n\\n资料:\\n\\n李白创作了许多著名的诗歌。他的诗歌展现了李白丰富的想象力、豪放的情感和对自然的热爱，被后人广泛传颂。\\n\\n\\n\\n相关：是。问题是关于李白的，资料虽然没有提到李白和杜甫的关系，但和李白相关。\\n\\n\\n\\n\\n\\n<< 例3 >>\\n\\n\\n\\n问题：\\n\\n诺贝尔文学奖的评选标准是什么。\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。问题是关于诺贝尔文学奖的，诺贝尔文学奖和孔子无关。\\n\\n\\n\\n<< 例4 >>\\n\\n\\n\\n问题：\\n\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\n\\n\\n资料:\\n\\n《四姐妹》\\n\\n荒凉的山冈上站着四姐妹\\n所有的风只向她们吹\\n所有的日子都为她们破碎\\n\\n空气中的一棵麦子\\n高举到我的头顶\\n我身在这荒凉的山冈\\n怀念我空空的房间，落满灰尘\\n\\n我爱过的这糊涂的四姐妹啊\\n光芒四射的四姐妹\\n夜里我头枕卷册和神州\\n想起蓝色远方的四姐妹\\n我爱过的这糊涂的四姐妹啊\\n像爱着我亲手写下的四首诗\\n我的美丽的结伴而行的四姐妹\\n比命运女神还要多出一个\\n赶着美丽苍白的奶牛 走向月亮形的山峰\\n\\n到了二月，你是从哪里来的\\n天上滚过春天的雷，你是从哪里来的\\n不和陌生人一起来\\n不和运货马车一起来\\n不和鸟群一起来\\n\\n四姐妹抱着这一棵\\n一棵空气中的麦子\\n抱着昨天的大雪，今天的雨水\\n明日的粮食与灰烬\\n这是绝望的麦子\\n\\n请告诉四姐妹：这是绝望的麦子\\n永远是这样\\n风后面是风\\n天空上面是天空\\n道路前面还是道路。\\n\\n\\n《面朝大海，春暖花开》\\n\\n从明天起，做一个幸福的人\\n喂马、劈柴，周游世界\\n从明天起，关心粮食和蔬菜\\n我有一所房子，面朝大海，春暖花开\\n\\n从明天起，和每一个亲人通信\\n告诉他们我的幸福\\n那幸福的闪电告诉我的\\n我将告诉每一个人\\n\\n给每一条河每一座山取一个温暖的名字\\n陌生人，我也为你祝福\\n愿你有一个灿烂的前程\\n愿你有情人终成眷属\\n愿你在尘世获得幸福\\n我只愿面朝大海，春暖花开\\n\\n\\n《日光》\\n\\n梨花\\n在土墙上滑动\\n牛铎声声\\n大婶拉过两位小堂弟\\n站在我面前\\n像两截黑炭\\n\\n日光其实很强\\n一种万物生长的鞭子和血！\\n\\n\\n《思念前生》\\n\\n庄子在水中洗手\\n洗完了手, 手掌上一片寂静\\n庄子在水中洗身\\n身子是一匹布\\n那布上粘满了\\n水面上漂来漂去的声音\\n\\n庄子想混入\\n凝望月亮的野兽\\n骨头一寸一寸\\n在肚脐上下\\n象树枝一样长着\\n\\n也许庄子就是我\\n摸一摸树皮\\n开始对自己的身子\\n亲切\\n亲切又苦恼\\n月亮触到我\\n仿佛我是光着身子\\n光着身子\\n进出\\n\\n\\n\\n相关：\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8673.91 ms\n",
      "llama_print_timings:      sample time =      92.06 ms /   256 runs   (    0.36 ms per token,  2780.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5042.62 ms /   870 tokens (    5.80 ms per token,   172.53 tokens per second)\n",
      "llama_print_timings:        eval time =   12438.36 ms /   255 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:       total time =   19120.64 ms /  1125 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 7:chain:LLMChain > 8:llm:LlamaCpp] [19.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"否。资料是关于《四姐妹》的，问题是关于《面朝大海，春暖花开》的，资料与问题无关。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 7:chain:LLMChain] [19.16s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"否。资料是关于《四姐妹》的，问题是关于《面朝大海，春暖花开》的，资料与问题无关。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 9:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\",\n",
      "  \"context\": \"瓦多④，狂欢节许多卓越的心灵，\\n蝴蝶一般到外游荡，闪闪发光，\\n灯人照亮了新鲜轻盈的布景，\\n使这旋风般的舞会如癫如狂；\\n\\n戈雅⑤，充满着未知之物的噩梦，\\n巫魔夜会中人们把胎儿烹煮，\\n揽镜自照的老妇，赤裸的儿童，\\n好让魔鬼们理好它们的袜子；\\n\\n血湖里恶煞出没，德拉克洛瓦⑥，\\n周围有四季长青的松林遮蔽，\\n奇怪的号声在忧愁的天空下\\n飘过，仿佛韦伯被压抑的叹息；\\n\\n这些诅咒，这些谴责，这些抱怨，\\n往复回荡在千百座迷宫中间，\\n如神圣的鸦片给了凡夫俗子；\\n\\n这是千百个哨兵重复的呐喊，\\n是千百个喊话筒传递的命令，\\n是灯塔在千百座城堡上点燃，\\n是密林中迷路的猎人的呼应；\\n\\n上帝，这确是我们所能给予的\\n关于我们的尊严的最好证明，\\n这是代代相传的热切的哭泣，\\n它刚消逝在悠悠永恒的边境！\\n\\n【注】\\n①鲁本斯（1577～1640），佛兰德斯画家。\\n②达·芬奇（1452～1519），意大利画家。\\n①米开朗琪罗（1475～1564），意大利雕塑家。\\n②即潘神，司山林畜牧，性喜嬉戏\\n\\n\\n一个幽灵（节选）\\n\\n像我一样在孤独中死去，\\n而时间，这不公正的老头，\\n每天都在用硬硬的翅擦拭……\\n生命，艺术的阴险的凶手，\\n你不能在记忆中杀死她，\\n她曾是我的快乐和荣华！\\n永远如此\\n您曾问：“您哪来的这奇特的愁，\\n好像潮水涌上黑而光的岩石？”\\n——当我们的心收过了葡萄之后，\\n生活就是痛苦了。皆知的秘密，\\n一种单纯而并不神秘的痛苦，\\n就像您的快乐，谁都看得明白。\\n那就别追问了，哦好奇的美女！\\n尽管您声音温柔，也别把嘴张开！\\n住嘴！无知者！总是快乐的灵魂！\\n嘴上尽是幼稚的笑！死亡比生命\\n常用更精细的锁链栓住我们。\\n让我的、让我的心陶醉于虚幻，\\n像沉入美丽的梦沉入你的眼，\\n并长久地沉睡，遮着您的睫阴！\\n猫头鹰\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 9:chain:LLMChain > 10:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给定以下问题和资料，如果资料与问题相关，请回答“是”；如果资料与问题不相关，则回答“否”。请依据事实逐步推理并给出确切理由。\\n\\n\\n\\n<< 例1 >>\\n\\n\\n\\n问题：\\n\\n中华人民共和国成立时间是？\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。资料是关于孔子的，孔子与中华人民共和国的成立时间无关。\\n\\n\\n\\n\\n\\n<< 例2 >>\\n\\n\\n\\n问题：\\n\\n李白和杜甫相识吗？\\n\\n\\n\\n资料:\\n\\n李白创作了许多著名的诗歌。他的诗歌展现了李白丰富的想象力、豪放的情感和对自然的热爱，被后人广泛传颂。\\n\\n\\n\\n相关：是。问题是关于李白的，资料虽然没有提到李白和杜甫的关系，但和李白相关。\\n\\n\\n\\n\\n\\n<< 例3 >>\\n\\n\\n\\n问题：\\n\\n诺贝尔文学奖的评选标准是什么。\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。问题是关于诺贝尔文学奖的，诺贝尔文学奖和孔子无关。\\n\\n\\n\\n<< 例4 >>\\n\\n\\n\\n问题：\\n\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\n\\n\\n资料:\\n\\n瓦多④，狂欢节许多卓越的心灵，\\n蝴蝶一般到外游荡，闪闪发光，\\n灯人照亮了新鲜轻盈的布景，\\n使这旋风般的舞会如癫如狂；\\n\\n戈雅⑤，充满着未知之物的噩梦，\\n巫魔夜会中人们把胎儿烹煮，\\n揽镜自照的老妇，赤裸的儿童，\\n好让魔鬼们理好它们的袜子；\\n\\n血湖里恶煞出没，德拉克洛瓦⑥，\\n周围有四季长青的松林遮蔽，\\n奇怪的号声在忧愁的天空下\\n飘过，仿佛韦伯被压抑的叹息；\\n\\n这些诅咒，这些谴责，这些抱怨，\\n往复回荡在千百座迷宫中间，\\n如神圣的鸦片给了凡夫俗子；\\n\\n这是千百个哨兵重复的呐喊，\\n是千百个喊话筒传递的命令，\\n是灯塔在千百座城堡上点燃，\\n是密林中迷路的猎人的呼应；\\n\\n上帝，这确是我们所能给予的\\n关于我们的尊严的最好证明，\\n这是代代相传的热切的哭泣，\\n它刚消逝在悠悠永恒的边境！\\n\\n【注】\\n①鲁本斯（1577～1640），佛兰德斯画家。\\n②达·芬奇（1452～1519），意大利画家。\\n①米开朗琪罗（1475～1564），意大利雕塑家。\\n②即潘神，司山林畜牧，性喜嬉戏\\n\\n\\n一个幽灵（节选）\\n\\n像我一样在孤独中死去，\\n而时间，这不公正的老头，\\n每天都在用硬硬的翅擦拭……\\n生命，艺术的阴险的凶手，\\n你不能在记忆中杀死她，\\n她曾是我的快乐和荣华！\\n永远如此\\n您曾问：“您哪来的这奇特的愁，\\n好像潮水涌上黑而光的岩石？”\\n——当我们的心收过了葡萄之后，\\n生活就是痛苦了。皆知的秘密，\\n一种单纯而并不神秘的痛苦，\\n就像您的快乐，谁都看得明白。\\n那就别追问了，哦好奇的美女！\\n尽管您声音温柔，也别把嘴张开！\\n住嘴！无知者！总是快乐的灵魂！\\n嘴上尽是幼稚的笑！死亡比生命\\n常用更精细的锁链栓住我们。\\n让我的、让我的心陶醉于虚幻，\\n像沉入美丽的梦沉入你的眼，\\n并长久地沉睡，遮着您的睫阴！\\n猫头鹰\\n\\n\\n\\n相关：\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8673.91 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    31 runs   (    0.37 ms per token,  2680.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3422.39 ms /   594 tokens (    5.76 ms per token,   173.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1275.61 ms /    30 runs   (   42.52 ms per token,    23.52 tokens per second)\n",
      "llama_print_timings:       total time =    4909.46 ms /   624 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 9:chain:LLMChain > 10:llm:LlamaCpp] [4.92s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"是。资料是关于诗歌的，问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌。[PAD151645]\\n[PAD151644]'test\\n\\n\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 9:chain:LLMChain] [4.92s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"是。资料是关于诗歌的，问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌。[PAD151645]\\n[PAD151644]'test\\n\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 11:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\",\n",
      "  \"context\": \"天上序曲\\n\\n\\np4\\n人在奋斗时，难免迷误。\\n善人虽受模糊的冲动驱使，\\n总会意识到正确的道路。\\n\\n\\n悲剧第一部\\n\\n第一场 夜\\n\\np11 浮士德\\n你们所说的时代精神，\\n其实乃是著者自己的精神，\\n其中反映着时代的事件。\\n\\n\\n第四场 书斋\\n\\np53 浮士德\\n如果我对某一瞬间说：\\n停一停吧！你真美丽！\\n那时就给我套上枷锁，\\n那时我也情愿毁灭！\\n我一停滞，就变成奴隶\\n\\n\\np55 浮士德\\n听着！问题并不在于快乐。\\n我要献身于沉醉、最痛苦的欢快、\\n迷恋的憎恨、令人爽适的愤慨。\\n我的心胸，求知欲已告熄灭，\\n今后对任何痛苦都视若等闲，\\n凡是赋予全体人类的一切，\\n我要在我内心里自我体验，\\n用这种精神掌握高深的至理，\\n把幸与不幸堆积在我心里，\\n将我的小我扩充为人类的大我，\\n最后我也像人类一样没落。\\n\\n\\np57\\n浮士德：\\n我一心一意，无非是争取戴上\\n人类的冠冕，如不可能，\\n那还成个什么样的人？\\n梅菲斯特 最后你还是——像现在这样。\\n你带几百万根发丝编成的假发，\\n把底厚几尺的高靴垫在脚下，\\n你还是永远像现在这样。\\n\\n浮士德：\\n我把人类精神的一切财富\\n徒然集于一身，我也知详，\\n而到最后，瞧我坐在此处，\\n内心却涌现不出新的力量；\\n我自己并未提高一分，\\n跟无限无量也毫未接近。\\n\\n梅菲斯特：\\n我的好先生，你的意见\\n跟一般见解并无差异。\\n在生的欢乐消逝以前，\\n我们务须聪明行事。\\n见鬼！当然，双足双手，\\n头和屁……（注：屁股），都是你的；\\n可是，我的新的享受，\\n就可因此说不是我的？\\n我若付得出六匹马的价格，\\n它们的脚力不就是我的？\\n我骑着奔驰，岂不就像一个\\n有二十四条腿的豪客？\\n打起精神！丢开顾虑，\\n一同冲向人世间去！\\n我对你讲：一个人只顾沉思，\\n就像个牲口，在荒野地上\\n被一个恶灵牵着，来回乱兜圈子，\\n不知外围有美丽青葱的牧场。\\n\\n\\np59 梅菲斯特\\n让你去蔑视理性、知识，\\n人类拥有的最高的实力，\\n让你沉迷于魔术幻术，\\n获得诳骗精灵的鼓舞，\\n我不用契约已将你驾驭——\\n命运已经赋予他一种精力，\\n永远向前直闯，不受约束，\\n这种过分轻率的努力\\n跳越过尘世的欢乐情趣。\\n我要拖住他过浪荡生活，\\n经历平凡的无聊事件，\\n让他挣扎、发呆、粘着，\\n再对付他的贪得无厌，\\n拿酒食对着他的贪婪的口唇晃摇；\\n他哀求疗愈饥渴，也是无益，\\n这样，即使他没向一个恶魔卖身投靠，\\n他也一定要归于毁灭！\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 11:chain:LLMChain > 12:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给定以下问题和资料，如果资料与问题相关，请回答“是”；如果资料与问题不相关，则回答“否”。请依据事实逐步推理并给出确切理由。\\n\\n\\n\\n<< 例1 >>\\n\\n\\n\\n问题：\\n\\n中华人民共和国成立时间是？\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。资料是关于孔子的，孔子与中华人民共和国的成立时间无关。\\n\\n\\n\\n\\n\\n<< 例2 >>\\n\\n\\n\\n问题：\\n\\n李白和杜甫相识吗？\\n\\n\\n\\n资料:\\n\\n李白创作了许多著名的诗歌。他的诗歌展现了李白丰富的想象力、豪放的情感和对自然的热爱，被后人广泛传颂。\\n\\n\\n\\n相关：是。问题是关于李白的，资料虽然没有提到李白和杜甫的关系，但和李白相关。\\n\\n\\n\\n\\n\\n<< 例3 >>\\n\\n\\n\\n问题：\\n\\n诺贝尔文学奖的评选标准是什么。\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。问题是关于诺贝尔文学奖的，诺贝尔文学奖和孔子无关。\\n\\n\\n\\n<< 例4 >>\\n\\n\\n\\n问题：\\n\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\n\\n\\n资料:\\n\\n天上序曲\\n\\n\\np4\\n人在奋斗时，难免迷误。\\n善人虽受模糊的冲动驱使，\\n总会意识到正确的道路。\\n\\n\\n悲剧第一部\\n\\n第一场 夜\\n\\np11 浮士德\\n你们所说的时代精神，\\n其实乃是著者自己的精神，\\n其中反映着时代的事件。\\n\\n\\n第四场 书斋\\n\\np53 浮士德\\n如果我对某一瞬间说：\\n停一停吧！你真美丽！\\n那时就给我套上枷锁，\\n那时我也情愿毁灭！\\n我一停滞，就变成奴隶\\n\\n\\np55 浮士德\\n听着！问题并不在于快乐。\\n我要献身于沉醉、最痛苦的欢快、\\n迷恋的憎恨、令人爽适的愤慨。\\n我的心胸，求知欲已告熄灭，\\n今后对任何痛苦都视若等闲，\\n凡是赋予全体人类的一切，\\n我要在我内心里自我体验，\\n用这种精神掌握高深的至理，\\n把幸与不幸堆积在我心里，\\n将我的小我扩充为人类的大我，\\n最后我也像人类一样没落。\\n\\n\\np57\\n浮士德：\\n我一心一意，无非是争取戴上\\n人类的冠冕，如不可能，\\n那还成个什么样的人？\\n梅菲斯特 最后你还是——像现在这样。\\n你带几百万根发丝编成的假发，\\n把底厚几尺的高靴垫在脚下，\\n你还是永远像现在这样。\\n\\n浮士德：\\n我把人类精神的一切财富\\n徒然集于一身，我也知详，\\n而到最后，瞧我坐在此处，\\n内心却涌现不出新的力量；\\n我自己并未提高一分，\\n跟无限无量也毫未接近。\\n\\n梅菲斯特：\\n我的好先生，你的意见\\n跟一般见解并无差异。\\n在生的欢乐消逝以前，\\n我们务须聪明行事。\\n见鬼！当然，双足双手，\\n头和屁……（注：屁股），都是你的；\\n可是，我的新的享受，\\n就可因此说不是我的？\\n我若付得出六匹马的价格，\\n它们的脚力不就是我的？\\n我骑着奔驰，岂不就像一个\\n有二十四条腿的豪客？\\n打起精神！丢开顾虑，\\n一同冲向人世间去！\\n我对你讲：一个人只顾沉思，\\n就像个牲口，在荒野地上\\n被一个恶灵牵着，来回乱兜圈子，\\n不知外围有美丽青葱的牧场。\\n\\n\\np59 梅菲斯特\\n让你去蔑视理性、知识，\\n人类拥有的最高的实力，\\n让你沉迷于魔术幻术，\\n获得诳骗精灵的鼓舞，\\n我不用契约已将你驾驭——\\n命运已经赋予他一种精力，\\n永远向前直闯，不受约束，\\n这种过分轻率的努力\\n跳越过尘世的欢乐情趣。\\n我要拖住他过浪荡生活，\\n经历平凡的无聊事件，\\n让他挣扎、发呆、粘着，\\n再对付他的贪得无厌，\\n拿酒食对着他的贪婪的口唇晃摇；\\n他哀求疗愈饥渴，也是无益，\\n这样，即使他没向一个恶魔卖身投靠，\\n他也一定要归于毁灭！\\n\\n\\n\\n相关：\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8673.91 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    33 runs   (    0.38 ms per token,  2640.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4264.32 ms /   731 tokens (    5.83 ms per token,   171.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1519.45 ms /    32 runs   (   47.48 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:       total time =    6019.97 ms /   763 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 11:chain:LLMChain > 12:llm:LlamaCpp] [6.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"是。问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌《浮士德》。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 11:chain:LLMChain] [6.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"是。问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌《浮士德》。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 13:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\",\n",
      "  \"context\": \"（一）\\n沉默注入后\\n水位逐渐升高\\n作为降低触礁风险的代价滑入\\n情绪的深海区\\n\\n（二）\\n即使以混沌示人\\n时序图中仍然有K线滋长\\n\\n（三）\\n存活是个恶劣的字眼！\\n拥有美德的因它放弃矜持\\n不知廉耻的变得更加猥琐\\n\\n（四）\\n唯当事情变得无趣起来\\n我的眼神剔透得愈发真诚\\n以直报怨\\n以怨报仇\\n下狗就该有下狗的生存方式\\n\\n（五）\\n第一次复活让我在早晨沉沉睡去\\n第二次复活理应让我在夜晚早早醒来\\n\\n（六）\\n行动是一种作恶但\\n行动也是一种净罪\\n不行动就什么也不算\\n贪婪让我们对共价键\\n心生敌意\\n\\n（七）\\n到处都在地震\\n但仔细想来\\n却并没有什么值得引发地震\\n\\n（八）\\n午后精心修剪的草坪上\\n有着被拦腰截断的生命\\n特有的馨香\\n\\n（九）\\n我对你的忠诚到底算是\\n因信仰引发的奇迹还是\\n因奇迹引发的信仰\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 13:chain:LLMChain > 14:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给定以下问题和资料，如果资料与问题相关，请回答“是”；如果资料与问题不相关，则回答“否”。请依据事实逐步推理并给出确切理由。\\n\\n\\n\\n<< 例1 >>\\n\\n\\n\\n问题：\\n\\n中华人民共和国成立时间是？\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。资料是关于孔子的，孔子与中华人民共和国的成立时间无关。\\n\\n\\n\\n\\n\\n<< 例2 >>\\n\\n\\n\\n问题：\\n\\n李白和杜甫相识吗？\\n\\n\\n\\n资料:\\n\\n李白创作了许多著名的诗歌。他的诗歌展现了李白丰富的想象力、豪放的情感和对自然的热爱，被后人广泛传颂。\\n\\n\\n\\n相关：是。问题是关于李白的，资料虽然没有提到李白和杜甫的关系，但和李白相关。\\n\\n\\n\\n\\n\\n<< 例3 >>\\n\\n\\n\\n问题：\\n\\n诺贝尔文学奖的评选标准是什么。\\n\\n\\n\\n资料:\\n\\n孔子是中国古代伟大的思想家、教育家和哲学家，他是儒家学派的创始人，被尊称为\\\"大成至圣先师\\\"。\\n\\n\\n\\n相关：否。问题是关于诺贝尔文学奖的，诺贝尔文学奖和孔子无关。\\n\\n\\n\\n<< 例4 >>\\n\\n\\n\\n问题：\\n\\n“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\\n\\n\\n\\n资料:\\n\\n（一）\\n沉默注入后\\n水位逐渐升高\\n作为降低触礁风险的代价滑入\\n情绪的深海区\\n\\n（二）\\n即使以混沌示人\\n时序图中仍然有K线滋长\\n\\n（三）\\n存活是个恶劣的字眼！\\n拥有美德的因它放弃矜持\\n不知廉耻的变得更加猥琐\\n\\n（四）\\n唯当事情变得无趣起来\\n我的眼神剔透得愈发真诚\\n以直报怨\\n以怨报仇\\n下狗就该有下狗的生存方式\\n\\n（五）\\n第一次复活让我在早晨沉沉睡去\\n第二次复活理应让我在夜晚早早醒来\\n\\n（六）\\n行动是一种作恶但\\n行动也是一种净罪\\n不行动就什么也不算\\n贪婪让我们对共价键\\n心生敌意\\n\\n（七）\\n到处都在地震\\n但仔细想来\\n却并没有什么值得引发地震\\n\\n（八）\\n午后精心修剪的草坪上\\n有着被拦腰截断的生命\\n特有的馨香\\n\\n（九）\\n我对你的忠诚到底算是\\n因信仰引发的奇迹还是\\n因奇迹引发的信仰\\n\\n\\n\\n相关：\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8673.91 ms\n",
      "llama_print_timings:      sample time =      96.00 ms /   256 runs   (    0.37 ms per token,  2666.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.81 ms /   255 tokens (    7.04 ms per token,   142.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10431.90 ms /   255 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   13851.03 ms /   510 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 13:chain:LLMChain > 14:llm:LlamaCpp] [13.86s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"是。问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 13:chain:LLMChain] [13.86s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"是。问题是关于“请告诉四姐妹”的，资料中提到了这首诗歌。[PAD151645]\\n[PAD151644]'test[PAD151645]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\\n[PAD151644]\"\n",
      "}\n",
      "CPU times: user 44.2 s, sys: 8.28 s, total: 52.4 s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='瓦多④，狂欢节许多卓越的心灵，\\n蝴蝶一般到外游荡，闪闪发光，\\n灯人照亮了新鲜轻盈的布景，\\n使这旋风般的舞会如癫如狂；\\n\\n戈雅⑤，充满着未知之物的噩梦，\\n巫魔夜会中人们把胎儿烹煮，\\n揽镜自照的老妇，赤裸的儿童，\\n好让魔鬼们理好它们的袜子；\\n\\n血湖里恶煞出没，德拉克洛瓦⑥，\\n周围有四季长青的松林遮蔽，\\n奇怪的号声在忧愁的天空下\\n飘过，仿佛韦伯被压抑的叹息；\\n\\n这些诅咒，这些谴责，这些抱怨，\\n往复回荡在千百座迷宫中间，\\n如神圣的鸦片给了凡夫俗子；\\n\\n这是千百个哨兵重复的呐喊，\\n是千百个喊话筒传递的命令，\\n是灯塔在千百座城堡上点燃，\\n是密林中迷路的猎人的呼应；\\n\\n上帝，这确是我们所能给予的\\n关于我们的尊严的最好证明，\\n这是代代相传的热切的哭泣，\\n它刚消逝在悠悠永恒的边境！\\n\\n【注】\\n①鲁本斯（1577～1640），佛兰德斯画家。\\n②达·芬奇（1452～1519），意大利画家。\\n①米开朗琪罗（1475～1564），意大利雕塑家。\\n②即潘神，司山林畜牧，性喜嬉戏\\n\\n\\n一个幽灵（节选）\\n\\n像我一样在孤独中死去，\\n而时间，这不公正的老头，\\n每天都在用硬硬的翅擦拭……\\n生命，艺术的阴险的凶手，\\n你不能在记忆中杀死她，\\n她曾是我的快乐和荣华！\\n永远如此\\n您曾问：“您哪来的这奇特的愁，\\n好像潮水涌上黑而光的岩石？”\\n——当我们的心收过了葡萄之后，\\n生活就是痛苦了。皆知的秘密，\\n一种单纯而并不神秘的痛苦，\\n就像您的快乐，谁都看得明白。\\n那就别追问了，哦好奇的美女！\\n尽管您声音温柔，也别把嘴张开！\\n住嘴！无知者！总是快乐的灵魂！\\n嘴上尽是幼稚的笑！死亡比生命\\n常用更精细的锁链栓住我们。\\n让我的、让我的心陶醉于虚幻，\\n像沉入美丽的梦沉入你的眼，\\n并长久地沉睡，遮着您的睫阴！\\n猫头鹰', metadata={'id': 'doc:notiondb:071f72a99e3b43fba373e7cc4e4fabbf', 'author': '【法】夏尔•波德莱尔', 'name': '恶之花 【法】夏尔•波德莱尔', 'source': '读书笔记（文学）', 'tags': '诗', 'date_start': '20140226', 'date_end': None}),\n",
       " Document(page_content='天上序曲\\n\\n\\np4\\n人在奋斗时，难免迷误。\\n善人虽受模糊的冲动驱使，\\n总会意识到正确的道路。\\n\\n\\n悲剧第一部\\n\\n第一场 夜\\n\\np11 浮士德\\n你们所说的时代精神，\\n其实乃是著者自己的精神，\\n其中反映着时代的事件。\\n\\n\\n第四场 书斋\\n\\np53 浮士德\\n如果我对某一瞬间说：\\n停一停吧！你真美丽！\\n那时就给我套上枷锁，\\n那时我也情愿毁灭！\\n我一停滞，就变成奴隶\\n\\n\\np55 浮士德\\n听着！问题并不在于快乐。\\n我要献身于沉醉、最痛苦的欢快、\\n迷恋的憎恨、令人爽适的愤慨。\\n我的心胸，求知欲已告熄灭，\\n今后对任何痛苦都视若等闲，\\n凡是赋予全体人类的一切，\\n我要在我内心里自我体验，\\n用这种精神掌握高深的至理，\\n把幸与不幸堆积在我心里，\\n将我的小我扩充为人类的大我，\\n最后我也像人类一样没落。\\n\\n\\np57\\n浮士德：\\n我一心一意，无非是争取戴上\\n人类的冠冕，如不可能，\\n那还成个什么样的人？\\n梅菲斯特 最后你还是——像现在这样。\\n你带几百万根发丝编成的假发，\\n把底厚几尺的高靴垫在脚下，\\n你还是永远像现在这样。\\n\\n浮士德：\\n我把人类精神的一切财富\\n徒然集于一身，我也知详，\\n而到最后，瞧我坐在此处，\\n内心却涌现不出新的力量；\\n我自己并未提高一分，\\n跟无限无量也毫未接近。\\n\\n梅菲斯特：\\n我的好先生，你的意见\\n跟一般见解并无差异。\\n在生的欢乐消逝以前，\\n我们务须聪明行事。\\n见鬼！当然，双足双手，\\n头和屁……（注：屁股），都是你的；\\n可是，我的新的享受，\\n就可因此说不是我的？\\n我若付得出六匹马的价格，\\n它们的脚力不就是我的？\\n我骑着奔驰，岂不就像一个\\n有二十四条腿的豪客？\\n打起精神！丢开顾虑，\\n一同冲向人世间去！\\n我对你讲：一个人只顾沉思，\\n就像个牲口，在荒野地上\\n被一个恶灵牵着，来回乱兜圈子，\\n不知外围有美丽青葱的牧场。\\n\\n\\np59 梅菲斯特\\n让你去蔑视理性、知识，\\n人类拥有的最高的实力，\\n让你沉迷于魔术幻术，\\n获得诳骗精灵的鼓舞，\\n我不用契约已将你驾驭——\\n命运已经赋予他一种精力，\\n永远向前直闯，不受约束，\\n这种过分轻率的努力\\n跳越过尘世的欢乐情趣。\\n我要拖住他过浪荡生活，\\n经历平凡的无聊事件，\\n让他挣扎、发呆、粘着，\\n再对付他的贪得无厌，\\n拿酒食对着他的贪婪的口唇晃摇；\\n他哀求疗愈饥渴，也是无益，\\n这样，即使他没向一个恶魔卖身投靠，\\n他也一定要归于毁灭！', metadata={'id': 'doc:notiondb:84fbe01935f24a5da23d4805d3f56949', 'author': '【德】歌德', 'name': '浮士德 【德】歌德', 'source': '读书笔记（文学）', 'tags': '诗', 'date_start': '20151120', 'date_end': None}),\n",
       " Document(page_content='（一）\\n沉默注入后\\n水位逐渐升高\\n作为降低触礁风险的代价滑入\\n情绪的深海区\\n\\n（二）\\n即使以混沌示人\\n时序图中仍然有K线滋长\\n\\n（三）\\n存活是个恶劣的字眼！\\n拥有美德的因它放弃矜持\\n不知廉耻的变得更加猥琐\\n\\n（四）\\n唯当事情变得无趣起来\\n我的眼神剔透得愈发真诚\\n以直报怨\\n以怨报仇\\n下狗就该有下狗的生存方式\\n\\n（五）\\n第一次复活让我在早晨沉沉睡去\\n第二次复活理应让我在夜晚早早醒来\\n\\n（六）\\n行动是一种作恶但\\n行动也是一种净罪\\n不行动就什么也不算\\n贪婪让我们对共价键\\n心生敌意\\n\\n（七）\\n到处都在地震\\n但仔细想来\\n却并没有什么值得引发地震\\n\\n（八）\\n午后精心修剪的草坪上\\n有着被拦腰截断的生命\\n特有的馨香\\n\\n（九）\\n我对你的忠诚到底算是\\n因信仰引发的奇迹还是\\n因奇迹引发的信仰', metadata={'id': 'doc:notiondb:d4d013ae0b2d436cbe9c0466e4c55c6b', 'author': None, 'name': '2017-DEC-02 社会人', 'source': '写作', 'tags': '日常记趣, 诗', 'date_start': '20171202', 'date_end': '20171202'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "\n",
    "s.invoke(\"“请告诉四姐妹”是哪首诗歌中的？请从“诗”中找答案。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610fcb3-e975-48a4-9303-de6d35e31a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
