{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d7d426-16b1-49bc-aeea-27b5536030e3",
   "metadata": {},
   "source": [
    "# Evaluate vector databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f13607d-272f-4daa-95a9-b4f167b5db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain_core.documents.base import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d8b58-0591-48e7-9f2b-54e57f921652",
   "metadata": {},
   "source": [
    "## Load evaluation dataset and docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccaca400-cd6b-410b-ab24-be1633f6937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import NotionDBLoader\n",
    "import tomllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0079b60-a225-4a6b-adc6-fae9d8b54dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)\n",
    "\n",
    "with open('../.notion_databases.toml', 'rb') as f:\n",
    "    _DATABASES_NOTION = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41545a3-717a-4836-8af6-f85d34cd5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notion_dbs(dbs, id):\n",
    "    loader = NotionDBLoader(\n",
    "        integration_token=_TOKENS['notion'],\n",
    "        database_id=dbs[id],\n",
    "        request_timeout_sec=300,  # optional, defaults to 10\n",
    "    )\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d8cd91-4231-4294-addc-5181f81dc36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 842 ms, total: 11.3 s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "te = ThreadPoolExecutor()\n",
    "results = list(te.map(lambda x: load_notion_dbs(_DATABASES_NOTION, x), _DATABASES_NOTION.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7712be4e-e8b2-4ae3-98ae-47e15b137ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_from_notion: Dict[str, List[Document]] = dict(zip(_DATABASES_NOTION.keys(), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a12508e-a1ee-4abb-9338-4b59cb5c3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional pickle step so we don't need to query notionDB again\n",
    "import pickle\n",
    "\n",
    "with open('../data/notion_offline.pkl', 'wb') as f:\n",
    "    pickle.dump(docs_from_notion, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049f9e94-78dd-4ba4-9e3c-aa37688b6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/notion_offline.pkl', 'rb') as f:\n",
    "    docs_from_notion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9603f28-8f80-46b2-8622-ff6c1e64936b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': {'start': '2013-10-26', 'end': '2013-10-26', 'time_zone': None},\n",
       " 'name': '2013-OCT-26 师说',\n",
       " 'tags': ['日常记趣'],\n",
       " 'id': '273ea76f-a35c-474e-bfe0-41a3daae5c96'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_from_notion['写作'][0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744edc8d-f8d0-4ca3-9a7e-33ab7792544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source_property(docs_from_notion: Dict[str, List[Document]]) -> List[Document]:\n",
    "    docs_list = list()\n",
    "    \n",
    "    for db_name, docs in docs_from_notion.items():\n",
    "        for doc in docs:\n",
    "            # because our data are gathered from multiple databases\n",
    "            # we are going to throw the database names as one property\n",
    "            # into the docs' metadata field\n",
    "            # and return as a list\n",
    "            doc.metadata['source'] = db_name\n",
    "\n",
    "            # vector dbs don't allow complex metadata types like dict and list\n",
    "            # chroma is explicity about this, faiss is implicit about it\n",
    "            # but both \"filter\" arg assumes simple string match\n",
    "            # we'll convert into flattened date\n",
    "            if 'date' in doc.metadata:\n",
    "                if 'start' in doc.metadata['date']:\n",
    "                    doc.metadata['date_start'] = doc.metadata['date']['start']\n",
    "                if 'end' in doc.metadata['date']:\n",
    "                    doc.metadata['date_end'] = doc.metadata['date']['end']\n",
    "                    del doc.metadata['date']\n",
    "\n",
    "            if 'tags' in doc.metadata:\n",
    "                doc.metadata['tags'] = \", \".join(doc.metadata['tags'])\n",
    "                \n",
    "\n",
    "        docs_list.extend(docs)\n",
    "        \n",
    "    return docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50dd31-37d0-474e-b263-b931716b97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let an automated process takes care the rest\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "filter_complex_metadata(docs_from_notion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e12db-10e3-46a9-9383-794f3b378c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS, Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d97c614-9c05-41c3-935d-e388ac551927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function similarity_search_with_score in module langchain_community.vectorstores.faiss:\n",
      "\n",
      "similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, Any]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      "    Return docs most similar to query.\n",
      "    \n",
      "    Args:\n",
      "        query: Text to look up documents similar to.\n",
      "        k: Number of Documents to return. Defaults to 4.\n",
      "        filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      "        fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      "                  Defaults to 20.\n",
      "    \n",
      "    Returns:\n",
      "        List of documents most similar to the query text with\n",
      "        L2 distance in float. Lower score represents more similarity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(FAISS.similarity_search_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d49ac4c-d89d-4a8c-a1b7-f3866186b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function similarity_search_with_score in module langchain_community.vectorstores.chroma:\n",
      "\n",
      "similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      "    Run similarity search with Chroma with distance.\n",
      "    \n",
      "    Args:\n",
      "        query (str): Query text to search for.\n",
      "        k (int): Number of results to return. Defaults to 4.\n",
      "        filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      "    \n",
      "    Returns:\n",
      "        List[Tuple[Document, float]]: List of documents most similar to\n",
      "        the query text and cosine distance in float for each.\n",
      "        Lower score represents more similarity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Chroma.similarity_search_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bed6e18-4831-449c-970f-dd5d880f3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': {'start': '2013-10-26', 'end': '2013-10-26', 'time_zone': None},\n",
       " 'name': '2013-OCT-26 师说',\n",
       " 'tags': ['日常记趣'],\n",
       " 'id': '273ea76f-a35c-474e-bfe0-41a3daae5c96'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_from_notion = add_source_property(docs_from_notion)\n",
    "docs_from_notion[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e60530-20b3-4536-830b-4dca9d02f39f",
   "metadata": {},
   "source": [
    "## Testing ideas\n",
    "\n",
    "* use langchain.text_splitterRecursiveCharacterTextSplitter\n",
    "* storage: test 2 vector databses: chroma & faiss\n",
    "* retriever:\n",
    "  * `Self-querying retriever` --  use an LLM to construct new queries that can question the structured data/metadata of the document\n",
    "  * `MultiQueryRetriever` -- allow an LLM to paraphrase the query to get hopefully a diverse set of docs\n",
    "  * `Contextual compression` -- use an LLM to pre-filter and compress the docs retrieved before feeding the contexts to another LLM to answer\n",
    "  * https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "* retrieval methods: cos/dot; llm-aided; MMR (Maximum marginal relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58bb7459-2a6b-4e7e-b7d8-7c09b407a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presumably docs in NotionDB fits more with MarkdownHeaderTextSplitter\n",
    "# however, most of the documents in my personal databases don't have such header-text structure\n",
    "# and they are not important for my use cases (I won't ask it to reason on a specific section \n",
    "# in a doc). Thus I'll use the regular RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372985ea-0e5b-4413-ab02-3ebfd0abe229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 1136)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_params = {\n",
    "    # 1 Chinese characters = 2 english character\n",
    "    # most paragraphs/sections are within 500 Chinese words/chars\n",
    "    'chunk_size': 1000, \n",
    "    'chunk_overlap': 250,\n",
    "}\n",
    "\n",
    "rc_splitter = RecursiveCharacterTextSplitter(**chunk_params)\n",
    "\n",
    "splits = rc_splitter.split_documents(docs_from_notion)\n",
    "len(docs_from_notion), len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3386af4-e73d-4492-abcd-91824ff08888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=_TOKENS['huggingface'], \n",
    "    model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfdf1bbe-d58c-4dac-80c5-483aedb91f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 111 ms, total: 1.48 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vs_chroma = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embeddings, \n",
    "    persist_directory='../database/vs_chroma'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75dca360-d649-4259-abfd-0a9aeb462895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 273 ms, sys: 60.6 ms, total: 333 ms\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# faiss is taking a lazy operation here to ingest document\n",
    "vs_faiss = FAISS.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embeddings, \n",
    ")\n",
    "\n",
    "vs_faiss.save_local('../database/vs_faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b15e2ea6-1511-4e2a-b814-da1a548a00a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both don't allow fuzzy matches on filter\n",
    "# have to be 100% match\n",
    "vs_faiss.similarity_search_with_score(\n",
    "    '谁说过陌生贵己？', \n",
    "    filter={\n",
    "        'author': '冯友兰',\n",
    "    }\n",
    ")\n",
    "\n",
    "vs_chroma.similarity_search_with_score(\n",
    "    '谁说过陌生贵己？', \n",
    "    filter={\n",
    "        'author': '冯友兰',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b86b7b-f05d-413c-8893-b4e1f5af3814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='为我，轻物重生\\n《孟子》中说：“杨子取为我，拔一毛而利天下，不为也。”；《吕氏春秋》中说：“陌生贵己。”；《淮南子》中写：“全性保真，不以物累形：杨子所立也。”这些是同时代的著作中对杨朱思想的记录和反映\\n在道家更后期的《老子》和《庄子》中也有相同的体现。《老子》中写到：“名与身：孰亲？身与货：孰多？”《庄子》中写到：“山木自寇也。膏火自煎也，桂可食，故伐之。漆可用，故割之。”\\n无用是全生的方法。善于全生的人，一定不能多为恶，但也一定不能多为善。他一定要生活在善恶之间，力求无用。到头来，无用却对于他有大用\\n从为我到无我：先秦道家发展三阶段\\n先秦道家都是为我的，但是随着思考的深入，后来的发展使这种为我走向反面，取消了它自身\\n第一阶段杨朱，出发点是全生避害\\n第二阶段老子，开始企图揭示宇宙事物变化的规律。一个人如果懂得了这些规律，并且遵循规律而调整行动，那么他就能够使事物转向对他有利的方向。但即便一个人懂得自然规律，预料之外的因素仍然会发挥作用，并带来可能的危害（“吾所以有大患者，为吾有身，及吾无身，吾有何患！”）\\n第三阶段庄子，因为没有办法避免受到外界事物的影响，庄子转而从一种更高的观点看待事物，产生”齐生死，一物我“的理论\\n孟子：儒家的理想主义派\\n人性本善', metadata={'author': '【中】冯友兰', 'date': {'start': '2023-05-06', 'end': None, 'time_zone': None}, 'tags': ['人文'], 'name': '中国哲学简史', 'id': '0419517a-59be-47a2-a4b9-bb6f21630614'}),\n",
       "  1.0759109)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faiss applies filter after semantic search\n",
    "# it also has an additional fetch_k arg for senmantic search\n",
    "vs_faiss.similarity_search_with_score(\n",
    "    '谁说过陌生贵己？', \n",
    "    filter={\n",
    "        'author': '【中】冯友兰',\n",
    "    },\n",
    "    k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f782db2b-e14d-4db4-8a67-148cbfde9074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='为我，轻物重生\\n《孟子》中说：“杨子取为我，拔一毛而利天下，不为也。”；《吕氏春秋》中说：“陌生贵己。”；《淮南子》中写：“全性保真，不以物累形：杨子所立也。”这些是同时代的著作中对杨朱思想的记录和反映\\n在道家更后期的《老子》和《庄子》中也有相同的体现。《老子》中写到：“名与身：孰亲？身与货：孰多？”《庄子》中写到：“山木自寇也。膏火自煎也，桂可食，故伐之。漆可用，故割之。”\\n无用是全生的方法。善于全生的人，一定不能多为恶，但也一定不能多为善。他一定要生活在善恶之间，力求无用。到头来，无用却对于他有大用\\n从为我到无我：先秦道家发展三阶段\\n先秦道家都是为我的，但是随着思考的深入，后来的发展使这种为我走向反面，取消了它自身\\n第一阶段杨朱，出发点是全生避害\\n第二阶段老子，开始企图揭示宇宙事物变化的规律。一个人如果懂得了这些规律，并且遵循规律而调整行动，那么他就能够使事物转向对他有利的方向。但即便一个人懂得自然规律，预料之外的因素仍然会发挥作用，并带来可能的危害（“吾所以有大患者，为吾有身，及吾无身，吾有何患！”）\\n第三阶段庄子，因为没有办法避免受到外界事物的影响，庄子转而从一种更高的观点看待事物，产生”齐生死，一物我“的理论\\n孟子：儒家的理想主义派\\n人性本善', metadata={'author': '【中】冯友兰', 'date_start': '2023-05-06', 'id': '0419517a-59be-47a2-a4b9-bb6f21630614', 'name': '中国哲学简史', 'source': '读书笔记（文学）', 'tags': '人文'}),\n",
       "  1.0759108066558838),\n",
       " (Document(page_content='忠与恕\\n实行仁的具体方法就是推己及人（“己欲立而立人，己欲达而达人……可谓仁之方也”）\\n“忠”是推己及人的肯定方面；“恕”是其否定方面\\n忠恕之道是人的道德生活的开端和终结，实行忠恕就是行仁（“夫子之道，忠恕而已矣”）\\n知命\\n“无所为而为”：儒家认为，一个人不可能“无为”，因为每个人都有他应该做的事。然而他做这些事都是“无所为”，因为做这些事的价值在于做的本身之内，而不是在于外在的结果\\n知命是承认世界本来存在的必然性，这样，对于外在的成败也就无所萦怀。在这种意义上，人就永远不会失败，因为如果我们尽了应尽的义务，那么这项义务在道德上就完成了，这与行动的外在成败并不相干\\n孔子的一生正是这种学说的写照。他周游各地，政治上的一切努力都没有得到回报，但他并不气馁（“不知命，无以为君子也。”）\\n超道德：孔子在五六十岁的时候认识“天命”并且顺乎天命，他在这时候认识到了超道德的价值，认为他所做的事是受到了天的支持（“天下之无道也久矣，天将以夫子为木铎。”）孔子的超道德价值仍然是人伦日用的，孔子的超道德价值和道家抛弃理智和目的的混沌、神秘仍然有所区别\\n墨子：孔子的第一个反对者\\n在周代，天子、诸侯、封建主都有他们的军事专家。当时军队的骨干，由世袭的武士组成。随着封建制度的解体，这些武士专家丧失了爵位，流散各地被雇佣，这种人被称为“游侠”。史记《游侠列传》说他们”其言必信，其行必果，已诺必诚，不爱其躯，赴士之厄困。“\\n和源自上层阶层的儒家思想不同，墨家思想是来自下层阶级的人。从平民观点看，礼乐一类的古代文化和社会活动完全限于贵族，毫无实用价值。墨家对这种传统制度及其辩护者（儒家）的批判，加上对本阶级职业道德的发挥，构成了墨家哲学的核心。\\n墨子及其门徒和普通游侠还是有两点不同：第一，普通游侠只要得到酬谢或者恩惠就可以打仗，但墨子强烈反对侵略战争，只参加严格限于自卫的战争；第二，普通游侠只是新手职业道德的条规，而墨子却详细阐明这种道德并论证了其正当性。\\n兼爱\\n“强之劫弱，众之暴寡，诈之谋愚，贵之傲贱：此天下之害也。”\\n兼爱是墨子哲学的中心概念，这种道德是游侠“有福同享有难同当”逻辑的延伸。以这种团体的概念为基础，墨子宣扬天下每个人都应该无差别地爱一切人\\n功利主义：天志和明鬼\\n为了诱导人们实行兼爱，墨子引进了宗教的、政治的制裁', metadata={'author': '【中】冯友兰', 'date_start': '2023-05-06', 'id': '0419517a-59be-47a2-a4b9-bb6f21630614', 'name': '中国哲学简史', 'source': '读书笔记（文学）', 'tags': '人文'}),\n",
       "  1.4103361368179321)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chroma applies filter before semantic sesarch\n",
    "vs_chroma.similarity_search_with_score(\n",
    "    '谁说过陌生贵己？', \n",
    "    filter={\n",
    "        'author': '【中】冯友兰',\n",
    "    },\n",
    "    k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901e40f-cf76-4431-a402-778528416ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d49cd-3c67-4f56-9d49-6f627e07f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7c892-8b1e-42a9-9899-13a7d10f603c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1df40-b792-4f71-8e39-154f2f868589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb83c4-01f5-4e12-90a9-ca0addbdffef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbf76a-e315-4007-a7ed-1a78308ccd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4490e02-f34a-4240-9540-204aa18c7cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a886f-53ec-4a7c-b372-0f880ad390e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eae43f-a251-4cfa-bbdf-1ee783516fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66034a93-b524-47ab-a8e6-1b8a1d5b645d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c733eff-df9e-4447-a692-140ff8c81c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use SelfQueryRetriever to allow in metadata context\n",
    "# https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\n",
    "retriever = vectorstore.as_retriever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
