{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2228b50e-bde6-4811-90d1-3e5ffba0020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eabb57f-21d8-4925-a7f6-ac5a797cc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c016251c-280c-4f27-9241-0a59f3e3a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)\n",
    "\n",
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f605074c-008f-407e-88f8-77d9de70006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q': '什么是我国第一部编年史著作？', 'a': '《左传》。', 'docs': ['附：《左传》是我国第一部编年史著作。\\n']},\n",
       " {'q': '什么是我国第一部编年国别史？', 'a': '《国语》。', 'docs': ['附：《国语》是我国第一部编年国别史。\\n']},\n",
       " {'q': '“寡人之于国也”下一句是什么？来自哪里？',\n",
       "  'a': '“寡人之于国也”下一句是“尽心焉耳矣”。这个句子来自《孟子》。',\n",
       "  'docs': ['梁惠王曰：“寡人之于国也，尽心焉耳矣。河内凶，则移其民于河东，移其粟于河内；河东凶亦然。察邻国之政，无如寡人之用心者。邻国之民不加少，寡人之民不加多，何也？”',\n",
       "   '《寡人之于国也》（孟子）\\n']}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_test_cases\n",
    "\n",
    "test_cases = load_test_cases('../data/test_cases.txt')\n",
    "test_cases[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef978eb-ad78-4ef6-bc74-d28f626807fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /Users/fred/Documents/models/zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4095.06 MiB, ( 4095.12 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4095.05 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   512.00 MiB, ( 4608.69 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    80.04 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1184.02 MiB, ( 5792.70 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1184.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   314.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'huggingfaceh4_zephyr-7b-beta'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+_CONFIGS['model_mapping'][_CONFIGS['model_name']],\n",
    "    name=_CONFIGS['model_name'], \n",
    "    **_CONFIGS['llm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa3445c7-b4da-4287-9fda-8ae8f84764a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    _CONFIGS[\"model_name\"], trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7286314-0821-4a9d-a34c-0caf800a0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open(\"../templates/query_constructor_template.toml\", \"rb\") as f:\n",
    "    templates = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7f01ac4-9fd2-4e9b-9a3c-cf85e2368ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\n你是一个乐于助人的AI助手，你的唯一任务是从给定的文本中找到关键词和搜索范围。关键词将用于后续在搜索引擎中进行搜索。搜索范围将定义搜索的数据库。关键词和搜索范围只能完全来源于文本中，禁止添加其他内容。搜索范围的默认输出为“无”，除非文本中有明确要求（如：“请从某处寻找答案”）。如果有多个关键词或搜索范围，用空格“ ”分隔。\\n</s>\\n<|user|>\\n<< 文本 >>\\n你是谁?</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：你是谁\\n搜索范围：无</s>\\n<|user|>\\n<< 文本 >>\\n小王认识小李相识吗？他们是怎么认识的？请从资料库中找到答案。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：小王和小李\\n搜索范围：资料库</s>\\n<|user|>\\n<< 文本 >>\\n请列举一个关于“深秋初冬”的描写片段。请从“文学”中寻找。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：深秋初冬\\n搜索范围：文学</s>\\n<|user|>\\n<< 文本 >>\\n李白针对《逍遥游》写过一首什么诗？答案在古代诗歌中。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：李白 逍遥游\\n搜索范围：古代诗歌</s>\\n<|user|>\\n<< 文本 >>\\n“鹅鹅鹅，曲项向天歌”是哪位诗人所作？何时所作？请只给出诗人名字。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：鹅鹅鹅，曲项向天歌\\n搜索范围：无</s>\\n<|user|>\\n<< 文本 >>\\n“结婚是想象战胜理智”下一句是什么？来自哪里？</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：结婚是想象战胜理智\\\\n搜索范围：无</s>\\n<|user|>\\n<< 文本 >>\\n哪一本小说谈到了“后现代性”的话题？请根据“摘抄”回答。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：后现代性\\\\n搜索范围：小说 摘抄</s>\\n<|user|>\\n<< 文本 >>\\n“我们之所以突然变得残暴”的后面是什么？请从三岛由纪夫的小说中寻找答案。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n关键词：我们之所以突然变得残暴\\\\n搜索范围：三岛由纪夫 小说</s>\\n<|user|>\\n<< 文本 >>\\n新裤子乐队最出名的专辑是什么时候发售的？请简单介绍该乐队。</s>\\n<|assistant|>\\n<< 关键词和搜索范围 >>\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_notion_companion.few_shot_constructor import FewShotTemplateConstructor\n",
    "\n",
    "few_shot = FewShotTemplateConstructor(tokenizer, templates)\n",
    "s = few_shot.invoke(\"新裤子乐队最出名的专辑是什么时候发售的？请简单介绍该乐队。\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab912a08-108a-4409-8ad0-e07b8fc2be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8600.66 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    28 runs   (    0.09 ms per token, 11372.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2832.99 ms /   559 tokens (    5.07 ms per token,   197.32 tokens per second)\n",
      "llama_print_timings:        eval time =     982.06 ms /    27 runs   (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =    3862.99 ms /   586 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'关键词：鹅鹅鹅，曲项向天歌\\\\n搜索范scope：无'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "c = RunnableLambda(few_shot.invoke) | llm\n",
    "\n",
    "c.invoke(\"“鹅鹅鹅，曲项向天歌”是哪位诗人所作？何时所作？请只给出诗人名字。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86928eb7-5873-4dec-a759-04ff6a5f6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_notion_companion.query_analyzer import QueryAnalyzer\n",
    "\n",
    "qa = QueryAnalyzer(llm, _CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5821494e-d12b-46be-b8d4-73103a3eefa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    28 runs   (    0.09 ms per token, 11322.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     450.03 ms /    45 tokens (   10.00 ms per token,    99.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.13 ms /    27 runs   (   41.19 ms per token,    24.28 tokens per second)\n",
      "llama_print_timings:       total time =    1609.82 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么是我国第一部编年史著作？\n",
      "{'keywords': ['我国第一部编年史著作'], 'domain': ['国家档案局数据库']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    25 runs   (    0.09 ms per token, 11579.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.21 ms /    45 tokens (    7.40 ms per token,   135.05 tokens per second)\n",
      "llama_print_timings:        eval time =     992.47 ms /    24 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
      "llama_print_timings:       total time =    1367.90 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么是我国第一部编年国别史？\n",
      "{'keywords': ['第一部编年史或编年国别史'], 'domain': ['我国']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    70 runs   (    0.09 ms per token, 11330.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.71 ms /    53 tokens (    6.37 ms per token,   156.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2881.45 ms /    69 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time =    3343.68 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“寡人之于国也”下一句是什么？来自哪里？\n",
      "{'keywords': ['寡人之于国也'], 'domain': ['孔子集经']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    27 runs   (    0.08 ms per token, 11952.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     342.41 ms /    61 tokens (    5.61 ms per token,   178.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.69 ms /    26 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1470.33 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "庄子写过哪些文章？请根据“高中古诗文”中收录的作品回答。\n",
      "{'keywords': ['庄子', '写过哪些文章'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    36 runs   (    0.09 ms per token, 11711.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.98 ms /    57 tokens (    5.98 ms per token,   167.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1472.14 ms /    35 runs   (   42.06 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time =    1874.57 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“一陂春水绕花身”中“陂”的读音是什么？\n",
      "{'keywords': ['一陂春水绕花身、陂、读音'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /    37 runs   (    0.10 ms per token, 10364.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     475.61 ms /    79 tokens (    6.02 ms per token,   166.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1523.65 ms /    36 runs   (   42.32 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time =    2064.86 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "补充对联：“此地有崇山峻岭茂林修竹”，请根据“高中古诗文”中收录的作品回答。\n",
      "{'keywords': ['此地有崇山峻岭茂林修竹'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    32 runs   (    0.08 ms per token, 12553.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.00 ms /    48 tokens (    7.08 ms per token,   141.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.57 ms /    31 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time =    1705.17 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "苏轼是如何评价韩愈的？\n",
      "{'keywords': ['苏轼', '韩愈', '评价'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    23 runs   (    0.08 ms per token, 11788.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.17 ms /    51 tokens (    6.67 ms per token,   149.93 tokens per second)\n",
      "llama_print_timings:        eval time =     935.12 ms /    22 runs   (   42.51 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time =    1316.53 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“治大国若烹小鲜”是谁说的？\n",
      "{'keywords': ['治大国若烹小鲜'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    28 runs   (    0.08 ms per token, 11824.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     342.59 ms /    52 tokens (    6.59 ms per token,   151.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.41 ms /    27 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time =    1538.66 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "据推测，《卫风•氓》是否没有经过修改？\n",
      "['关键词：卫风、氓、修改、无搜索范围（默认为“无”）']\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    26 runs   (    0.10 ms per token, 10248.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.15 ms /    44 tokens (    8.03 ms per token,   124.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1069.48 ms /    25 runs   (   42.78 ms per token,    23.38 tokens per second)\n",
      "llama_print_timings:       total time =    1493.23 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《短歌行》中前两句是什么？\n",
      "{'keywords': ['《短歌行》前两句'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /    23 runs   (    0.09 ms per token, 11704.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     344.27 ms /    59 tokens (    5.84 ms per token,   171.38 tokens per second)\n",
      "llama_print_timings:        eval time =     970.41 ms /    22 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =    1356.89 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《春江花月夜》收录在哪里？请根据“高中古诗文”回答。\n",
      "{'keywords': ['春江花月夜'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    34 runs   (    0.08 ms per token, 12413.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     335.41 ms /    64 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1426.75 ms /    33 runs   (   43.23 ms per token,    23.13 tokens per second)\n",
      "llama_print_timings:       total time =    1821.80 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《黄州快哉亭记》中宋玉是怎么讽刺楚襄王的？\n",
      "{'keywords': ['宋玉', '讽刺楚襄王'], 'domain': ['高中古诗文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    22 runs   (    0.08 ms per token, 12263.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     346.01 ms /    54 tokens (    6.41 ms per token,   156.07 tokens per second)\n",
      "llama_print_timings:        eval time =     906.54 ms /    21 runs   (   43.17 ms per token,    23.16 tokens per second)\n",
      "llama_print_timings:       total time =    1295.28 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白针对《逍遥游》写过一首什么诗？\n",
      "{'keywords': ['李白', '逍遥游'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    24 runs   (    0.09 ms per token, 11434.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     480.58 ms /    68 tokens (    7.07 ms per token,   141.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.73 ms /    23 runs   (   43.64 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:       total time =    1527.95 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哪一本小说谈到了“美的一次性”的话题？请根据“读书笔记（文学）”回答。\n",
      "{'keywords': ['美的一次性'], 'domain': ['读书笔记（文学）']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    30 runs   (    0.09 ms per token, 11481.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     473.64 ms /    67 tokens (    7.07 ms per token,   141.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1262.92 ms /    29 runs   (   43.55 ms per token,    22.96 tokens per second)\n",
      "llama_print_timings:       total time =    1790.88 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“我们之所以突然变得残暴”的后面是什么？请从三岛由纪夫的小说中寻找答案。\n",
      "{'keywords': ['我们之所以突然变得残暴'], 'domain': ['三岛由纪夫的小说']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    38 runs   (    0.08 ms per token, 11964.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     479.01 ms /    77 tokens (    6.22 ms per token,   160.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1652.31 ms /    37 runs   (   44.66 ms per token,    22.39 tokens per second)\n",
      "llama_print_timings:       total time =    2199.76 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“每个人都以为他自己至少有一种主要的美德。”是出自哪里？请从“读书笔记（文学）”中找到答案。\n",
      "{'keywords': ['每个人都以为他自己至少有一种主要的美德'], 'domain': ['读书笔记（文学）']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /   182 runs   (    0.08 ms per token, 12028.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     482.89 ms /    81 tokens (    5.96 ms per token,   167.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8071.20 ms /   181 runs   (   44.59 ms per token,    22.43 tokens per second)\n",
      "llama_print_timings:       total time =    8882.14 ms /   262 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么钱钟书说“忠厚老实人的恶毒，像饭里的沙砾或者出骨鱼片里未净的刺”？\n",
      "{'keywords': ['钱钟书', '忠厚老实人的恶毒'], 'domain': ['文学作品']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    45 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     483.17 ms /    82 tokens (    5.89 ms per token,   169.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1954.88 ms /    44 runs   (   44.43 ms per token,    22.51 tokens per second)\n",
      "llama_print_timings:       total time =    2515.47 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是什么让昆德拉说“我要对你说出我一生中最悲愁的发现：受迫害者并不比迫害者更高贵”？\n",
      "{'keywords': ['受迫害者、迫害者、高贵、昆德拉'], 'domain': ['文学作品或者作者的言论记录']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    16 runs   (    0.09 ms per token, 10973.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.95 ms /    45 tokens (    7.58 ms per token,   131.98 tokens per second)\n",
      "llama_print_timings:        eval time =     675.36 ms /    15 runs   (   45.02 ms per token,    22.21 tokens per second)\n",
      "llama_print_timings:       total time =    1044.44 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哪本小说中提到了“细密画”？\n",
      "{'keywords': ['细密画'], 'domain': ['小说']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    30 runs   (    0.08 ms per token, 12053.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     478.95 ms /    70 tokens (    6.84 ms per token,   146.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.36 ms /    29 runs   (   45.01 ms per token,    22.22 tokens per second)\n",
      "llama_print_timings:       total time =    1836.58 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请补充“火车代表黑夜与毁灭”的后一句。请从“读书笔记（文学）”中找到答案。\n",
      "{'keywords': ['火车代表黑夜与毁灭'], 'domain': ['读书笔记（文学）']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    24 runs   (    0.09 ms per token, 11374.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     345.75 ms /    51 tokens (    6.78 ms per token,   147.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1034.01 ms /    23 runs   (   44.96 ms per token,    22.24 tokens per second)\n",
      "llama_print_timings:       total time =    1422.81 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《天使与昆虫》是哪位作家的作品？\n",
      "{'keywords': ['天使与昆虫'], 'domain': ['作者名单']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /    22 runs   (    0.08 ms per token, 12134.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     348.54 ms /    58 tokens (    6.01 ms per token,   166.41 tokens per second)\n",
      "llama_print_timings:        eval time =     944.31 ms /    21 runs   (   44.97 ms per token,    22.24 tokens per second)\n",
      "llama_print_timings:       total time =    1332.18 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请从辛波斯卡的诗歌中找出一首以“雪”为主题的。\n",
      "['关键词：雪 搜索范围：辛波斯卡诗歌']\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    26 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     350.38 ms /    58 tokens (    6.04 ms per token,   165.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.75 ms /    25 runs   (   45.39 ms per token,    22.03 tokens per second)\n",
      "llama_print_timings:       total time =    1531.81 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请补充完整以下句子：“铁如意，指挥倜傥”。\n",
      "{'keywords': ['铁如意，指挥倜傥'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /    17 runs   (    0.08 ms per token, 12390.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     348.65 ms /    43 tokens (    8.11 ms per token,   123.33 tokens per second)\n",
      "llama_print_timings:        eval time =     725.58 ms /    16 runs   (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_print_timings:       total time =    1105.45 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人生有哪“四不捡”？\n",
      "{'keywords': ['四不捡'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    22 runs   (    0.08 ms per token, 11789.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     347.59 ms /    51 tokens (    6.82 ms per token,   146.73 tokens per second)\n",
      "llama_print_timings:        eval time =     957.95 ms /    21 runs   (   45.62 ms per token,    21.92 tokens per second)\n",
      "llama_print_timings:       total time =    1345.18 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请全文摘录海子的《春天，十个海子》。\n",
      "{'keywords': ['春天，十个海子'], 'domain': ['海子全文']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    25 runs   (    0.09 ms per token, 11410.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     342.90 ms /    45 tokens (    7.62 ms per token,   131.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.17 ms /    24 runs   (   45.67 ms per token,    21.89 tokens per second)\n",
      "llama_print_timings:       total time =    1484.09 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本多是哪本小说中出现的人物？\n",
      "{'keywords': ['本多是哪本小说中出现的人物'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    22 runs   (    0.08 ms per token, 11827.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     350.91 ms /    55 tokens (    6.38 ms per token,   156.74 tokens per second)\n",
      "llama_print_timings:        eval time =     962.24 ms /    21 runs   (   45.82 ms per token,    21.82 tokens per second)\n",
      "llama_print_timings:       total time =    1353.55 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“接受神的恩惠降生的人”下一句是什么？来自哪里？\n",
      "{'keywords': ['接受神的恩惠降生的人'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    23 runs   (    0.09 ms per token, 11710.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     350.34 ms /    55 tokens (    6.37 ms per token,   156.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1012.53 ms /    22 runs   (   46.02 ms per token,    21.73 tokens per second)\n",
      "llama_print_timings:       total time =    1404.53 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“西伯利亚癔病”是哪本小说中出现的概念？\n",
      "{'keywords': ['西伯利亚癔病'], 'domain': ['小说']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    25 runs   (    0.09 ms per token, 11261.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     483.54 ms /    67 tokens (    7.22 ms per token,   138.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.03 ms /    24 runs   (   46.21 ms per token,    21.64 tokens per second)\n",
      "llama_print_timings:       total time =    1637.92 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请列举一个关于“深秋初冬”的描写片段。请从“读书笔记（文学）”中寻找。\n",
      "{'keywords': ['深秋初冬'], 'domain': ['读书笔记（文学）']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    32 runs   (    0.08 ms per token, 11949.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.40 ms /    60 tokens (    5.91 ms per token,   169.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.78 ms /    31 runs   (   46.48 ms per token,    21.52 tokens per second)\n",
      "llama_print_timings:       total time =    1853.98 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请摘录“猛忆西湖，当年一梦难忘”的全诗词。\n",
      "['关键词：猛忆西湖、当年一梦难忘、诗词、搜索范围：无']\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    29 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     352.16 ms /    56 tokens (    6.29 ms per token,   159.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1307.06 ms /    28 runs   (   46.68 ms per token,    21.42 tokens per second)\n",
      "llama_print_timings:       total time =    1712.05 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“胁肩媚笑，病于夏畦”是什么意思？\n",
      "['关键词：胁肩媚笑、病于夏畦、搜索范围：无']\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    28 runs   (    0.09 ms per token, 11067.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.22 ms /    56 tokens (    6.33 ms per token,   158.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1261.94 ms /    27 runs   (   46.74 ms per token,    21.40 tokens per second)\n",
      "llama_print_timings:       total time =    1667.67 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在《道连·葛雷的画像》中王尔德是如何形容英国人的。\n",
      "{'keywords': ['王尔德', '英国人', '道连·葛雷的画像'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /    19 runs   (    0.08 ms per token, 11942.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     347.52 ms /    47 tokens (    7.39 ms per token,   135.25 tokens per second)\n",
      "llama_print_timings:        eval time =     844.14 ms /    18 runs   (   46.90 ms per token,    21.32 tokens per second)\n",
      "llama_print_timings:       total time =    1226.65 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“子非吾友也”的出处是哪里？\n",
      "{'keywords': ['子非吾友也'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    22 runs   (    0.09 ms per token, 11708.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     349.59 ms /    49 tokens (    7.13 ms per token,   140.16 tokens per second)\n",
      "llama_print_timings:        eval time =     989.08 ms /    21 runs   (   47.10 ms per token,    21.23 tokens per second)\n",
      "llama_print_timings:       total time =    1380.06 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昆德拉是否有关于纽约的描写？\n",
      "{'keywords': ['昆德拉', '纽约'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    52 runs   (    0.09 ms per token, 11426.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     492.58 ms /    79 tokens (    6.24 ms per token,   160.38 tokens per second)\n",
      "llama_print_timings:        eval time =    2417.34 ms /    51 runs   (   47.40 ms per token,    21.10 tokens per second)\n",
      "llama_print_timings:       total time =    3003.94 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“我相信某一天，在某个人的生命中，他头顶天空中所有云朵的形状将会片刻地与他相似。”出自哪里？\n",
      "{'keywords': ['我相信某一天，在某个人的生命中，他头顶天空中所有云朵的形状将会片刻地与他相似'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    36 runs   (    0.09 ms per token, 11635.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     506.71 ms /    78 tokens (    6.50 ms per token,   153.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1668.50 ms /    35 runs   (   47.67 ms per token,    20.98 tokens per second)\n",
      "llama_print_timings:       total time =    2244.26 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有一个诗人曾经写过类似“有人把国家带进沟里，但这些人说统治是一门艺术”的话。请找到出处。\n",
      "{'keywords': ['有人把国家带进沟里，但这些人说统治是一门艺术'], 'domain': ['无']}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4042.14 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    29 runs   (    0.08 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     359.47 ms /    63 tokens (    5.71 ms per token,   175.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1337.96 ms /    28 runs   (   47.78 ms per token,    20.93 tokens per second)\n",
      "llama_print_timings:       total time =    1777.49 ms /    91 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "心学和理学的区别是什么？请从《中国哲学简史》中找到相关资料。\n",
      "{'keywords': ['心学和理学的区别'], 'domain': ['《中国哲学简史》']}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for case in test_cases:\n",
    "    r = qa.invoke(case['q'])\n",
    "    print(case['q'])\n",
    "    print(r)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3abc70-7406-4fca-bc20-f0b781f4aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
