{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687426f4-14b4-4d40-97f9-447ac9baf617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a071a8-cac2-470f-8d96-f73feb1708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078e0401-7050-4f98-b60c-d2bb2d330a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebdc5df-377d-4463-943e-218bd6402c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6ba61d-e198-4ccb-af9d-0ce45515b488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /Users/fred/Documents/models/zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4095.06 MiB, ( 4095.12 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4095.05 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 7168\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   896.00 MiB, ( 4992.69 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =   896.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  896.00 MiB, K (f16):  448.00 MiB, V (f16):  448.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =   104.05 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1976.02 MiB, ( 6968.70 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1976.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   314.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'huggingfaceh4_zephyr-7b-beta'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+_CONFIGS['model_mapping'][_CONFIGS['model_name']],\n",
    "    name=_CONFIGS['model_name'], \n",
    "    **_CONFIGS['llm']\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    _CONFIGS['model_name'], \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0861913d-350e-4b76-a391-0249866dd0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-12 12:09:39.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36m_load_documents\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mLoad data from existing offline copy.\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:39.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.document_filter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mSetting metadata fuzzy match threshold to: 0.8.\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:39.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mInitialize Query Analyzer.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from my_notion_companion.notion_chatbot import NotionChatBot\n",
    "\n",
    "c = NotionChatBot(llm, tokenizer, '../.config.toml', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89898617-eaa6-4b90-a99e-f158719ef269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-12 12:06:52.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mTry lexical search.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    20 runs   (    0.12 ms per token,  8051.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3315.79 ms /   727 tokens (    4.56 ms per token,   219.25 tokens per second)\n",
      "llama_print_timings:        eval time =     651.32 ms /    19 runs   (   34.28 ms per token,    29.17 tokens per second)\n",
      "llama_print_timings:       total time =    4002.90 ms /   746 tokens\n",
      "\u001b[32m2024-03-12 12:06:56.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mclean_output\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mQuery Analyzer output: 关键词：印第安纳步行者队|搜索范围：无\u001b[0m\n",
      "\u001b[32m2024-03-12 12:06:56.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mparse_output\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\n",
      "Query Analyzer output\n",
      "keyword: ['印第安纳步行者队']\n",
      "search domains:['无']\u001b[0m\n",
      "\u001b[32m2024-03-12 12:06:56.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretriever\u001b[0m:\u001b[36m_filter_documents\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mNo filters found by query analyzer.\u001b[0m\n",
      "\u001b[32m2024-03-12 12:06:57.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1m2 docs found via lexical search. Try semantic search.\u001b[0m\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "\u001b[32m2024-03-12 12:06:57.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1m4 docs found via semantic search. Use LLM to check relevance.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6663.58 ms /  1444 tokens (    4.61 ms per token,   216.70 tokens per second)\n",
      "llama_print_timings:        eval time =     115.29 ms /     3 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
      "llama_print_timings:       total time =    6796.01 ms /  1447 tokens\n",
      "\u001b[32m2024-03-12 12:07:04.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:304a3209df4c44369d273b9f148a0825', 'author': None, 'name': '嘘之默然新纪元版3.33：来自新世界', 'source': '写作', 'tags': '嘘之默然', 'date_start': '20150626', 'date_end': '20150708'}\n",
      "\n",
      "我现在的态度是，只要知晓自己走的道路并非南辕北辙，那么即使遇...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:04.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     4 runs   (    0.15 ms per token,  6504.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4727.75 ms /  1082 tokens (    4.37 ms per token,   228.86 tokens per second)\n",
      "llama_print_timings:        eval time =     116.70 ms /     3 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
      "llama_print_timings:       total time =    4853.07 ms /  1085 tokens\n",
      "\u001b[32m2024-03-12 12:07:09.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:1d3ebb527e294fbb80d5d22805a8407e', 'author': '贾雷德·戴蒙德', 'name': '枪炮、病菌和钢铁', 'source': '笔记（非文学）', 'tags': '历史, 人文', 'date_start': '20170113', 'date_end': None}\n",
      "\n",
      "谷物/禾本科植物+豆类+纤维+根/块茎+瓜类案例研究：橡树没...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:09.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     4 runs   (    0.12 ms per token,  8179.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4024.40 ms /   919 tokens (    4.38 ms per token,   228.36 tokens per second)\n",
      "llama_print_timings:        eval time =     113.49 ms /     3 runs   (   37.83 ms per token,    26.43 tokens per second)\n",
      "llama_print_timings:       total time =    4145.60 ms /   922 tokens\n",
      "\u001b[32m2024-03-12 12:07:13.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:cb44dff9476748258780ade80b8353fc', 'author': None, 'name': '2013-Aug-22 质数的孤独', 'source': '写作', 'tags': '日常记趣', 'date_start': '20130822', 'date_end': '20130822'}\n",
      "\n",
      "而现在，NTU的学生社团竞选又开始了。我看着人人上铺天盖地的...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:13.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     4 runs   (    0.13 ms per token,  7504.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.74 ms /    31 tokens (    6.48 ms per token,   154.43 tokens per second)\n",
      "llama_print_timings:        eval time =     103.09 ms /     3 runs   (   34.36 ms per token,    29.10 tokens per second)\n",
      "llama_print_timings:       total time =     310.76 ms /    34 tokens\n",
      "\u001b[32m2024-03-12 12:07:14.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:95d7374c7a334e8488596a5d377a24c7', 'author': '【清】李渔', 'name': '十二楼 【清】李渔', 'source': '读书笔记（文学）', 'tags': '古文', 'date_start': '20150410', 'date_end': None}\n",
      "\n",
      "《闻过楼》\n",
      "\n",
      "城狐社鼠\n",
      "眠云漱石...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:14.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:14.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mRetrieved relevant docs:\n",
      "\n",
      "{'name': '嘘之默然♯♯♯致死的疾病，然后...', 'tags': '嘘之默然', 'id': '62dd822e-1014-4404-bfb8-668d55f1ca32', 'source': '写作', 'date_start': 20200822, 'date_end': 20201208}\n",
      "\n",
      "大卫·韦斯特是个令人敬佩的竞争者，同时也是，作为詹姆斯球队曾...\n",
      "------------------------------\n",
      "{'author': '【英】赫胥黎', 'tags': '小说', 'name': '美丽新世界 【英】赫胥黎', 'id': '17c7c631-886b-4851-af76-8ae6a98d9dab', 'source': '读书笔记（文学）', 'date_start': 20130928}\n",
      "\n",
      "7.  “如果你让你自己想到上帝，就不会让自己因为风流罪过而...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:07:14.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mInitialize Conversational RAG.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =      15.71 ms /   130 runs   (    0.12 ms per token,  8276.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6476.48 ms /  1481 tokens (    4.37 ms per token,   228.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4885.37 ms /   129 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:       total time =   11586.68 ms /  1610 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '根据提供的资料，我们不能确定是否有关印第安纳步行者队的信息。 文档1 讨论了大卫·韦斯特，但它主要关注他作为竞争者和球员的角色，并没有提及他是否曾经参加过印第安纳步行者队。 请提供更多信息或上下文，以帮助我们确定是否有关印第安纳纳步行者队的信息。'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"印第安纳步行者队\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3c6e07a-41f8-41d0-bf15-f2f6c1eb7eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =      31.80 ms /   256 runs   (    0.12 ms per token,  8050.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.84 ms /    37 tokens (   32.78 ms per token,    30.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10195.24 ms /   255 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:       total time =   11899.18 ms /   292 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '内容：\\n大卫·韦斯特是个令人敬佩的竞争者，同时也是，作为詹姆斯球队曾经的对手，令人厌恶的老油条。 在步行者的时期，他曾经以一手16尺的毫无破绽的中投，强硬的挡拆和护框，加之敏锐的球场嗅觉，搭配当年还算内线一霸的高圆圆，在东决给热火内线造成了巨大打击。 而作为一名狡猾的自由球员，他在油箱里仍有不少货的时候为了划水躺赢总冠军，选择底薪加盟争冠球队，领跑了一代精致利己主义老兵的转会风潮。 你当然可以说他墙头草的做派'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"请原文返回 文档1 的内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66a8c113-3c9b-4962-ae71-ea72bf6a487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-12 12:09:42.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mTry lexical search.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    26 runs   (    0.12 ms per token,  8220.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4285.68 ms /   742 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_print_timings:        eval time =     870.38 ms /    25 runs   (   34.82 ms per token,    28.72 tokens per second)\n",
      "llama_print_timings:       total time =    5210.70 ms /   767 tokens\n",
      "\u001b[32m2024-03-12 12:09:47.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mclean_output\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mQuery Analyzer output: 关键词：在理念之上的日子里梦想着形式|搜索范围：无\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:47.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mparse_output\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\n",
      "Query Analyzer output\n",
      "keyword: ['在理念之上的日子里梦想着形式']\n",
      "search domains:['无']\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:47.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretriever\u001b[0m:\u001b[36m_filter_documents\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mNo filters found by query analyzer.\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mRetrieved relevant docs:\n",
      "\n",
      "{'author': '【英】奥斯卡·王尔德', 'tags': '小说', 'name': '道连·葛雷的画像 【英】奥斯卡·王尔德', 'id': 'c48ca9c6-7932-4fde-987b-6fd2e483d8e4', 'source': '读书笔记（文学）', 'date_start': 20170920}\n",
      "\n",
      "“我讨厌你这样谈你的家庭生活，亨利，”贝泽尔·霍尔渥德一面说...\n",
      "------------------------------\n",
      "{'name': '2017-OCT-22 While { if: break;', 'tags': '日常记趣', 'id': '572ca423-a1c7-4cbd-854e-d2a537024787', 'source': '写作', 'date_start': 20171007, 'date_end': 20171022}\n",
      "\n",
      "有趣的是，随着人类意识到自己在宇宙中的地位越来越不重要，他们...\n",
      "------------------------------\n",
      "{'name': '2024-05-04 婚礼演讲、采访稿', 'tags': '日常记趣', 'id': 'c481b317-3156-40d8-8037-ebc01e83938b', 'source': '写作', 'date_start': 20240225}\n",
      "\n",
      "自我之外与真实生活\n",
      "王尔德说“结婚是想象战胜理智”，这个发言...\n",
      "------------------------------\n",
      "{'author': '【法】加缪', 'tags': '小说', 'name': '鼠疫 【法】加缪', 'id': 'e6f0fccc-9617-4067-b6fa-1ba4e433a864', 'source': '读书笔记（文学）', 'date_start': 20231204}\n",
      "\n",
      "在深渊和顶峰的半中腰，说他们生活不如说他们在飘浮，他们被遗弃...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:48.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mInitialize Conversational RAG.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    32 runs   (    0.13 ms per token,  7799.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11039.90 ms /  2463 tokens (    4.48 ms per token,   223.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.02 ms /    31 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time =   12398.94 ms /  2494 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '这段语句是《道连·葛雷的画像》中出现的，作者是奥斯卡·王尔德。'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"“在理念之上的日子里梦想着形式”是哪本书中的？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eaf1af86-7559-4c6c-aa30-60911e1119c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =      31.10 ms /   256 runs   (    0.12 ms per token,  8232.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.25 ms /    28 tokens (   43.01 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11464.48 ms /   255 runs   (   44.96 ms per token,    22.24 tokens per second)\n",
      "llama_print_timings:       total time =   13188.37 ms /   283 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '文档2:\\n\\n\"有趣的是，随着人类意识到自己在宇宙中的地位越来越不重要，他们的自我感就变得越来越重要。自哥白尼之后，我们从寓居宇宙中心的神的子民最终降级为广漠星空之间的无关紧要尘埃；而人文主义适时教导人们放弃从更高的外部寻求存在感的徒劳，转而从心灵中发掘出不逊于时空的无限。\" (文档2)\\n\\n\"我们谈论的美的时候，我们谈论的是一种形式。以凛然不容侵犯的几何——三角、圆、黄金比——为基础的，对某种隐喻于自然中的绝对法则的临摹和揣测……完美是一'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"请引用相关文档的内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef775ce0-23c9-46e3-bf29-ac3fa02bc532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /   149 runs   (    0.09 ms per token, 11132.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     487.97 ms /    38 tokens (   12.84 ms per token,    77.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6891.15 ms /   148 runs   (   46.56 ms per token,    21.48 tokens per second)\n",
      "llama_print_timings:       total time =    7659.87 ms /   186 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '晋侯、秦伯围郑，以其无礼于晋，且贰于楚也。晋军函陵，秦军氾（fán）南。佚（yì）之狐言于郑伯曰：“国危矣，若使烛之武见秦君，师必退。”公从之。辞曰：“臣之壮也，犹不如人；今老矣，无能为也已。”'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"背诵《烛之武退秦师》前5句话。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06323c7-8216-435b-8fce-0341e140511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /   113 runs   (    0.09 ms per token, 11361.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.72 ms /    23 tokens (   14.55 ms per token,    68.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5277.06 ms /   112 runs   (   47.12 ms per token,    21.22 tokens per second)\n",
      "llama_print_timings:       total time =    5828.31 ms /   135 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '夜缒（zhuì）而出，见秦伯，曰：“秦、晋围郑，郑既知亡矣。若亡郑而有益于君，敢以烦执事。” 这就是后面三句话，来自《左传》的《秦春秋》第二十八章的《烛之武退秦师》。'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"后面三句呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb796c6-963d-4d81-8d9f-dda803efd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    55 runs   (    0.09 ms per token, 11749.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3644.25 ms /   729 tokens (    5.00 ms per token,   200.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2644.11 ms /    54 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:       total time =    6400.61 ms /   783 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '根据提供的文档，我可以看出有四段落来自读书笔记（文学），其中包括《高中古诗文》这个标签下的四篇文章。'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"文档中有多少段落来自读书笔记？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1327a79-b19f-497a-a531-7e91b664f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    43 runs   (    0.09 ms per token, 11518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3164.93 ms /   629 tokens (    5.03 ms per token,   198.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2024.03 ms /    42 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_print_timings:       total time =    5270.71 ms /   671 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '根据提供的文档中的元数据，我可以看出所有四篇文章都创建在2013年8月12日上午。'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"这些文档创建的时间是什么时候？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3015033e-f53f-4d7b-a356-e930340573ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /   103 runs   (    0.09 ms per token, 11468.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2849.59 ms /   559 tokens (    5.10 ms per token,   196.17 tokens per second)\n",
      "llama_print_timings:        eval time =    4917.83 ms /   102 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_print_timings:       total time =    7960.13 ms /   661 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '我是一个智能语言处理模型，我可以帮助您回答您提出的问题并为您提供相应的信息。我不具有身体或者感知能力，我只能通过语言来与您交互。我不能为您完成任何实际操作或者为您提供任何物质帮助，我只能为您提供信息和建议。'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"你是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa94db36-0703-4ba8-a0de-361cc77c992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =      13.75 ms /   158 runs   (    0.09 ms per token, 11487.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2749.28 ms /   522 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7567.45 ms /   157 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_print_timings:       total time =   10623.00 ms /   679 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '如果您是在唱或者引述《孤帆远影》这首歌曲，那么下一句可能是：\"孤帆远影碧空尽，烟雾茫茫中，我只能等待，直到我的心肝荡然去\"。然而，如果您是在引述其他文字或者作品中的这段语句，那么下一句可能会完全不同。请提供更多上下文或者完整的句子，以帮助我更好地理解并回答您的问题。'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"孤帆远影碧空尽下一句是？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
