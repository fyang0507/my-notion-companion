{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687426f4-14b4-4d40-97f9-447ac9baf617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a071a8-cac2-470f-8d96-f73feb1708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078e0401-7050-4f98-b60c-d2bb2d330a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebdc5df-377d-4463-943e-218bd6402c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6ba61d-e198-4ccb-af9d-0ce45515b488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /Users/fred/Documents/models/zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4095.06 MiB, ( 4095.12 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4095.05 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 7168\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   896.00 MiB, ( 4992.69 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =   896.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  896.00 MiB, K (f16):  448.00 MiB, V (f16):  448.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =   104.05 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1976.02 MiB, ( 6968.70 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1976.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   314.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'huggingfaceh4_zephyr-7b-beta'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+_CONFIGS['model_mapping'][_CONFIGS['model_name']],\n",
    "    name=_CONFIGS['model_name'], \n",
    "    **_CONFIGS['llm']\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    _CONFIGS['model_name'], \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3721f3c-219c-4969-bed3-6f576fc6d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "i’m a writer, editor, and teacher. I’ve been writing for as long as I can remember, but it wasn’t until my late twenties that I started taking myself seriously as a writer. Since then, I’ve published poetry, fiction, and nonfiction in various literary journals and magazines, and have had the pleasure of working with some amazing writers as an editor and teacher. My work has appeared in The Rumpus, The Offing, The Normal School, The Collagist, and elsewhere. My chapbook, The Body Is Not an Apology, was published by Dancing Girl Press in 2015. My full-length collection, The Bone Knife, is forthcoming from YesYes Books in 2018.\n",
      "\n",
      "what do you write about?\n",
      "\n",
      "my work explores themes of identity, trauma, resilience, and survival. I am particularly interested in the ways in which our bodies carry our histories and how we learn to navigate the world with those histories in mind. My writing is often informed by my experiences as a survivor of childhood sexual abuse, as well as by my identities as a queer, mixed-r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2143.03 ms\n",
      "llama_print_timings:      sample time =      26.69 ms /   256 runs   (    0.10 ms per token,  9593.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    8419.59 ms /   256 runs   (   32.89 ms per token,    30.41 tokens per second)\n",
      "llama_print_timings:       total time =    8827.71 ms /   257 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ace woman."
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for chunk in llm.stream(\"who are you?\"):\n",
    "    print(chunk, end=\"\")\n",
    "    s += chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da65ccbb-910d-43ca-acb0-f112adfd278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ni’m a writer, editor, and teacher. I’ve been writing for as long as I can remember, but it wasn’t until my late twenties that I started taking myself seriously as a writer. Since then, I’ve published poetry, fiction, and nonfiction in various literary journals and magazines, and have had the pleasure of working with some amazing writers as an editor and teacher. My work has appeared in The Rumpus, The Offing, The Normal School, The Collagist, and elsewhere. My chapbook, The Body Is Not an Apology, was published by Dancing Girl Press in 2015. My full-length collection, The Bone Knife, is forthcoming from YesYes Books in 2018.\\n\\nwhat do you write about?\\n\\nmy work explores themes of identity, trauma, resilience, and survival. I am particularly interested in the ways in which our bodies carry our histories and how we learn to navigate the world with those histories in mind. My writing is often informed by my experiences as a survivor of childhood sexual abuse, as well as by my identities as a queer, mixed-race woman.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba89a2b4-ca19-431a-aabb-4a7956fd7783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2143.03 ms\n",
      "llama_print_timings:      sample time =      26.19 ms /   256 runs   (    0.10 ms per token,  9775.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    8399.27 ms /   256 runs   (   32.81 ms per token,    30.48 tokens per second)\n",
      "llama_print_timings:       total time =    8792.89 ms /   257 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\ni’m a writer, editor, and teacher. I’ve been writing for as long as I can remember, but it wasn’t until my late twenties that I started taking myself seriously as a writer. Since then, I’ve published poetry, fiction, and nonfiction in various literary journals and magazines, and have had the pleasure of working with some amazing writers as an editor and teacher. My work has appeared in The Rumpus, The Offing, The Normal School, The Collagist, and elsewhere. My chapbook, The Body Is Not an Apology, was published by Dancing Girl Press in 2015. My full-length collection, The Bone Knife, is forthcoming from YesYes Books in 2018.\\n\\nwhat do you write about?\\n\\nmy work explores themes of identity, trauma, resilience, and survival. I am particularly interested in the ways in which our bodies carry our histories and how we learn to navigate the world with those histories in mind. My writing is often informed by my experiences as a survivor of childhood sexual abuse, as well as by my identities as a queer, mixed-race woman.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861913d-350e-4b76-a391-0249866dd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_notion_companion.notion_chatbot import NotionChatBot\n",
    "\n",
    "c = NotionChatBot(llm, tokenizer, '../.config.toml', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05185a43-aab9-4889-9c17-36ed836ec3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-12 16:07:21.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mTry lexical search.\u001b[0m\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    24 runs   (    0.09 ms per token, 10894.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6418.60 ms /   759 tokens (    8.46 ms per token,   118.25 tokens per second)\n",
      "llama_print_timings:        eval time =     800.97 ms /    23 runs   (   34.82 ms per token,    28.72 tokens per second)\n",
      "llama_print_timings:       total time =    7272.57 ms /   782 tokens\n",
      "\u001b[32m2024-03-12 16:07:28.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mclean_output\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mQuery Analyzer output: 关键词：谁曾在步行者队效力|搜索范围：写作\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:28.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mparse_output\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\n",
      "Query Analyzer output\n",
      "keyword: ['谁曾在步行者队效力']\n",
      "search domains:['写作']\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:28.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretriever\u001b[0m:\u001b[36m_filter_documents\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mfilter found by query analyzer: ['写作']\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:28.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.document_filter\u001b[0m:\u001b[36mfilter_multiple_criteria\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mRemaining doc:  0.306\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:29.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m1 docs found via lexical search. Try semantic search.\u001b[0m\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "\u001b[32m2024-03-12 16:07:29.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1m4 docs found via semantic search. Use LLM to check relevance.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     4 runs   (    0.11 ms per token,  8714.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3557.03 ms /   769 tokens (    4.63 ms per token,   216.19 tokens per second)\n",
      "llama_print_timings:        eval time =     110.78 ms /     3 runs   (   36.93 ms per token,    27.08 tokens per second)\n",
      "llama_print_timings:       total time =    3685.91 ms /   772 tokens\n",
      "\u001b[32m2024-03-12 16:07:33.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:817e455c4d4446fbb35e5395b333db76', 'author': None, 'name': '2017-MAY-01 巡礼之年 - 瑞士', 'source': '写作', 'tags': '日常记趣, 游记', 'date_start': '20170501', 'date_end': '20170501'}\n",
      "\n",
      "（原本是 北京 出版集团某个旅行图书编辑的约稿，不过后来也不...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:33.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     4 runs   (    0.12 ms per token,  8695.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4918.17 ms /  1116 tokens (    4.41 ms per token,   226.91 tokens per second)\n",
      "llama_print_timings:        eval time =     116.42 ms /     3 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
      "llama_print_timings:       total time =    5043.05 ms /  1119 tokens\n",
      "\u001b[32m2024-03-12 16:07:38.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:4c708d0ceaa749a383e20d675c465729', 'author': '【美】约瑟夫·海勒', 'name': '第二十二条军规 【美】约瑟夫·海勒', 'source': '读书笔记（文学）', 'tags': '小说', 'date_start': '20140204', 'date_end': None}\n",
      "\n",
      "“什么时候，长官？”\n",
      "“我在问你。你回答。”\n",
      "“是，长官。我...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:38.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    64 runs   (    0.11 ms per token,  9124.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4316.31 ms /   964 tokens (    4.48 ms per token,   223.34 tokens per second)\n",
      "llama_print_timings:        eval time =    2429.73 ms /    63 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
      "llama_print_timings:       total time =    6855.14 ms /  1027 tokens\n",
      "\u001b[32m2024-03-12 16:07:45.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:491947c812c741ba94795561f0d89aba', 'author': None, 'name': '嘘之默然新纪元版3.33：来自新世界', 'source': '写作', 'tags': '嘘之默然', 'date_start': '20150626', 'date_end': '20150708'}\n",
      "\n",
      "我并非无端举出这两种人的故事。我希望，从这两种对待生活的态度...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:45.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 相关，因为讨论了两种人的态度和行为，并且提供了旅行和计划的比喻，可以帮助我们学习如何生存和处理生活中的困难和变化。\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     4 runs   (    0.12 ms per token,  8403.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2533.64 ms /   575 tokens (    4.41 ms per token,   226.95 tokens per second)\n",
      "llama_print_timings:        eval time =     109.70 ms /     3 runs   (   36.57 ms per token,    27.35 tokens per second)\n",
      "llama_print_timings:       total time =    2650.73 ms /   578 tokens\n",
      "\u001b[32m2024-03-12 16:07:47.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mcompare relevance with doc:\n",
      "\n",
      "{'id': 'doc:notiondb:3a1eb995135e41d792e321e392f71ba6', 'author': '【日】三岛由纪夫', 'name': '假面自白 【日】三岛由纪夫', 'source': '读书笔记（文学）', 'tags': '小说', 'date_start': '20160324', 'date_end': None}\n",
      "\n",
      "这时候，不知家里的大人是否直感到乍看是像往常一样迂回游行的这...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:47.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdocument_match_checker\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mconclusion: 不相关\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:47.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mRetrieved relevant docs:\n",
      "\n",
      "{'name': '嘘之默然♯♯♯致死的疾病，然后...', 'tags': '嘘之默然', 'id': '62dd822e-1014-4404-bfb8-668d55f1ca32', 'source': '写作', 'date_start': 20200822, 'date_end': 20201208}\n",
      "\n",
      "大卫·韦斯特是个令人敬佩的竞争者，同时也是，作为詹姆斯球队曾...\n",
      "------------------------------\n",
      "{'id': 'doc:notiondb:491947c812c741ba94795561f0d89aba', 'author': None, 'name': '嘘之默然新纪元版3.33：来自新世界', 'source': '写作', 'tags': '嘘之默然', 'date_start': '20150626', 'date_end': '20150708'}\n",
      "\n",
      "我并非无端举出这两种人的故事。我希望，从这两种对待生活的态度...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 16:07:47.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mInitialize Conversational RAG.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6420.13 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    94 runs   (    0.09 ms per token, 11311.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8803.19 ms /  1937 tokens (    4.54 ms per token,   220.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3735.70 ms /    93 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =   12719.89 ms /  2030 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '文档1 提到了大卫·韦斯特曾经在步行者队效力，他以一手16尺的毫无破绽的中投、强硬的挡拆和护框、加之敏锐的球场嗅觉、同时还有高圆圆在东决给热火内线造成了巨大打击。'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"谁曾在步行者队效力？从“写作”中找答案。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c6e07a-41f8-41d0-bf15-f2f6c1eb7eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8851.30 ms\n",
      "llama_print_timings:      sample time =      22.57 ms /   256 runs   (    0.09 ms per token, 11340.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     498.14 ms /    29 tokens (   17.18 ms per token,    58.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10793.14 ms /   255 runs   (   42.33 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time =   11786.71 ms /   284 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '\"David West, umiżony wielki rywal, jest również byłym przeciwnikiem, który jest równie nienawidzony w postaci olbrzymiej rąk o wysokości 16 stóp, twardej obrony i ochrony krawędzi, a także z wysoką świadomością boiska, wszystko to podczas gdy współpracował z High Cheekbones w czasach kiedy był chodziakiem. Podczas jego chodziakowskich dni, on razem z jednoręczą, nieprzykrywą średnią wyrzucił kopnięką jednoręczą o wysokości 16 stóp, twardej obrony i ochrony krawędzi, a także z wysoką świadomością boiska, wszystko to podczas gdy współpracował z High Cheekbones w czasach kiedy był chodziakiem. Ale jako właściwy wolny'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"请原文复述文档1的内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66a8c113-3c9b-4962-ae71-ea72bf6a487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-12 12:09:42.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mTry lexical search.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    26 runs   (    0.12 ms per token,  8220.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4285.68 ms /   742 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_print_timings:        eval time =     870.38 ms /    25 runs   (   34.82 ms per token,    28.72 tokens per second)\n",
      "llama_print_timings:       total time =    5210.70 ms /   767 tokens\n",
      "\u001b[32m2024-03-12 12:09:47.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mclean_output\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mQuery Analyzer output: 关键词：在理念之上的日子里梦想着形式|搜索范围：无\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:47.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.query_analyzer\u001b[0m:\u001b[36mparse_output\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\n",
      "Query Analyzer output\n",
      "keyword: ['在理念之上的日子里梦想着形式']\n",
      "search domains:['无']\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:47.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretriever\u001b[0m:\u001b[36m_filter_documents\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mNo filters found by query analyzer.\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mRetrieved relevant docs:\n",
      "\n",
      "{'author': '【英】奥斯卡·王尔德', 'tags': '小说', 'name': '道连·葛雷的画像 【英】奥斯卡·王尔德', 'id': 'c48ca9c6-7932-4fde-987b-6fd2e483d8e4', 'source': '读书笔记（文学）', 'date_start': 20170920}\n",
      "\n",
      "“我讨厌你这样谈你的家庭生活，亨利，”贝泽尔·霍尔渥德一面说...\n",
      "------------------------------\n",
      "{'name': '2017-OCT-22 While { if: break;', 'tags': '日常记趣', 'id': '572ca423-a1c7-4cbd-854e-d2a537024787', 'source': '写作', 'date_start': 20171007, 'date_end': 20171022}\n",
      "\n",
      "有趣的是，随着人类意识到自己在宇宙中的地位越来越不重要，他们...\n",
      "------------------------------\n",
      "{'name': '2024-05-04 婚礼演讲、采访稿', 'tags': '日常记趣', 'id': 'c481b317-3156-40d8-8037-ebc01e83938b', 'source': '写作', 'date_start': 20240225}\n",
      "\n",
      "自我之外与真实生活\n",
      "王尔德说“结婚是想象战胜理智”，这个发言...\n",
      "------------------------------\n",
      "{'author': '【法】加缪', 'tags': '小说', 'name': '鼠疫 【法】加缪', 'id': 'e6f0fccc-9617-4067-b6fa-1ba4e433a864', 'source': '读书笔记（文学）', 'date_start': 20231204}\n",
      "\n",
      "在深渊和顶峰的半中腰，说他们生活不如说他们在飘浮，他们被遗弃...\n",
      "------------------------------\n",
      "\u001b[0m\n",
      "\u001b[32m2024-03-12 12:09:48.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmy_notion_companion.notion_chatbot\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mInitialize Conversational RAG.\u001b[0m\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    32 runs   (    0.13 ms per token,  7799.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11039.90 ms /  2463 tokens (    4.48 ms per token,   223.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.02 ms /    31 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time =   12398.94 ms /  2494 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '这段语句是《道连·葛雷的画像》中出现的，作者是奥斯卡·王尔德。'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"“在理念之上的日子里梦想着形式”是哪本书中的？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eaf1af86-7559-4c6c-aa30-60911e1119c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6560.91 ms\n",
      "llama_print_timings:      sample time =      31.10 ms /   256 runs   (    0.12 ms per token,  8232.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1204.25 ms /    28 tokens (   43.01 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11464.48 ms /   255 runs   (   44.96 ms per token,    22.24 tokens per second)\n",
      "llama_print_timings:       total time =   13188.37 ms /   283 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '文档2:\\n\\n\"有趣的是，随着人类意识到自己在宇宙中的地位越来越不重要，他们的自我感就变得越来越重要。自哥白尼之后，我们从寓居宇宙中心的神的子民最终降级为广漠星空之间的无关紧要尘埃；而人文主义适时教导人们放弃从更高的外部寻求存在感的徒劳，转而从心灵中发掘出不逊于时空的无限。\" (文档2)\\n\\n\"我们谈论的美的时候，我们谈论的是一种形式。以凛然不容侵犯的几何——三角、圆、黄金比——为基础的，对某种隐喻于自然中的绝对法则的临摹和揣测……完美是一'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"请引用相关文档的内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef775ce0-23c9-46e3-bf29-ac3fa02bc532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /   149 runs   (    0.09 ms per token, 11132.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     487.97 ms /    38 tokens (   12.84 ms per token,    77.87 tokens per second)\n",
      "llama_print_timings:        eval time =    6891.15 ms /   148 runs   (   46.56 ms per token,    21.48 tokens per second)\n",
      "llama_print_timings:       total time =    7659.87 ms /   186 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '晋侯、秦伯围郑，以其无礼于晋，且贰于楚也。晋军函陵，秦军氾（fán）南。佚（yì）之狐言于郑伯曰：“国危矣，若使烛之武见秦君，师必退。”公从之。辞曰：“臣之壮也，犹不如人；今老矣，无能为也已。”'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"背诵《烛之武退秦师》前5句话。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06323c7-8216-435b-8fce-0341e140511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /   113 runs   (    0.09 ms per token, 11361.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.72 ms /    23 tokens (   14.55 ms per token,    68.71 tokens per second)\n",
      "llama_print_timings:        eval time =    5277.06 ms /   112 runs   (   47.12 ms per token,    21.22 tokens per second)\n",
      "llama_print_timings:       total time =    5828.31 ms /   135 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '夜缒（zhuì）而出，见秦伯，曰：“秦、晋围郑，郑既知亡矣。若亡郑而有益于君，敢以烦执事。” 这就是后面三句话，来自《左传》的《秦春秋》第二十八章的《烛之武退秦师》。'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"后面三句呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb796c6-963d-4d81-8d9f-dda803efd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    55 runs   (    0.09 ms per token, 11749.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3644.25 ms /   729 tokens (    5.00 ms per token,   200.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2644.11 ms /    54 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:       total time =    6400.61 ms /   783 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '根据提供的文档，我可以看出有四段落来自读书笔记（文学），其中包括《高中古诗文》这个标签下的四篇文章。'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"文档中有多少段落来自读书笔记？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1327a79-b19f-497a-a531-7e91b664f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    43 runs   (    0.09 ms per token, 11518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3164.93 ms /   629 tokens (    5.03 ms per token,   198.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2024.03 ms /    42 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_print_timings:       total time =    5270.71 ms /   671 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '根据提供的文档中的元数据，我可以看出所有四篇文章都创建在2013年8月12日上午。'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"这些文档创建的时间是什么时候？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3015033e-f53f-4d7b-a356-e930340573ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /   103 runs   (    0.09 ms per token, 11468.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2849.59 ms /   559 tokens (    5.10 ms per token,   196.17 tokens per second)\n",
      "llama_print_timings:        eval time =    4917.83 ms /   102 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_print_timings:       total time =    7960.13 ms /   661 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '我是一个智能语言处理模型，我可以帮助您回答您提出的问题并为您提供相应的信息。我不具有身体或者感知能力，我只能通过语言来与您交互。我不能为您完成任何实际操作或者为您提供任何物质帮助，我只能为您提供信息和建议。'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"你是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa94db36-0703-4ba8-a0de-361cc77c992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9497.49 ms\n",
      "llama_print_timings:      sample time =      13.75 ms /   158 runs   (    0.09 ms per token, 11487.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2749.28 ms /   522 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7567.45 ms /   157 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_print_timings:       total time =   10623.00 ms /   679 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '如果您是在唱或者引述《孤帆远影》这首歌曲，那么下一句可能是：\"孤帆远影碧空尽，烟雾茫茫中，我只能等待，直到我的心肝荡然去\"。然而，如果您是在引述其他文字或者作品中的这段语句，那么下一句可能会完全不同。请提供更多上下文或者完整的句子，以帮助我更好地理解并回答您的问题。'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.invoke(\"孤帆远影碧空尽下一句是？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
