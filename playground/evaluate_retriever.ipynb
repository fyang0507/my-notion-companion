{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccf3a26-c0f0-4830-bcc3-dc50a316d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54e41e7-6407-4634-aa05-4c82342d8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4419f65f-7af1-4010-8fe4-f9f78b594247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_test_cases\n",
    "from my_notion_companion.retriever import SelfQueryAgent, BasicRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e3932c-0c14-4e6f-8f16-1a664d915c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 387 tensors from /Users/fred/Documents/models/qwen1_5-7b-chat-q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Qwen1.5-7B-Chat-AWQ-fp16\n",
      "llama_model_loader: - kv   2:                          qwen2.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     qwen2.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  qwen2.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 qwen2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              qwen2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv   9:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  10:                qwen2.use_parallel_residual bool             = true\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  13:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  16:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  18:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 2\n",
      "llama_model_loader: - type  f32:  161 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 293/151936 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 7.72 B\n",
      "llm_load_print_meta: model size       = 4.20 GiB (4.67 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen1.5-7B-Chat-AWQ-fp16\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 'ÄĬ'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  3963.36 MiB, ( 3963.42 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4297.21 MiB\n",
      "llm_load_tensors:      Metal buffer size =  3963.36 MiB\n",
      "...................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  2048.00 MiB, ( 6012.98 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  2048.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    80.04 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1120.02 MiB, ( 7133.00 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1120.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1251.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.file_type': '2', 'general.quantization_version': '2', 'tokenizer.chat_template': \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.bos_token_id': '151643', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151645', 'tokenizer.ggml.model': 'gpt2', 'qwen2.use_parallel_residual': 'true', 'qwen2.rope.freq_base': '1000000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'qwen2.embedding_length': '4096', 'qwen2.attention.head_count_kv': '32', 'qwen2.context_length': '32768', 'qwen2.attention.head_count': '32', 'general.architecture': 'qwen2', 'qwen2.block_count': '32', 'qwen2.feed_forward_length': '11008', 'general.name': 'Qwen1.5-7B-Chat-AWQ-fp16'}\n",
      "Guessed chat format: chatml\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)\n",
    "\n",
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+_CONFIGS['model_mapping'][_CONFIGS['model_name']],\n",
    "    name=_CONFIGS['model_name'], \n",
    "    **_CONFIGS['llm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b276b2-8e7e-442b-b555-ea80adf5cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q': '什么是我国第一部编年史著作？', 'a': '《左传》。', 'docs': ['附：《左传》是我国第一部编年史著作。\\n']},\n",
       " {'q': '什么是我国第一部编年国别史？', 'a': '《国语》。', 'docs': ['附：《国语》是我国第一部编年国别史。\\n']},\n",
       " {'q': '“寡人之于国也”下一句是什么？来自哪里？',\n",
       "  'a': '“寡人之于国也”下一句是“尽心焉耳矣”。这个句子来自《孟子》。',\n",
       "  'docs': ['梁惠王曰：“寡人之于国也，尽心焉耳矣。河内凶，则移其民于河东，移其粟于河内；河东凶亦然。察邻国之政，无如寡人之用心者。邻国之民不加少，寡人之民不加多，何也？”',\n",
       "   '《寡人之于国也》（孟子）\\n']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases = load_test_cases('../data/test_cases.txt')\n",
    "test_cases[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a024effd-47ca-48b9-b207-c6d0a7e08a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6d5b25-9140-4510-b48e-3f216881c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def match_chinese(string_to_match, docs):\n",
    "    # find all chinese characters\n",
    "    # ref: https://stackoverflow.com/questions/2718196/find-all-chinese-text-in-a-string-using-python-and-regex\n",
    "    for tokens in re.findall(r'[\\u4e00-\\u9fff]+', string_to_match):\n",
    "        return any([tokens in x.page_content for x in docs])\n",
    "\n",
    "def evaluate_retriever(test_cases, retriever):\n",
    "    score_list = list()\n",
    "\n",
    "    for case in tqdm(test_cases):\n",
    "        docs_retrieved = retriever.invoke(case['q'])\n",
    "        contains_all_ref = list()\n",
    "        for ref in case['docs']:\n",
    "            contains_all_ref.append(match_chinese(ref, docs_retrieved))\n",
    "            \n",
    "        \n",
    "        score_list.extend(contains_all_ref)\n",
    "\n",
    "    return sum(score_list)/len(score_list), score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e9f309-a4b3-4248-884c-d258b1d4f9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 0/37 [00:00<?, ?it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "  5%|█████▎                                                                                             | 2/37 [00:00<00:02, 12.74it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 11%|██████████▋                                                                                        | 4/37 [00:00<00:02, 12.20it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 16%|████████████████                                                                                   | 6/37 [00:00<00:02, 11.64it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 22%|█████████████████████▍                                                                             | 8/37 [00:00<00:02, 11.69it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 27%|██████████████████████████▍                                                                       | 10/37 [00:00<00:02, 12.01it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 32%|███████████████████████████████▊                                                                  | 12/37 [00:00<00:02, 12.11it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 38%|█████████████████████████████████████                                                             | 14/37 [00:01<00:01, 11.88it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 43%|██████████████████████████████████████████▍                                                       | 16/37 [00:01<00:01, 11.20it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 49%|███████████████████████████████████████████████▋                                                  | 18/37 [00:01<00:01, 11.11it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 54%|████████████████████████████████████████████████████▉                                             | 20/37 [00:01<00:01, 11.13it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 59%|██████████████████████████████████████████████████████████▎                                       | 22/37 [00:01<00:01, 11.15it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key tags not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_start not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 65%|███████████████████████████████████████████████████████████████▌                                  | 24/37 [00:02<00:01, 10.83it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 70%|████████████████████████████████████████████████████████████████████▊                             | 26/37 [00:02<00:00, 11.08it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 76%|██████████████████████████████████████████████████████████████████████████▏                       | 28/37 [00:02<00:00, 11.24it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████▍                  | 30/37 [00:02<00:00, 11.28it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████▊             | 32/37 [00:02<00:00, 11.22it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████        | 34/37 [00:02<00:00, 11.23it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████▎  | 36/37 [00:03<00:00, 11.43it/s]score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:03<00:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 109 ms, total: 1.13 s\n",
      "Wall time: 3.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# only retriever\n",
    "stats, score_list = evaluate_retriever(test_cases,  BasicRetriever(_CONFIGS, _TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730781a6-9063-4e40-a130-b318a2fc3b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1836734693877551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f390ee-4944-451a-b3d6-02eba28acb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from my_notion_companion.query_constructor import QueryConstructor\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qc = QueryConstructor(llm, _CONFIGS)\n",
    "b = BasicRetriever(_CONFIGS, _TOKENS)\n",
    "\n",
    "retriever_plus = RunnableLambda(qc.invoke) | RunnableLambda(b.invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a217dc-afc4-411c-b14e-b49e895ddf46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 0/37 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      11.42 ms /    32 runs   (    0.36 ms per token,  2803.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     409.05 ms /    24 tokens (   17.04 ms per token,    58.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1039.13 ms /    31 runs   (   33.52 ms per token,    29.83 tokens per second)\n",
      "llama_print_timings:       total time =    1647.75 ms /    55 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "  3%|██▋                                                                                                | 1/37 [00:01<01:05,  1.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      22.47 ms /    64 runs   (    0.35 ms per token,  2848.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     309.83 ms /    25 tokens (   12.39 ms per token,    80.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2099.98 ms /    63 runs   (   33.33 ms per token,    30.00 tokens per second)\n",
      "llama_print_timings:       total time =    2809.67 ms /    88 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "  5%|█████▎                                                                                             | 2/37 [00:34<11:33, 19.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      14.80 ms /    40 runs   (    0.37 ms per token,  2701.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     497.37 ms /    31 tokens (   16.04 ms per token,    62.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1307.60 ms /    39 runs   (   33.53 ms per token,    29.83 tokens per second)\n",
      "llama_print_timings:       total time =    2050.74 ms /    70 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "  8%|████████                                                                                           | 3/37 [00:36<06:40, 11.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    12 runs   (    0.37 ms per token,  2721.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.85 ms /    36 tokens (   18.36 ms per token,    54.48 tokens per second)\n",
      "llama_print_timings:        eval time =     380.78 ms /    11 runs   (   34.62 ms per token,    28.89 tokens per second)\n",
      "llama_print_timings:       total time =    1115.62 ms /    47 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 11%|██████████▋                                                                                        | 4/37 [00:37<04:12,  7.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     7 runs   (    0.35 ms per token,  2873.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     460.74 ms /    33 tokens (   13.96 ms per token,    71.62 tokens per second)\n",
      "llama_print_timings:        eval time =     214.56 ms /     6 runs   (   35.76 ms per token,    27.96 tokens per second)\n",
      "llama_print_timings:       total time =     719.82 ms /    39 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 14%|█████████████▍                                                                                     | 5/37 [00:38<02:46,  5.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      27.71 ms /    79 runs   (    0.35 ms per token,  2851.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     426.43 ms /    45 tokens (    9.48 ms per token,   105.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2674.53 ms /    78 runs   (   34.29 ms per token,    29.16 tokens per second)\n",
      "llama_print_timings:       total time =    3588.99 ms /   123 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 16%|████████████████                                                                                   | 6/37 [00:42<02:25,  4.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      31.64 ms /    89 runs   (    0.36 ms per token,  2812.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.43 ms /    24 tokens (   12.31 ms per token,    81.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3003.98 ms /    88 runs   (   34.14 ms per token,    29.29 tokens per second)\n",
      "llama_print_timings:       total time =    3847.06 ms /   112 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 19%|██████████████████▋                                                                                | 7/37 [00:46<02:13,  4.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     7 runs   (    0.35 ms per token,  2816.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     314.32 ms /    28 tokens (   11.23 ms per token,    89.08 tokens per second)\n",
      "llama_print_timings:        eval time =     203.85 ms /     6 runs   (   33.98 ms per token,    29.43 tokens per second)\n",
      "llama_print_timings:       total time =     561.65 ms /    34 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 22%|█████████████████████▍                                                                             | 8/37 [00:47<01:34,  3.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     8 runs   (    0.35 ms per token,  2846.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.00 ms /    29 tokens (   11.38 ms per token,    87.88 tokens per second)\n",
      "llama_print_timings:        eval time =     249.51 ms /     7 runs   (   35.64 ms per token,    28.05 tokens per second)\n",
      "llama_print_timings:       total time =     631.19 ms /    36 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 24%|████████████████████████                                                                           | 9/37 [00:47<01:09,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    19 runs   (    0.36 ms per token,  2799.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     307.93 ms /    26 tokens (   11.84 ms per token,    84.43 tokens per second)\n",
      "llama_print_timings:        eval time =     625.98 ms /    18 runs   (   34.78 ms per token,    28.75 tokens per second)\n",
      "llama_print_timings:       total time =    1052.10 ms /    44 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 27%|██████████████████████████▍                                                                       | 10/37 [00:48<00:56,  2.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    12 runs   (    0.35 ms per token,  2882.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     449.59 ms /    36 tokens (   12.49 ms per token,    80.07 tokens per second)\n",
      "llama_print_timings:        eval time =     381.49 ms /    11 runs   (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_print_timings:       total time =     908.31 ms /    47 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 30%|█████████████████████████████▏                                                                    | 11/37 [00:50<00:46,  1.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      22.14 ms /    63 runs   (    0.35 ms per token,  2845.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.65 ms /    34 tokens (   13.64 ms per token,    73.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2156.08 ms /    62 runs   (   34.78 ms per token,    28.76 tokens per second)\n",
      "llama_print_timings:       total time =    3016.13 ms /    96 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 32%|███████████████████████████████▊                                                                  | 12/37 [00:53<00:54,  2.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     5 runs   (    0.35 ms per token,  2821.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     315.74 ms /    28 tokens (   11.28 ms per token,    88.68 tokens per second)\n",
      "llama_print_timings:        eval time =     148.34 ms /     4 runs   (   37.09 ms per token,    26.96 tokens per second)\n",
      "llama_print_timings:       total time =     497.26 ms /    32 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 35%|██████████████████████████████████▍                                                               | 13/37 [00:53<00:41,  1.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     6 runs   (    0.34 ms per token,  2918.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.61 ms /    40 tokens (   10.72 ms per token,    93.33 tokens per second)\n",
      "llama_print_timings:        eval time =     177.52 ms /     5 runs   (   35.50 ms per token,    28.17 tokens per second)\n",
      "llama_print_timings:       total time =     643.01 ms /    45 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 38%|█████████████████████████████████████                                                             | 14/37 [00:54<00:32,  1.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    18 runs   (    0.36 ms per token,  2795.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     469.29 ms /    40 tokens (   11.73 ms per token,    85.24 tokens per second)\n",
      "llama_print_timings:        eval time =     600.45 ms /    17 runs   (   35.32 ms per token,    28.31 tokens per second)\n",
      "llama_print_timings:       total time =    1183.17 ms /    57 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 41%|███████████████████████████████████████▋                                                          | 15/37 [00:55<00:30,  1.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    27 runs   (    0.36 ms per token,  2757.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     445.13 ms /    43 tokens (   10.35 ms per token,    96.60 tokens per second)\n",
      "llama_print_timings:        eval time =     920.01 ms /    26 runs   (   35.39 ms per token,    28.26 tokens per second)\n",
      "llama_print_timings:       total time =    1533.89 ms /    69 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 43%|██████████████████████████████████████████▍                                                       | 16/37 [00:57<00:31,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /    57 runs   (    0.34 ms per token,  2908.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     471.34 ms /    46 tokens (   10.25 ms per token,    97.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1988.50 ms /    56 runs   (   35.51 ms per token,    28.16 tokens per second)\n",
      "llama_print_timings:       total time =    2817.18 ms /   102 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 46%|█████████████████████████████████████████████                                                     | 17/37 [01:00<00:38,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      25.83 ms /    74 runs   (    0.35 ms per token,  2865.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     445.32 ms /    47 tokens (    9.47 ms per token,   105.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2598.12 ms /    73 runs   (   35.59 ms per token,    28.10 tokens per second)\n",
      "llama_print_timings:       total time =    3507.15 ms /   120 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 49%|███████████████████████████████████████████████▋                                                  | 18/37 [01:04<00:46,  2.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     5 runs   (    0.36 ms per token,  2759.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.12 ms /    28 tokens (   11.50 ms per token,    86.92 tokens per second)\n",
      "llama_print_timings:        eval time =     143.24 ms /     4 runs   (   35.81 ms per token,    27.93 tokens per second)\n",
      "llama_print_timings:       total time =     497.13 ms /    32 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 51%|██████████████████████████████████████████████████▎                                               | 19/37 [01:04<00:34,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      16.47 ms /    46 runs   (    0.36 ms per token,  2792.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.84 ms /    41 tokens (   10.36 ms per token,    96.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1622.42 ms /    45 runs   (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_print_timings:       total time =    2335.57 ms /    86 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 54%|████████████████████████████████████████████████████▉                                             | 20/37 [01:07<00:35,  2.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     7 runs   (    0.37 ms per token,  2708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     314.97 ms /    27 tokens (   11.67 ms per token,    85.72 tokens per second)\n",
      "llama_print_timings:        eval time =     217.77 ms /     6 runs   (   36.29 ms per token,    27.55 tokens per second)\n",
      "llama_print_timings:       total time =     577.47 ms /    33 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 57%|███████████████████████████████████████████████████████▌                                          | 21/37 [01:08<00:26,  1.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    11 runs   (    0.36 ms per token,  2749.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     468.51 ms /    33 tokens (   14.20 ms per token,    70.44 tokens per second)\n",
      "llama_print_timings:        eval time =     364.72 ms /    10 runs   (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_print_timings:       total time =     903.15 ms /    43 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 59%|██████████████████████████████████████████████████████████▎                                       | 22/37 [01:09<00:22,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     7 runs   (    0.36 ms per token,  2803.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.97 ms /    29 tokens (   11.24 ms per token,    88.96 tokens per second)\n",
      "llama_print_timings:        eval time =     229.66 ms /     6 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
      "llama_print_timings:       total time =     601.69 ms /    35 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 62%|████████████████████████████████████████████████████████████▉                                     | 23/37 [01:09<00:17,  1.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     6 runs   (    0.38 ms per token,  2623.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.45 ms /    25 tokens (   12.14 ms per token,    82.39 tokens per second)\n",
      "llama_print_timings:        eval time =     191.21 ms /     5 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
      "llama_print_timings:       total time =     535.01 ms /    30 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key tags not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_start not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 65%|███████████████████████████████████████████████████████████████▌                                  | 24/37 [01:10<00:14,  1.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      34.95 ms /    99 runs   (    0.35 ms per token,  2832.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     338.72 ms /    31 tokens (   10.93 ms per token,    91.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3589.42 ms /    98 runs   (   36.63 ms per token,    27.30 tokens per second)\n",
      "llama_print_timings:       total time =    4554.13 ms /   129 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 68%|██████████████████████████████████████████████████████████████████▏                               | 25/37 [01:15<00:26,  2.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    41 runs   (    0.36 ms per token,  2791.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     305.45 ms /    26 tokens (   11.75 ms per token,    85.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.40 ms /    40 runs   (   36.51 ms per token,    27.39 tokens per second)\n",
      "llama_print_timings:       total time =    2022.22 ms /    66 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 70%|████████████████████████████████████████████████████████████████████▊                             | 26/37 [01:17<00:23,  2.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      18.57 ms /    52 runs   (    0.36 ms per token,  2799.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.85 ms /    33 tokens (   14.06 ms per token,    71.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1875.92 ms /    51 runs   (   36.78 ms per token,    27.19 tokens per second)\n",
      "llama_print_timings:       total time =    2665.40 ms /    84 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 73%|███████████████████████████████████████████████████████████████████████▌                          | 27/37 [01:20<00:23,  2.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     9 runs   (    0.35 ms per token,  2892.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.17 ms /    31 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =     292.09 ms /     8 runs   (   36.51 ms per token,    27.39 tokens per second)\n",
      "llama_print_timings:       total time =     685.27 ms /    39 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 76%|██████████████████████████████████████████████████████████████████████████▏                       | 28/37 [01:21<00:17,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      23.00 ms /    65 runs   (    0.35 ms per token,  2826.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     470.03 ms /    41 tokens (   11.46 ms per token,    87.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2381.08 ms /    64 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_print_timings:       total time =    3258.03 ms /   105 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 78%|████████████████████████████████████████████████████████████████████████████▊                     | 29/37 [01:24<00:18,  2.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      14.35 ms /    41 runs   (    0.35 ms per token,  2858.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     348.97 ms /    32 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1490.55 ms /    40 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =    2094.23 ms /    72 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████▍                  | 30/37 [01:26<00:16,  2.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      55.37 ms /   163 runs   (    0.34 ms per token,  2944.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.73 ms /    30 tokens (   11.26 ms per token,    88.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6076.34 ms /   162 runs   (   37.51 ms per token,    26.66 tokens per second)\n",
      "llama_print_timings:       total time =    7453.27 ms /   192 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 84%|██████████████████████████████████████████████████████████████████████████████████                | 31/37 [01:34<00:23,  3.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      29.53 ms /    85 runs   (    0.35 ms per token,  2878.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     545.38 ms /    35 tokens (   15.58 ms per token,    64.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3151.54 ms /    84 runs   (   37.52 ms per token,    26.65 tokens per second)\n",
      "llama_print_timings:       total time =    4226.71 ms /   119 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████▊             | 32/37 [01:38<00:20,  4.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    50 runs   (    0.35 ms per token,  2864.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     313.57 ms /    27 tokens (   11.61 ms per token,    86.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1848.10 ms /    49 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
      "llama_print_timings:       total time =    2470.12 ms /    76 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████▍          | 33/37 [01:41<00:14,  3.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      19.43 ms /    56 runs   (    0.35 ms per token,  2882.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     314.28 ms /    25 tokens (   12.57 ms per token,    79.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2074.46 ms /    55 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
      "llama_print_timings:       total time =    2734.42 ms /    80 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████        | 34/37 [01:44<00:10,  3.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      18.71 ms /    54 runs   (    0.35 ms per token,  2886.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     438.82 ms /    45 tokens (    9.75 ms per token,   102.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2002.09 ms /    53 runs   (   37.78 ms per token,    26.47 tokens per second)\n",
      "llama_print_timings:       total time =    2779.32 ms /    98 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████▋     | 35/37 [01:47<00:06,  3.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    49 runs   (    0.35 ms per token,  2841.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     458.89 ms /    45 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1813.08 ms /    48 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
      "llama_print_timings:       total time =    2579.97 ms /    93 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████▎  | 36/37 [01:50<00:03,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      46.33 ms /   133 runs   (    0.35 ms per token,  2870.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     444.77 ms /    37 tokens (   12.02 ms per token,    83.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5055.60 ms /   132 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
      "llama_print_timings:       total time =    6338.55 ms /   169 tokens\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [01:57<00:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 2.66 s, total: 1min 31s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with query constructor + basic retriever\n",
    "stats, score_list = evaluate_retriever(test_cases, retriever_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d15b510-0c8c-40bd-9664-2c4d6faf07db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20408163265306123"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5cb0a36-373a-461f-a385-5e4f52027467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.75 ms /   256 runs   (    0.36 ms per token,  2790.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8354.64 ms /  1134 tokens (    7.37 ms per token,   135.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12966.16 ms /   255 runs   (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:       total time =   23012.52 ms /  1389 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.92 ms /   256 runs   (    0.37 ms per token,  2697.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1999.07 ms /   298 tokens (    6.71 ms per token,   149.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10150.56 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:       total time =   13780.02 ms /   553 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.68 ms /   256 runs   (    0.37 ms per token,  2675.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3388.28 ms /   585 tokens (    5.79 ms per token,   172.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.59 ms /   255 runs   (   42.58 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time =   15909.01 ms /   840 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      32.68 ms /    93 runs   (    0.35 ms per token,  2845.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.92 ms /    27 tokens (   10.77 ms per token,    92.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3609.90 ms /    92 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:       total time =    4495.86 ms /   119 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.36 ms /   256 runs   (    0.36 ms per token,  2802.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3536.18 ms /   635 tokens (    5.57 ms per token,   179.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10933.05 ms /   255 runs   (   42.87 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time =   16130.06 ms /   890 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.45 ms /   256 runs   (    0.35 ms per token,  2830.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6032.62 ms /  1134 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.53 ms /   255 runs   (   44.80 ms per token,    22.32 tokens per second)\n",
      "llama_print_timings:       total time =   19266.88 ms /  1389 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.28 ms /   256 runs   (    0.36 ms per token,  2744.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5476.65 ms /   922 tokens (    5.94 ms per token,   168.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11146.94 ms /   255 runs   (   43.71 ms per token,    22.88 tokens per second)\n",
      "llama_print_timings:       total time =   18343.28 ms /  1177 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.42 ms /   256 runs   (    0.37 ms per token,  2682.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2640.90 ms /   426 tokens (    6.20 ms per token,   161.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.99 ms /   255 runs   (   42.40 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time =   15347.02 ms /   681 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.72 ms /   256 runs   (    0.38 ms per token,  2619.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.76 ms /    27 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10165.12 ms /   255 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:       total time =   12535.33 ms /   282 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.21 ms /   256 runs   (    0.37 ms per token,  2688.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.18 ms /    12 tokens (   17.01 ms per token,    58.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10186.68 ms /   255 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:       total time =   12092.74 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.53 ms /   256 runs   (    0.35 ms per token,  2827.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6193.64 ms /  1140 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11549.18 ms /   255 runs   (   45.29 ms per token,    22.08 tokens per second)\n",
      "llama_print_timings:       total time =   19812.30 ms /  1395 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    30 runs   (    0.45 ms per token,  2207.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6203.65 ms /  1180 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1770.51 ms /    29 runs   (   61.05 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:       total time =    8467.44 ms /  1209 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.00 ms /   256 runs   (    0.37 ms per token,  2723.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.47 ms /    11 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10175.93 ms /   255 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:       total time =   12049.43 ms /   266 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.75 ms /   256 runs   (    0.37 ms per token,  2673.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2736.48 ms /   451 tokens (    6.07 ms per token,   164.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10725.90 ms /   255 runs   (   42.06 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time =   15424.73 ms /   706 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.58 ms /   256 runs   (    0.37 ms per token,  2735.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.40 ms /   126 tokens (    8.58 ms per token,   116.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10249.72 ms /   255 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:       total time =   12996.24 ms /   381 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.92 ms /   256 runs   (    0.37 ms per token,  2725.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6026.07 ms /  1145 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12051.89 ms /   255 runs   (   47.26 ms per token,    21.16 tokens per second)\n",
      "llama_print_timings:       total time =   19872.04 ms /  1400 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.96 ms /   256 runs   (    0.38 ms per token,  2613.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1961.47 ms /   306 tokens (    6.41 ms per token,   156.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10161.39 ms /   255 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:       total time =   13809.73 ms /   561 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.70 ms /   256 runs   (    0.39 ms per token,  2593.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.78 ms /     6 tokens (   33.46 ms per token,    29.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10170.94 ms /   255 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =   12049.17 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.12 ms /   256 runs   (    0.38 ms per token,  2635.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.98 ms /     6 tokens (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10154.54 ms /   255 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =   11975.41 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.21 ms /   256 runs   (    0.37 ms per token,  2688.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3530.11 ms /   631 tokens (    5.59 ms per token,   178.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10952.92 ms /   255 runs   (   42.95 ms per token,    23.28 tokens per second)\n",
      "llama_print_timings:       total time =   16774.60 ms /   886 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.58 ms /   256 runs   (    0.36 ms per token,  2795.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5995.46 ms /  1142 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11402.47 ms /   255 runs   (   44.72 ms per token,    22.36 tokens per second)\n",
      "llama_print_timings:       total time =   19128.35 ms /  1397 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.84 ms /   256 runs   (    0.38 ms per token,  2643.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2721.30 ms /   476 tokens (    5.72 ms per token,   174.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10374.64 ms /   255 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =   15038.98 ms /   731 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.63 ms /   256 runs   (    0.37 ms per token,  2705.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3945.85 ms /   693 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11234.44 ms /   255 runs   (   44.06 ms per token,    22.70 tokens per second)\n",
      "llama_print_timings:       total time =   16924.13 ms /   948 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.91 ms /   256 runs   (    0.38 ms per token,  2641.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.03 ms /    19 tokens (   13.58 ms per token,    73.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10119.60 ms /   255 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:       total time =   12326.91 ms /   274 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.42 ms /   256 runs   (    0.37 ms per token,  2682.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2171.66 ms /   333 tokens (    6.52 ms per token,   153.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10540.68 ms /   255 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =   14684.79 ms /   588 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.17 ms /   256 runs   (    0.36 ms per token,  2808.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6225.65 ms /  1154 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11962.47 ms /   255 runs   (   46.91 ms per token,    21.32 tokens per second)\n",
      "llama_print_timings:       total time =   20195.03 ms /  1409 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.41 ms /   256 runs   (    0.36 ms per token,  2740.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2985.78 ms /   489 tokens (    6.11 ms per token,   163.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10385.71 ms /   255 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =   15070.63 ms /   744 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.72 ms /   256 runs   (    0.38 ms per token,  2619.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.47 ms /    66 tokens (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10226.32 ms /   255 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:       total time =   12984.45 ms /   321 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.34 ms /   256 runs   (    0.38 ms per token,  2603.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4960.04 ms /   904 tokens (    5.49 ms per token,   182.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.29 ms /   255 runs   (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_print_timings:       total time =   18133.84 ms /  1159 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.46 ms /   256 runs   (    0.37 ms per token,  2710.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2669.09 ms /   423 tokens (    6.31 ms per token,   158.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10686.77 ms /   255 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time =   15252.78 ms /   678 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.54 ms /   256 runs   (    0.36 ms per token,  2796.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6101.96 ms /  1133 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11798.39 ms /   255 runs   (   46.27 ms per token,    21.61 tokens per second)\n",
      "llama_print_timings:       total time =   19891.61 ms /  1388 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     102.26 ms /   256 runs   (    0.40 ms per token,  2503.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5354.71 ms /   986 tokens (    5.43 ms per token,   184.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11217.59 ms /   255 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time =   18690.06 ms /  1241 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     134.21 ms /   256 runs   (    0.52 ms per token,  1907.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4270.27 ms /   607 tokens (    7.04 ms per token,   142.15 tokens per second)\n",
      "llama_print_timings:        eval time =   17794.13 ms /   255 runs   (   69.78 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:       total time =   24762.12 ms /   862 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.32 ms /   256 runs   (    0.38 ms per token,  2603.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2368.32 ms /   376 tokens (    6.30 ms per token,   158.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10918.25 ms /   255 runs   (   42.82 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time =   15490.17 ms /   631 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.77 ms /   256 runs   (    0.37 ms per token,  2672.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.11 ms /    21 tokens (   13.05 ms per token,    76.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10352.44 ms /   255 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =   13212.79 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.37 ms /   256 runs   (    0.37 ms per token,  2684.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6893.36 ms /  1137 tokens (    6.06 ms per token,   164.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12274.45 ms /   255 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_print_timings:       total time =   21409.41 ms /  1392 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.08 ms /   256 runs   (    0.35 ms per token,  2841.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     297.59 ms /    17 tokens (   17.51 ms per token,    57.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11249.08 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =   13242.00 ms /   272 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.12 ms /   256 runs   (    0.36 ms per token,  2749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1969.37 ms /   299 tokens (    6.59 ms per token,   151.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10188.67 ms /   255 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:       total time =   13891.73 ms /   554 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.91 ms /   256 runs   (    0.36 ms per token,  2755.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.63 ms /    10 tokens (   19.16 ms per token,    52.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10168.12 ms /   255 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =   12026.53 ms /   265 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.89 ms /   256 runs   (    0.37 ms per token,  2669.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3248.97 ms /   564 tokens (    5.76 ms per token,   173.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10874.81 ms /   255 runs   (   42.65 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time =   16223.44 ms /   819 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.69 ms /   256 runs   (    0.36 ms per token,  2761.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.29 ms /     6 tokens (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.40 ms /   255 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
      "llama_print_timings:       total time =   12052.12 ms /   261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.61 ms /   256 runs   (    0.35 ms per token,  2825.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6070.08 ms /  1135 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11863.79 ms /   255 runs   (   46.52 ms per token,    21.49 tokens per second)\n",
      "llama_print_timings:       total time =   19708.48 ms /  1390 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.87 ms /   256 runs   (    0.35 ms per token,  2817.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.00 ms /    23 tokens (   14.35 ms per token,    69.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.51 ms /   255 runs   (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13223.51 ms /   278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.74 ms /   256 runs   (    0.35 ms per token,  2821.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.86 ms /    21 tokens (   14.09 ms per token,    70.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11212.39 ms /   255 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13190.00 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.48 ms /   256 runs   (    0.37 ms per token,  2738.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.78 ms /    16 tokens (   17.86 ms per token,    55.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11206.73 ms /   255 runs   (   43.95 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =   13223.79 ms /   271 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.11 ms /   256 runs   (    0.38 ms per token,  2636.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5000.49 ms /   897 tokens (    5.57 ms per token,   179.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11136.68 ms /   255 runs   (   43.67 ms per token,    22.90 tokens per second)\n",
      "llama_print_timings:       total time =   18202.66 ms /  1152 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    27 runs   (    0.39 ms per token,  2583.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.65 ms /   278 tokens (    6.78 ms per token,   147.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1066.84 ms /    26 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =    3184.81 ms /   304 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      21.15 ms /    56 runs   (    0.38 ms per token,  2647.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    21 tokens (   12.03 ms per token,    83.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2174.01 ms /    55 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
      "llama_print_timings:       total time =    2796.18 ms /    76 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.52 ms /   256 runs   (    0.37 ms per token,  2680.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.53 ms /   157 tokens (    6.51 ms per token,   153.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10330.46 ms /   255 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:       total time =   13265.65 ms /   412 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.60 ms /   256 runs   (    0.36 ms per token,  2764.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6120.82 ms /  1149 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12205.45 ms /   255 runs   (   47.86 ms per token,    20.89 tokens per second)\n",
      "llama_print_timings:       total time =   20475.40 ms /  1404 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.31 ms /   256 runs   (    0.37 ms per token,  2686.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5304.61 ms /   981 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11314.26 ms /   255 runs   (   44.37 ms per token,    22.54 tokens per second)\n",
      "llama_print_timings:       total time =   18450.07 ms /  1236 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.09 ms /   256 runs   (    0.38 ms per token,  2636.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3439.46 ms /   598 tokens (    5.75 ms per token,   173.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10946.19 ms /   255 runs   (   42.93 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time =   16106.41 ms /   853 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      17.08 ms /    46 runs   (    0.37 ms per token,  2693.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3383.68 ms /   589 tokens (    5.74 ms per token,   174.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1913.04 ms /    45 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
      "llama_print_timings:       total time =    5609.73 ms /   634 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.11 ms /   256 runs   (    0.38 ms per token,  2609.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2499.34 ms /   396 tokens (    6.31 ms per token,   158.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.11 ms /   255 runs   (   41.88 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time =   15252.01 ms /   651 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.03 ms /   256 runs   (    0.36 ms per token,  2812.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6147.25 ms /  1149 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12271.46 ms /   255 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =   20481.37 ms /  1404 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.49 ms /   256 runs   (    0.37 ms per token,  2680.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5119.66 ms /   950 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.78 ms /   255 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time =   18056.50 ms /  1205 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.15 ms /   256 runs   (    0.38 ms per token,  2635.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3383.68 ms /   581 tokens (    5.82 ms per token,   171.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10901.66 ms /   255 runs   (   42.75 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =   15989.68 ms /   836 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.32 ms /   256 runs   (    0.36 ms per token,  2743.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4141.58 ms /   602 tokens (    6.88 ms per token,   145.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12193.82 ms /   255 runs   (   47.82 ms per token,    20.91 tokens per second)\n",
      "llama_print_timings:       total time =   18076.03 ms /   857 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.82 ms /   256 runs   (    0.38 ms per token,  2644.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2751.78 ms /   461 tokens (    5.97 ms per token,   167.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10837.50 ms /   255 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time =   15526.93 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.85 ms /   256 runs   (    0.36 ms per token,  2787.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6406.37 ms /  1152 tokens (    5.56 ms per token,   179.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12428.41 ms /   255 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_print_timings:       total time =   21157.31 ms /  1407 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.44 ms /   256 runs   (    0.38 ms per token,  2654.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4791.05 ms /   788 tokens (    6.08 ms per token,   164.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13069.95 ms /   255 runs   (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:       total time =   20073.82 ms /  1043 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.23 ms /   256 runs   (    0.38 ms per token,  2660.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.29 ms /    97 tokens (   13.97 ms per token,    71.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10370.92 ms /   255 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:       total time =   13823.48 ms /   352 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.06 ms /   256 runs   (    0.37 ms per token,  2692.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2596.72 ms /   396 tokens (    6.56 ms per token,   152.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10807.25 ms /   255 runs   (   42.38 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time =   15279.63 ms /   651 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     103.52 ms /   256 runs   (    0.40 ms per token,  2473.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4626.60 ms /   677 tokens (    6.83 ms per token,   146.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12688.87 ms /   255 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:       total time =   19573.56 ms /   932 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.19 ms /   256 runs   (    0.38 ms per token,  2607.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6797.89 ms /  1156 tokens (    5.88 ms per token,   170.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11680.89 ms /   255 runs   (   45.81 ms per token,    21.83 tokens per second)\n",
      "llama_print_timings:       total time =   21043.11 ms /  1411 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.71 ms /   256 runs   (    0.37 ms per token,  2674.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7101.69 ms /  1006 tokens (    7.06 ms per token,   141.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15145.91 ms /   255 runs   (   59.40 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:       total time =   24460.03 ms /  1261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    34 runs   (    0.41 ms per token,  2467.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1810.83 ms /    56 tokens (   32.34 ms per token,    30.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1614.54 ms /    33 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:       total time =    3735.07 ms /    89 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.52 ms /   256 runs   (    0.37 ms per token,  2680.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3293.00 ms /   403 tokens (    8.17 ms per token,   122.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11901.56 ms /   255 runs   (   46.67 ms per token,    21.43 tokens per second)\n",
      "llama_print_timings:       total time =   17341.14 ms /   658 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.01 ms /   256 runs   (    0.38 ms per token,  2666.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.23 ms /    61 tokens (   16.22 ms per token,    61.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10434.19 ms /   255 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   13647.37 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.35 ms /   256 runs   (    0.37 ms per token,  2713.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8080.23 ms /  1157 tokens (    6.98 ms per token,   143.19 tokens per second)\n",
      "llama_print_timings:        eval time =   15016.95 ms /   255 runs   (   58.89 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:       total time =   26086.48 ms /  1412 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    22 runs   (    0.41 ms per token,  2465.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2886.82 ms /   512 tokens (    5.64 ms per token,   177.36 tokens per second)\n",
      "llama_print_timings:        eval time =     859.10 ms /    21 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =    3939.32 ms /   533 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.13 ms /   256 runs   (    0.39 ms per token,  2582.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2530.63 ms /   363 tokens (    6.97 ms per token,   143.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.67 ms /   255 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time =   15492.32 ms /   618 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      16.46 ms /    46 runs   (    0.36 ms per token,  2795.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3574.06 ms /   637 tokens (    5.61 ms per token,   178.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1957.45 ms /    45 runs   (   43.50 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =    5941.25 ms /   682 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.21 ms /   256 runs   (    0.38 ms per token,  2660.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2437.81 ms /   397 tokens (    6.14 ms per token,   162.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10827.17 ms /   255 runs   (   42.46 ms per token,    23.55 tokens per second)\n",
      "llama_print_timings:       total time =   15053.50 ms /   652 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.84 ms /   256 runs   (    0.36 ms per token,  2757.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6561.81 ms /  1138 tokens (    5.77 ms per token,   173.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.44 ms /   255 runs   (   45.12 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time =   20255.99 ms /  1393 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.60 ms /   256 runs   (    0.38 ms per token,  2622.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7023.22 ms /   900 tokens (    7.80 ms per token,   128.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11147.82 ms /   255 runs   (   43.72 ms per token,    22.87 tokens per second)\n",
      "llama_print_timings:       total time =   20331.78 ms /  1155 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.40 ms /   256 runs   (    0.38 ms per token,  2601.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.18 ms /   274 tokens (    6.80 ms per token,   147.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.86 ms /   255 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   14598.22 ms /   529 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     102.42 ms /   256 runs   (    0.40 ms per token,  2499.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3299.00 ms /   576 tokens (    5.73 ms per token,   174.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11062.38 ms /   255 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
      "llama_print_timings:       total time =   16182.01 ms /   831 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.41 ms /   256 runs   (    0.37 ms per token,  2683.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3697.45 ms /   667 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11211.13 ms /   255 runs   (   43.97 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =   16696.83 ms /   922 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.78 ms /   256 runs   (    0.36 ms per token,  2759.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6289.38 ms /  1150 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12263.23 ms /   255 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_print_timings:       total time =   20652.37 ms /  1405 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.43 ms /   256 runs   (    0.37 ms per token,  2682.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4764.87 ms /   833 tokens (    5.72 ms per token,   174.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11890.20 ms /   255 runs   (   46.63 ms per token,    21.45 tokens per second)\n",
      "llama_print_timings:       total time =   18952.25 ms /  1088 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.27 ms /   256 runs   (    0.38 ms per token,  2631.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1701.16 ms /   234 tokens (    7.27 ms per token,   137.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10429.51 ms /   255 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =   14328.92 ms /   489 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    31 runs   (    0.38 ms per token,  2626.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     305.81 ms /    25 tokens (   12.23 ms per token,    81.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.32 ms /    30 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
      "llama_print_timings:       total time =    1753.83 ms /    55 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.87 ms /   256 runs   (    0.38 ms per token,  2642.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.63 ms /   297 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10558.06 ms /   255 runs   (   41.40 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =   13928.97 ms /   552 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.91 ms /   256 runs   (    0.37 ms per token,  2725.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6367.32 ms /  1136 tokens (    5.61 ms per token,   178.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11988.44 ms /   255 runs   (   47.01 ms per token,    21.27 tokens per second)\n",
      "llama_print_timings:       total time =   20546.01 ms /  1391 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.11 ms /   256 runs   (    0.37 ms per token,  2691.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3866.63 ms /   696 tokens (    5.56 ms per token,   180.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10655.67 ms /   255 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =   16238.06 ms /   951 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.78 ms /   256 runs   (    0.38 ms per token,  2645.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2466.34 ms /   413 tokens (    5.97 ms per token,   167.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.05 ms /   255 runs   (   41.78 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =   14808.92 ms /   668 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.18 ms /   256 runs   (    0.38 ms per token,  2661.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.98 ms /    21 tokens (   12.19 ms per token,    82.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10158.36 ms /   255 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:       total time =   12494.19 ms /   276 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.07 ms /   256 runs   (    0.37 ms per token,  2692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3750.66 ms /   655 tokens (    5.73 ms per token,   174.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11030.34 ms /   255 runs   (   43.26 ms per token,    23.12 tokens per second)\n",
      "llama_print_timings:       total time =   16729.37 ms /   910 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.32 ms /   256 runs   (    0.36 ms per token,  2743.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6496.24 ms /  1142 tokens (    5.69 ms per token,   175.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12179.27 ms /   255 runs   (   47.76 ms per token,    20.94 tokens per second)\n",
      "llama_print_timings:       total time =   20759.06 ms /  1397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.76 ms /   256 runs   (    0.35 ms per token,  2820.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.99 ms /    17 tokens (   17.41 ms per token,    57.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11212.84 ms /   255 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13183.72 ms /   272 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.16 ms /   256 runs   (    0.38 ms per token,  2662.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3544.57 ms /   623 tokens (    5.69 ms per token,   175.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10571.22 ms /   255 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   16293.50 ms /   878 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.60 ms /   256 runs   (    0.39 ms per token,  2596.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3152.23 ms /   541 tokens (    5.83 ms per token,   171.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10877.76 ms /   255 runs   (   42.66 ms per token,    23.44 tokens per second)\n",
      "llama_print_timings:       total time =   15956.14 ms /   796 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.47 ms /   256 runs   (    0.38 ms per token,  2653.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1986.26 ms /   259 tokens (    7.67 ms per token,   130.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10488.54 ms /   255 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
      "llama_print_timings:       total time =   14302.26 ms /   514 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    25 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3231.03 ms /   557 tokens (    5.80 ms per token,   172.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1016.52 ms /    24 runs   (   42.36 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time =    4419.43 ms /   581 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.13 ms /   256 runs   (    0.36 ms per token,  2748.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6141.61 ms /  1135 tokens (    5.41 ms per token,   184.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.00 ms /   255 runs   (   44.70 ms per token,    22.37 tokens per second)\n",
      "llama_print_timings:       total time =   19630.32 ms /  1390 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.60 ms /   256 runs   (    0.38 ms per token,  2650.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1979.50 ms /   295 tokens (    6.71 ms per token,   149.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10159.80 ms /   255 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:       total time =   14316.78 ms /   550 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.66 ms /   256 runs   (    0.37 ms per token,  2733.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.64 ms /     6 tokens (   36.94 ms per token,    27.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10130.46 ms /   255 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:       total time =   12044.01 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.74 ms /   256 runs   (    0.36 ms per token,  2760.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     166.87 ms /     6 tokens (   27.81 ms per token,    35.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10150.73 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:       total time =   11972.93 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.33 ms /   256 runs   (    0.37 ms per token,  2713.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.41 ms /     9 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10173.20 ms /   255 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =   12084.02 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.24 ms /   256 runs   (    0.36 ms per token,  2745.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6067.86 ms /  1141 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12274.73 ms /   255 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_print_timings:       total time =   20178.44 ms /  1396 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.38 ms /   256 runs   (    0.38 ms per token,  2656.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2795.67 ms /   475 tokens (    5.89 ms per token,   169.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10329.58 ms /   255 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time =   15141.76 ms /   730 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     100.62 ms /   256 runs   (    0.39 ms per token,  2544.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3803.41 ms /   675 tokens (    5.63 ms per token,   177.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11172.34 ms /   255 runs   (   43.81 ms per token,    22.82 tokens per second)\n",
      "llama_print_timings:       total time =   17349.70 ms /   930 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.44 ms /   256 runs   (    0.37 ms per token,  2682.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.44 ms /   102 tokens (   10.70 ms per token,    93.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10377.65 ms /   255 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =   13306.01 ms /   357 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.01 ms /   256 runs   (    0.38 ms per token,  2611.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2216.31 ms /   339 tokens (    6.54 ms per token,   152.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.95 ms /   255 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time =   14915.36 ms /   594 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.84 ms /   256 runs   (    0.37 ms per token,  2727.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6705.47 ms /  1135 tokens (    5.91 ms per token,   169.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12348.84 ms /   255 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_print_timings:       total time =   21346.70 ms /  1390 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.93 ms /   256 runs   (    0.36 ms per token,  2784.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.16 ms /    21 tokens (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.38 ms /   255 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =   13420.89 ms /   276 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.77 ms /   256 runs   (    0.37 ms per token,  2673.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2045.47 ms /   312 tokens (    6.56 ms per token,   152.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10282.30 ms /   255 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =   14503.01 ms /   567 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.24 ms /   256 runs   (    0.37 ms per token,  2687.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.51 ms /   126 tokens (    9.78 ms per token,   102.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10434.46 ms /   255 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   13580.80 ms /   381 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.62 ms /   256 runs   (    0.38 ms per token,  2649.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3090.16 ms /   532 tokens (    5.81 ms per token,   172.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10961.92 ms /   255 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time =   16197.66 ms /   787 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.37 ms /   256 runs   (    0.37 ms per token,  2684.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3130.55 ms /   499 tokens (    6.27 ms per token,   159.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11081.93 ms /   255 runs   (   43.46 ms per token,    23.01 tokens per second)\n",
      "llama_print_timings:       total time =   16078.62 ms /   754 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.62 ms /   256 runs   (    0.36 ms per token,  2794.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6788.21 ms /  1140 tokens (    5.95 ms per token,   167.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13215.53 ms /   255 runs   (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:       total time =   22167.69 ms /  1395 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.66 ms /   256 runs   (    0.37 ms per token,  2704.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4194.01 ms /   755 tokens (    5.55 ms per token,   180.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10815.14 ms /   255 runs   (   42.41 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time =   17142.82 ms /  1010 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.18 ms /   256 runs   (    0.36 ms per token,  2777.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.26 ms /    17 tokens (   17.66 ms per token,    56.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10225.62 ms /   255 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:       total time =   12617.80 ms /   272 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.29 ms /   256 runs   (    0.38 ms per token,  2631.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3580.47 ms /   626 tokens (    5.72 ms per token,   174.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11114.61 ms /   255 runs   (   43.59 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time =   16748.93 ms /   881 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.04 ms /   256 runs   (    0.38 ms per token,  2611.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3296.59 ms /   561 tokens (    5.88 ms per token,   170.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10963.28 ms /   255 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time =   16008.69 ms /   816 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.23 ms /   256 runs   (    0.36 ms per token,  2775.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6619.25 ms /  1150 tokens (    5.76 ms per token,   173.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12499.23 ms /   255 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:       total time =   21250.52 ms /  1405 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.71 ms /   256 runs   (    0.37 ms per token,  2731.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5324.20 ms /   833 tokens (    6.39 ms per token,   156.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11141.03 ms /   255 runs   (   43.69 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time =   18666.61 ms /  1088 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.33 ms /   256 runs   (    0.37 ms per token,  2713.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.28 ms /   182 tokens (    8.12 ms per token,   123.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10436.93 ms /   255 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =   14053.89 ms /   437 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.10 ms /   256 runs   (    0.37 ms per token,  2691.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3887.67 ms /   693 tokens (    5.61 ms per token,   178.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11248.07 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =   17247.07 ms /   948 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.03 ms /   256 runs   (    0.39 ms per token,  2585.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3429.81 ms /   592 tokens (    5.79 ms per token,   172.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.11 ms /   255 runs   (   44.17 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time =   16517.51 ms /   847 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.39 ms /   256 runs   (    0.37 ms per token,  2683.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6517.17 ms /  1141 tokens (    5.71 ms per token,   175.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12217.76 ms /   255 runs   (   47.91 ms per token,    20.87 tokens per second)\n",
      "llama_print_timings:       total time =   20923.93 ms /  1396 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.52 ms /   256 runs   (    0.38 ms per token,  2652.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5715.03 ms /  1077 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.91 ms /   255 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =   18903.40 ms /  1332 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.06 ms /   256 runs   (    0.38 ms per token,  2665.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2302.06 ms /   376 tokens (    6.12 ms per token,   163.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10593.03 ms /   255 runs   (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time =   15049.94 ms /   631 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.78 ms /   256 runs   (    0.39 ms per token,  2591.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5084.57 ms /   893 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.22 ms /   255 runs   (   45.18 ms per token,    22.13 tokens per second)\n",
      "llama_print_timings:       total time =   18444.57 ms /  1148 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     100.18 ms /   256 runs   (    0.39 ms per token,  2555.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4334.63 ms /   796 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11363.55 ms /   255 runs   (   44.56 ms per token,    22.44 tokens per second)\n",
      "llama_print_timings:       total time =   17588.06 ms /  1051 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.54 ms /   256 runs   (    0.36 ms per token,  2766.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6152.75 ms /  1139 tokens (    5.40 ms per token,   185.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.26 ms /   255 runs   (   44.94 ms per token,    22.25 tokens per second)\n",
      "llama_print_timings:       total time =   19472.75 ms /  1394 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.25 ms /   256 runs   (    0.38 ms per token,  2632.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5369.98 ms /  1009 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11235.23 ms /   255 runs   (   44.06 ms per token,    22.70 tokens per second)\n",
      "llama_print_timings:       total time =   18567.85 ms /  1264 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.09 ms /   256 runs   (    0.37 ms per token,  2692.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     312.93 ms /    21 tokens (   14.90 ms per token,    67.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10110.53 ms /   255 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:       total time =   12564.56 ms /   276 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.86 ms /   256 runs   (    0.38 ms per token,  2642.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    19 tokens (   13.17 ms per token,    75.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10169.40 ms /   255 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =   12071.17 ms /   274 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.41 ms /   256 runs   (    0.38 ms per token,  2601.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.37 ms /   698 tokens (    5.59 ms per token,   179.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11054.52 ms /   255 runs   (   43.35 ms per token,    23.07 tokens per second)\n",
      "llama_print_timings:       total time =   16730.74 ms /   953 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.38 ms /   256 runs   (    0.36 ms per token,  2801.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6102.94 ms /  1144 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11839.01 ms /   255 runs   (   46.43 ms per token,    21.54 tokens per second)\n",
      "llama_print_timings:       total time =   19809.89 ms /  1399 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.92 ms /   256 runs   (    0.36 ms per token,  2784.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.81 ms /    15 tokens (   18.52 ms per token,    53.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11203.15 ms /   255 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time =   13195.21 ms /   270 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     101.27 ms /   256 runs   (    0.40 ms per token,  2527.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6151.94 ms /  1157 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11509.76 ms /   255 runs   (   45.14 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time =   19569.51 ms /  1412 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.90 ms /   256 runs   (    0.38 ms per token,  2614.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4586.94 ms /   850 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.71 ms /   255 runs   (   44.23 ms per token,    22.61 tokens per second)\n",
      "llama_print_timings:       total time =   17601.13 ms /  1105 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.23 ms /   256 runs   (    0.39 ms per token,  2579.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4210.83 ms /   752 tokens (    5.60 ms per token,   178.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.56 ms /   255 runs   (   44.31 ms per token,    22.57 tokens per second)\n",
      "llama_print_timings:       total time =   17371.65 ms /  1007 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.48 ms /   256 runs   (    0.35 ms per token,  2829.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5996.09 ms /  1134 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11412.19 ms /   255 runs   (   44.75 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time =   19181.20 ms /  1389 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.21 ms /   256 runs   (    0.35 ms per token,  2837.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.03 ms /    33 tokens (   26.24 ms per token,    38.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.21 ms /   255 runs   (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13762.14 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.80 ms /   256 runs   (    0.35 ms per token,  2819.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     503.99 ms /    33 tokens (   15.27 ms per token,    65.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.44 ms /   255 runs   (   44.27 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time =   13484.53 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      89.91 ms /   256 runs   (    0.35 ms per token,  2847.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.50 ms /    25 tokens (   13.22 ms per token,    75.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.84 ms /   255 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time =   13247.35 ms /   280 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.82 ms /   256 runs   (    0.38 ms per token,  2644.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4908.47 ms /   921 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11138.02 ms /   255 runs   (   43.68 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time =   17955.49 ms /  1176 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.10 ms /   256 runs   (    0.38 ms per token,  2663.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3071.59 ms /   523 tokens (    5.87 ms per token,   170.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10818.84 ms /   255 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time =   15796.21 ms /   778 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.86 ms /   256 runs   (    0.37 ms per token,  2727.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3733.25 ms /   645 tokens (    5.79 ms per token,   172.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11082.98 ms /   255 runs   (   43.46 ms per token,    23.01 tokens per second)\n",
      "llama_print_timings:       total time =   16606.42 ms /   900 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.75 ms /   256 runs   (    0.38 ms per token,  2645.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.49 ms /   126 tokens (    8.85 ms per token,   113.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10288.98 ms /   255 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
      "llama_print_timings:       total time =   13640.64 ms /   381 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 16s, sys: 3min 26s, total: 29min 43s\n",
      "Wall time: 39min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  SelfQueryAgent(llm, _CONFIGS, _TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475fcf3a-64f8-4f97-91a4-82a620f2e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c453c796-218e-4101-9a43-022aceb8453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/notion_offline.pkl', 'rb') as f:\n",
    "    docs_from_notion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b28648e-825d-460c-b33e-7d1d8cc07dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = list()\n",
    "for k, v in docs_from_notion.items():\n",
    "    docs.extend(v)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9877d641-a343-4bc7-ad39-877a457d6bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "l = [1,2,3, 4, 5]\n",
    "l[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef149715-286f-4191-801d-257b5e4dde0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2282)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_params = {\n",
    "    # 1 Chinese characters = 2 english character\n",
    "    # most paragraphs/sections are within 500 Chinese words/chars\n",
    "    'chunk_size': 500, \n",
    "    'chunk_overlap': 100,\n",
    "}\n",
    "\n",
    "rc_splitter = RecursiveCharacterTextSplitter(**chunk_params)\n",
    "\n",
    "splits = rc_splitter.split_documents(docs)\n",
    "len(docs_from_notion), len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe5bfef-7030-4b60-9ad3-009ccedd2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "import jieba\n",
    "\n",
    "# ref: https://www.kaggle.com/code/terrychanorg/rank-bm25-notebook34e931b070\n",
    "# ref: https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/retrievers/bm25.py#L15\n",
    "# ref: https://github.com/fxsjy/jieba?tab=readme-ov-file\n",
    "retriever = BM25Retriever.from_documents(\n",
    "    splits,\n",
    "    preprocess_func=lambda x: jieba.lcut_for_search(x, HMM=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0e3356f-cf1e-492a-acea-b56c38fedf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 188.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 ms, sys: 1.5 ms, total: 195 ms\n",
      "Wall time: 197 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4462f7-320f-4bd8-8e1e-97cc1d6a8fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3877551020408163"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99f1fc42-5848-45f3-a778-328912146c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from my_notion_companion.query_constructor import QueryConstructor\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qc = QueryConstructor(llm, _CONFIGS)\n",
    "\n",
    "retriever_plus = RunnableLambda(qc.invoke) | retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a30a20d0-e40f-46bb-97f1-18c5edbc69ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 0/37 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     7 runs   (    0.38 ms per token,  2640.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.35 ms /     7 tokens (  154.48 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:        eval time =     200.03 ms /     6 runs   (   33.34 ms per token,    30.00 tokens per second)\n",
      "llama_print_timings:       total time =    1330.87 ms /    13 tokens\n",
      "  3%|██▋                                                                                                | 1/37 [00:01<00:48,  1.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     9 runs   (    0.35 ms per token,  2850.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.18 ms /    25 tokens (   10.65 ms per token,    93.92 tokens per second)\n",
      "llama_print_timings:        eval time =     264.46 ms /     8 runs   (   33.06 ms per token,    30.25 tokens per second)\n",
      "llama_print_timings:       total time =     589.03 ms /    33 tokens\n",
      "  5%|█████▎                                                                                             | 2/37 [00:01<00:32,  1.09it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    45 runs   (    0.36 ms per token,  2781.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.67 ms /    31 tokens (    9.34 ms per token,   107.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1464.21 ms /    44 runs   (   33.28 ms per token,    30.05 tokens per second)\n",
      "llama_print_timings:       total time =    2047.96 ms /    75 tokens\n",
      "  8%|████████                                                                                           | 3/37 [00:04<00:49,  1.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      50.09 ms /   140 runs   (    0.36 ms per token,  2794.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.53 ms /    36 tokens (   22.29 ms per token,    44.86 tokens per second)\n",
      "llama_print_timings:        eval time =    4663.06 ms /   139 runs   (   33.55 ms per token,    29.81 tokens per second)\n",
      "llama_print_timings:       total time =    6369.44 ms /   175 tokens\n",
      " 11%|██████████▋                                                                                        | 4/37 [00:10<01:51,  3.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     6 runs   (    0.34 ms per token,  2899.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     420.53 ms /    33 tokens (   12.74 ms per token,    78.47 tokens per second)\n",
      "llama_print_timings:        eval time =     171.08 ms /     5 runs   (   34.22 ms per token,    29.23 tokens per second)\n",
      "llama_print_timings:       total time =     630.80 ms /    38 tokens\n",
      " 14%|█████████████▍                                                                                     | 5/37 [00:11<01:16,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      32.91 ms /    92 runs   (    0.36 ms per token,  2795.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     452.20 ms /    45 tokens (   10.05 ms per token,    99.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3067.20 ms /    91 runs   (   33.71 ms per token,    29.67 tokens per second)\n",
      "llama_print_timings:       total time =    4100.41 ms /   136 tokens\n",
      " 16%|████████████████                                                                                   | 6/37 [00:15<01:32,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /    68 runs   (    0.34 ms per token,  2911.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.77 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2277.11 ms /    67 runs   (   33.99 ms per token,    29.42 tokens per second)\n",
      "llama_print_timings:       total time =    2956.15 ms /    91 tokens\n",
      " 19%|██████████████████▋                                                                                | 7/37 [00:18<01:29,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     7 runs   (    0.36 ms per token,  2786.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.18 ms /    28 tokens (    9.79 ms per token,   102.12 tokens per second)\n",
      "llama_print_timings:        eval time =     204.27 ms /     6 runs   (   34.05 ms per token,    29.37 tokens per second)\n",
      "llama_print_timings:       total time =     523.69 ms /    34 tokens\n",
      " 22%|█████████████████████▍                                                                             | 8/37 [00:18<01:03,  2.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     9 runs   (    0.34 ms per token,  2919.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.76 ms /    29 tokens (    9.61 ms per token,   104.03 tokens per second)\n",
      "llama_print_timings:        eval time =     268.79 ms /     8 runs   (   33.60 ms per token,    29.76 tokens per second)\n",
      "llama_print_timings:       total time =     603.73 ms /    37 tokens\n",
      " 24%|████████████████████████                                                                           | 9/37 [00:19<00:47,  1.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    19 runs   (    0.36 ms per token,  2801.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.55 ms /    26 tokens (   10.14 ms per token,    98.65 tokens per second)\n",
      "llama_print_timings:        eval time =     609.82 ms /    18 runs   (   33.88 ms per token,    29.52 tokens per second)\n",
      "llama_print_timings:       total time =     996.50 ms /    44 tokens\n",
      " 27%|██████████████████████████▍                                                                       | 10/37 [00:20<00:40,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    12 runs   (    0.36 ms per token,  2744.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.39 ms /    36 tokens (   12.07 ms per token,    82.87 tokens per second)\n",
      "llama_print_timings:        eval time =     382.91 ms /    11 runs   (   34.81 ms per token,    28.73 tokens per second)\n",
      "llama_print_timings:       total time =     895.67 ms /    47 tokens\n",
      " 30%|█████████████████████████████▏                                                                    | 11/37 [00:21<00:34,  1.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      20.45 ms /    58 runs   (    0.35 ms per token,  2835.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     418.51 ms /    34 tokens (   12.31 ms per token,    81.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1959.68 ms /    57 runs   (   34.38 ms per token,    29.09 tokens per second)\n",
      "llama_print_timings:       total time =    2754.98 ms /    91 tokens\n",
      " 32%|███████████████████████████████▊                                                                  | 12/37 [00:23<00:43,  1.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    42 runs   (    0.35 ms per token,  2834.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.71 ms /    28 tokens (    9.78 ms per token,   102.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1407.70 ms /    41 runs   (   34.33 ms per token,    29.13 tokens per second)\n",
      "llama_print_timings:       total time =    1944.37 ms /    69 tokens\n",
      " 35%|██████████████████████████████████▍                                                               | 13/37 [00:25<00:43,  1.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     6 runs   (    0.35 ms per token,  2853.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.37 ms /    40 tokens (   10.78 ms per token,    92.73 tokens per second)\n",
      "llama_print_timings:        eval time =     180.91 ms /     5 runs   (   36.18 ms per token,    27.64 tokens per second)\n",
      "llama_print_timings:       total time =     650.32 ms /    45 tokens\n",
      " 38%|█████████████████████████████████████                                                             | 14/37 [00:26<00:33,  1.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      24.82 ms /    71 runs   (    0.35 ms per token,  2860.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.36 ms /    40 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =    2457.13 ms /    70 runs   (   35.10 ms per token,    28.49 tokens per second)\n",
      "llama_print_timings:       total time =    3337.96 ms /   110 tokens\n",
      " 41%|███████████████████████████████████████▋                                                          | 15/37 [00:29<00:44,  2.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    27 runs   (    0.34 ms per token,  2910.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     575.81 ms /    43 tokens (   13.39 ms per token,    74.68 tokens per second)\n",
      "llama_print_timings:        eval time =     912.36 ms /    26 runs   (   35.09 ms per token,    28.50 tokens per second)\n",
      "llama_print_timings:       total time =    1657.87 ms /    69 tokens\n",
      " 43%|██████████████████████████████████████████▍                                                       | 16/37 [00:31<00:40,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      23.59 ms /    65 runs   (    0.36 ms per token,  2755.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     427.78 ms /    46 tokens (    9.30 ms per token,   107.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2260.98 ms /    64 runs   (   35.33 ms per token,    28.31 tokens per second)\n",
      "llama_print_timings:       total time =    3108.28 ms /   110 tokens\n",
      " 46%|█████████████████████████████████████████████                                                     | 17/37 [00:34<00:45,  2.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      24.35 ms /    68 runs   (    0.36 ms per token,  2793.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.06 ms /    47 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2377.76 ms /    67 runs   (   35.49 ms per token,    28.18 tokens per second)\n",
      "llama_print_timings:       total time =    3282.27 ms /   114 tokens\n",
      " 49%|███████████████████████████████████████████████▋                                                  | 18/37 [00:38<00:49,  2.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     4 runs   (    0.37 ms per token,  2697.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.41 ms /    28 tokens (   10.05 ms per token,    99.50 tokens per second)\n",
      "llama_print_timings:        eval time =     105.87 ms /     3 runs   (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_print_timings:       total time =     413.21 ms /    31 tokens\n",
      " 51%|██████████████████████████████████████████████████▎                                               | 19/37 [00:38<00:34,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    11 runs   (    0.37 ms per token,  2697.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     443.43 ms /    41 tokens (   10.82 ms per token,    92.46 tokens per second)\n",
      "llama_print_timings:        eval time =     364.74 ms /    10 runs   (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_print_timings:       total time =     882.88 ms /    51 tokens\n",
      " 54%|████████████████████████████████████████████████████▉                                             | 20/37 [00:39<00:27,  1.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     7 runs   (    0.34 ms per token,  2926.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.49 ms /    27 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =     214.88 ms /     6 runs   (   35.81 ms per token,    27.92 tokens per second)\n",
      "llama_print_timings:       total time =     535.69 ms /    33 tokens\n",
      " 57%|███████████████████████████████████████████████████████▌                                          | 21/37 [00:39<00:20,  1.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    11 runs   (    0.36 ms per token,  2807.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     447.80 ms /    33 tokens (   13.57 ms per token,    73.69 tokens per second)\n",
      "llama_print_timings:        eval time =     377.56 ms /    10 runs   (   37.76 ms per token,    26.49 tokens per second)\n",
      "llama_print_timings:       total time =     904.53 ms /    43 tokens\n",
      " 59%|██████████████████████████████████████████████████████████▎                                       | 22/37 [00:40<00:17,  1.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    17 runs   (    0.36 ms per token,  2815.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.72 ms /    29 tokens (    9.85 ms per token,   101.50 tokens per second)\n",
      "llama_print_timings:        eval time =     600.05 ms /    16 runs   (   37.50 ms per token,    26.66 tokens per second)\n",
      "llama_print_timings:       total time =    1004.81 ms /    45 tokens\n",
      " 62%|████████████████████████████████████████████████████████████▉                                     | 23/37 [00:41<00:15,  1.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     5 runs   (    0.34 ms per token,  2912.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.05 ms /    25 tokens (   10.84 ms per token,    92.23 tokens per second)\n",
      "llama_print_timings:        eval time =     142.68 ms /     4 runs   (   35.67 ms per token,    28.03 tokens per second)\n",
      "llama_print_timings:       total time =     447.40 ms /    29 tokens\n",
      " 65%|███████████████████████████████████████████████████████████████▌                                  | 24/37 [00:42<00:12,  1.07it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      33.19 ms /    94 runs   (    0.35 ms per token,  2832.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.80 ms /    31 tokens (    9.64 ms per token,   103.75 tokens per second)\n",
      "llama_print_timings:        eval time =    3390.87 ms /    93 runs   (   36.46 ms per token,    27.43 tokens per second)\n",
      "llama_print_timings:       total time =    4299.04 ms /   124 tokens\n",
      " 68%|██████████████████████████████████████████████████████████████████▏                               | 25/37 [00:46<00:23,  1.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      13.95 ms /    39 runs   (    0.36 ms per token,  2796.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.08 ms /    26 tokens (   10.31 ms per token,    96.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.77 ms /    38 runs   (   36.20 ms per token,    27.62 tokens per second)\n",
      "llama_print_timings:       total time =    1892.31 ms /    64 tokens\n",
      " 70%|████████████████████████████████████████████████████████████████████▊                             | 26/37 [00:48<00:21,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      15.19 ms /    43 runs   (    0.35 ms per token,  2831.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.51 ms /    33 tokens (   22.71 ms per token,    44.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.97 ms /    42 runs   (   36.57 ms per token,    27.34 tokens per second)\n",
      "llama_print_timings:       total time =    2562.92 ms /    75 tokens\n",
      " 73%|███████████████████████████████████████████████████████████████████████▌                          | 27/37 [00:51<00:21,  2.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      18.24 ms /    53 runs   (    0.34 ms per token,  2905.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.44 ms /    31 tokens (    9.47 ms per token,   105.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1898.09 ms /    52 runs   (   36.50 ms per token,    27.40 tokens per second)\n",
      "llama_print_timings:       total time =    2533.43 ms /    83 tokens\n",
      " 76%|██████████████████████████████████████████████████████████████████████████▏                       | 28/37 [00:53<00:20,  2.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      13.55 ms /    39 runs   (    0.35 ms per token,  2877.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.54 ms /    41 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1409.24 ms /    38 runs   (   37.09 ms per token,    26.96 tokens per second)\n",
      "llama_print_timings:       total time =    2096.58 ms /    79 tokens\n",
      " 78%|████████████████████████████████████████████████████████████████████████████▊                     | 29/37 [00:55<00:17,  2.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.74 ms /    50 runs   (    0.35 ms per token,  2818.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.60 ms /    32 tokens (   10.21 ms per token,    97.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1855.40 ms /    49 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:       total time =    2518.19 ms /    81 tokens\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████▍                  | 30/37 [00:58<00:16,  2.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      59.01 ms /   166 runs   (    0.36 ms per token,  2813.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     296.85 ms /    30 tokens (    9.90 ms per token,   101.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6166.07 ms /   165 runs   (   37.37 ms per token,    26.76 tokens per second)\n",
      "llama_print_timings:       total time =    7557.17 ms /   195 tokens\n",
      " 84%|██████████████████████████████████████████████████████████████████████████████████                | 31/37 [01:05<00:23,  3.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    19 runs   (    0.36 ms per token,  2814.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.50 ms /    35 tokens (   20.44 ms per token,    48.92 tokens per second)\n",
      "llama_print_timings:        eval time =     671.75 ms /    18 runs   (   37.32 ms per token,    26.80 tokens per second)\n",
      "llama_print_timings:       total time =    1510.75 ms /    53 tokens\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████▊             | 32/37 [01:07<00:15,  3.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    50 runs   (    0.35 ms per token,  2837.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.71 ms /    27 tokens (   10.03 ms per token,    99.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1832.33 ms /    49 runs   (   37.39 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:       total time =    2424.48 ms /    76 tokens\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████▍          | 33/37 [01:09<00:11,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      20.71 ms /    58 runs   (    0.36 ms per token,  2801.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.17 ms /    25 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2122.08 ms /    57 runs   (   37.23 ms per token,    26.86 tokens per second)\n",
      "llama_print_timings:       total time =    2755.84 ms /    82 tokens\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████        | 34/37 [01:12<00:08,  2.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      19.46 ms /    54 runs   (    0.36 ms per token,  2775.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     441.50 ms /    45 tokens (    9.81 ms per token,   101.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1987.18 ms /    53 runs   (   37.49 ms per token,    26.67 tokens per second)\n",
      "llama_print_timings:       total time =    2771.08 ms /    98 tokens\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████▋     | 35/37 [01:15<00:05,  2.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.44 ms /    49 runs   (    0.36 ms per token,  2810.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.09 ms /    45 tokens (    9.54 ms per token,   104.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1812.97 ms /    48 runs   (   37.77 ms per token,    26.48 tokens per second)\n",
      "llama_print_timings:       total time =    2555.30 ms /    93 tokens\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████▎  | 36/37 [01:17<00:02,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      66.86 ms /   191 runs   (    0.35 ms per token,  2856.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     427.26 ms /    37 tokens (   11.55 ms per token,    86.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7261.08 ms /   190 runs   (   38.22 ms per token,    26.17 tokens per second)\n",
      "llama_print_timings:       total time =    8941.88 ms /   227 tokens\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [01:26<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 5.86 s, total: 1min 33s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  retriever_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89444340-5197-4ded-aa6f-48fa03b0490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46938775510204084"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "118a7a38-b2d7-4b41-8713-8ca54e4edb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TFIDFRetriever\n",
    "\n",
    "retriever = TFIDFRetriever.from_documents(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e457d3bd-b910-48f2-be3d-ac44d10d4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 852 ms, sys: 61.3 ms, total: 913 ms\n",
      "Wall time: 942 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ea02921-75d2-4648-8d28-02f1d55a6aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30612244897959184"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccd978bc-ac74-453a-95f2-1ff699782cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from my_notion_companion.query_constructor import QueryConstructor\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qc = QueryConstructor(llm, _CONFIGS)\n",
    "\n",
    "retriever_plus = RunnableLambda(qc.invoke) | retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cff6e7bd-082b-4f69-9e87-0490e274b23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 0/37 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     7 runs   (    0.36 ms per token,  2741.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.81 ms /     7 tokens (   50.69 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =     198.40 ms /     6 runs   (   33.07 ms per token,    30.24 tokens per second)\n",
      "llama_print_timings:       total time =     599.99 ms /    13 tokens\n",
      "  3%|██▋                                                                                                | 1/37 [00:00<00:23,  1.52it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2576.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.85 ms /    25 tokens (   11.27 ms per token,    88.70 tokens per second)\n",
      "llama_print_timings:        eval time =     270.19 ms /     8 runs   (   33.77 ms per token,    29.61 tokens per second)\n",
      "llama_print_timings:       total time =     611.19 ms /    33 tokens\n",
      "  5%|█████▎                                                                                             | 2/37 [00:01<00:23,  1.50it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      15.91 ms /    45 runs   (    0.35 ms per token,  2828.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     286.32 ms /    31 tokens (    9.24 ms per token,   108.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1485.36 ms /    44 runs   (   33.76 ms per token,    29.62 tokens per second)\n",
      "llama_print_timings:       total time =    2069.76 ms /    75 tokens\n",
      "  8%|████████                                                                                           | 3/37 [00:03<00:45,  1.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      49.65 ms /   140 runs   (    0.35 ms per token,  2819.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.52 ms /    36 tokens (   22.65 ms per token,    44.14 tokens per second)\n",
      "llama_print_timings:        eval time =    4698.88 ms /   139 runs   (   33.80 ms per token,    29.58 tokens per second)\n",
      "llama_print_timings:       total time =    6438.47 ms /   175 tokens\n",
      " 11%|██████████▋                                                                                        | 4/37 [00:09<01:51,  3.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     6 runs   (    0.36 ms per token,  2806.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     422.43 ms /    33 tokens (   12.80 ms per token,    78.12 tokens per second)\n",
      "llama_print_timings:        eval time =     176.09 ms /     5 runs   (   35.22 ms per token,    28.39 tokens per second)\n",
      "llama_print_timings:       total time =     638.29 ms /    38 tokens\n",
      " 14%|█████████████▍                                                                                     | 5/37 [00:10<01:17,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      33.34 ms /    92 runs   (    0.36 ms per token,  2759.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     422.74 ms /    45 tokens (    9.39 ms per token,   106.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3075.05 ms /    91 runs   (   33.79 ms per token,    29.59 tokens per second)\n",
      "llama_print_timings:       total time =    4093.43 ms /   136 tokens\n",
      " 16%|████████████████                                                                                   | 6/37 [00:14<01:33,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      24.97 ms /    68 runs   (    0.37 ms per token,  2723.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    24 tokens (   10.43 ms per token,    95.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2273.27 ms /    67 runs   (   33.93 ms per token,    29.47 tokens per second)\n",
      "llama_print_timings:       total time =    2962.23 ms /    91 tokens\n",
      " 19%|██████████████████▋                                                                                | 7/37 [00:17<01:30,  3.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     7 runs   (    0.39 ms per token,  2542.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.19 ms /    28 tokens (    9.90 ms per token,   101.01 tokens per second)\n",
      "llama_print_timings:        eval time =     210.95 ms /     6 runs   (   35.16 ms per token,    28.44 tokens per second)\n",
      "llama_print_timings:       total time =     533.41 ms /    34 tokens\n",
      " 22%|█████████████████████▍                                                                             | 8/37 [00:18<01:04,  2.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     9 runs   (    0.35 ms per token,  2831.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.56 ms /    29 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =     269.28 ms /     8 runs   (   33.66 ms per token,    29.71 tokens per second)\n",
      "llama_print_timings:       total time =     629.79 ms /    37 tokens\n",
      " 24%|████████████████████████                                                                           | 9/37 [00:19<00:49,  1.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    19 runs   (    0.35 ms per token,  2839.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.17 ms /    26 tokens (   10.12 ms per token,    98.80 tokens per second)\n",
      "llama_print_timings:        eval time =     631.05 ms /    18 runs   (   35.06 ms per token,    28.52 tokens per second)\n",
      "llama_print_timings:       total time =    1016.50 ms /    44 tokens\n",
      " 27%|██████████████████████████▍                                                                       | 10/37 [00:20<00:41,  1.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    12 runs   (    0.35 ms per token,  2853.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     437.22 ms /    36 tokens (   12.14 ms per token,    82.34 tokens per second)\n",
      "llama_print_timings:        eval time =     383.31 ms /    11 runs   (   34.85 ms per token,    28.70 tokens per second)\n",
      "llama_print_timings:       total time =     899.35 ms /    47 tokens\n",
      " 30%|█████████████████████████████▏                                                                    | 11/37 [00:21<00:35,  1.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      20.73 ms /    58 runs   (    0.36 ms per token,  2798.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     418.35 ms /    34 tokens (   12.30 ms per token,    81.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1961.80 ms /    57 runs   (   34.42 ms per token,    29.05 tokens per second)\n",
      "llama_print_timings:       total time =    2759.41 ms /    91 tokens\n",
      " 32%|███████████████████████████████▊                                                                  | 12/37 [00:23<00:45,  1.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      15.26 ms /    42 runs   (    0.36 ms per token,  2752.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.47 ms /    28 tokens (    9.80 ms per token,   102.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1421.58 ms /    41 runs   (   34.67 ms per token,    28.84 tokens per second)\n",
      "llama_print_timings:       total time =    1965.39 ms /    69 tokens\n",
      " 35%|██████████████████████████████████▍                                                               | 13/37 [00:25<00:44,  1.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     6 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     425.91 ms /    40 tokens (   10.65 ms per token,    93.92 tokens per second)\n",
      "llama_print_timings:        eval time =     179.57 ms /     5 runs   (   35.91 ms per token,    27.84 tokens per second)\n",
      "llama_print_timings:       total time =     644.44 ms /    45 tokens\n",
      " 38%|█████████████████████████████████████                                                             | 14/37 [00:26<00:34,  1.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      26.12 ms /    71 runs   (    0.37 ms per token,  2717.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.83 ms /    40 tokens (   14.67 ms per token,    68.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2461.05 ms /    70 runs   (   35.16 ms per token,    28.44 tokens per second)\n",
      "llama_print_timings:       total time =    3525.05 ms /   110 tokens\n",
      " 41%|███████████████████████████████████████▋                                                          | 15/37 [00:30<00:47,  2.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    27 runs   (    0.35 ms per token,  2846.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     619.93 ms /    43 tokens (   14.42 ms per token,    69.36 tokens per second)\n",
      "llama_print_timings:        eval time =     911.00 ms /    26 runs   (   35.04 ms per token,    28.54 tokens per second)\n",
      "llama_print_timings:       total time =    1706.49 ms /    69 tokens\n",
      " 43%|██████████████████████████████████████████▍                                                       | 16/37 [00:32<00:42,  2.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      23.47 ms /    65 runs   (    0.36 ms per token,  2769.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.08 ms /    46 tokens (    9.31 ms per token,   107.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2260.90 ms /    64 runs   (   35.33 ms per token,    28.31 tokens per second)\n",
      "llama_print_timings:       total time =    3122.39 ms /   110 tokens\n",
      " 46%|█████████████████████████████████████████████                                                     | 17/37 [00:35<00:47,  2.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      24.66 ms /    68 runs   (    0.36 ms per token,  2757.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     437.00 ms /    47 tokens (    9.30 ms per token,   107.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2382.69 ms /    67 runs   (   35.56 ms per token,    28.12 tokens per second)\n",
      "llama_print_timings:       total time =    3268.11 ms /   114 tokens\n",
      " 49%|███████████████████████████████████████████████▋                                                  | 18/37 [00:38<00:50,  2.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     4 runs   (    0.37 ms per token,  2735.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.50 ms /    28 tokens (    9.80 ms per token,   102.01 tokens per second)\n",
      "llama_print_timings:        eval time =     112.28 ms /     3 runs   (   37.43 ms per token,    26.72 tokens per second)\n",
      "llama_print_timings:       total time =     414.10 ms /    31 tokens\n",
      " 51%|██████████████████████████████████████████████████▎                                               | 19/37 [00:39<00:36,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2670.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     455.86 ms /    41 tokens (   11.12 ms per token,    89.94 tokens per second)\n",
      "llama_print_timings:        eval time =     363.76 ms /    10 runs   (   36.38 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =     890.63 ms /    51 tokens\n",
      " 54%|████████████████████████████████████████████████████▉                                             | 20/37 [00:40<00:28,  1.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     7 runs   (    0.38 ms per token,  2665.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.42 ms /    27 tokens (    9.98 ms per token,   100.21 tokens per second)\n",
      "llama_print_timings:        eval time =     216.75 ms /     6 runs   (   36.12 ms per token,    27.68 tokens per second)\n",
      "llama_print_timings:       total time =     533.93 ms /    33 tokens\n",
      " 57%|███████████████████████████████████████████████████████▌                                          | 21/37 [00:40<00:21,  1.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    11 runs   (    0.36 ms per token,  2761.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     425.29 ms /    33 tokens (   12.89 ms per token,    77.59 tokens per second)\n",
      "llama_print_timings:        eval time =     361.77 ms /    10 runs   (   36.18 ms per token,    27.64 tokens per second)\n",
      "llama_print_timings:       total time =     861.16 ms /    43 tokens\n",
      " 59%|██████████████████████████████████████████████████████████▎                                       | 22/37 [00:41<00:18,  1.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    17 runs   (    0.36 ms per token,  2743.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.78 ms /    29 tokens (    9.75 ms per token,   102.55 tokens per second)\n",
      "llama_print_timings:        eval time =     580.83 ms /    16 runs   (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_print_timings:       total time =     977.02 ms /    45 tokens\n",
      " 62%|████████████████████████████████████████████████████████████▉                                     | 23/37 [00:42<00:16,  1.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /     5 runs   (    0.38 ms per token,  2637.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.49 ms /    25 tokens (   10.34 ms per token,    96.72 tokens per second)\n",
      "llama_print_timings:        eval time =     150.80 ms /     4 runs   (   37.70 ms per token,    26.53 tokens per second)\n",
      "llama_print_timings:       total time =     444.18 ms /    29 tokens\n",
      " 65%|███████████████████████████████████████████████████████████████▌                                  | 24/37 [00:43<00:12,  1.03it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      33.87 ms /    94 runs   (    0.36 ms per token,  2775.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.50 ms /    31 tokens (    9.44 ms per token,   105.98 tokens per second)\n",
      "llama_print_timings:        eval time =    3395.92 ms /    93 runs   (   36.52 ms per token,    27.39 tokens per second)\n",
      "llama_print_timings:       total time =    4326.96 ms /   124 tokens\n",
      " 68%|██████████████████████████████████████████████████████████████████▏                               | 25/37 [00:47<00:23,  2.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      13.97 ms /    39 runs   (    0.36 ms per token,  2790.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.16 ms /    26 tokens (   10.54 ms per token,    94.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1379.49 ms /    38 runs   (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_print_timings:       total time =    1907.57 ms /    64 tokens\n",
      " 70%|████████████████████████████████████████████████████████████████████▊                             | 26/37 [00:49<00:21,  1.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      15.88 ms /    43 runs   (    0.37 ms per token,  2706.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.86 ms /    33 tokens (   23.66 ms per token,    42.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1534.44 ms /    42 runs   (   36.53 ms per token,    27.37 tokens per second)\n",
      "llama_print_timings:       total time =    2595.72 ms /    75 tokens\n",
      " 73%|███████████████████████████████████████████████████████████████████████▌                          | 27/37 [00:52<00:21,  2.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      19.33 ms /    53 runs   (    0.36 ms per token,  2741.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.17 ms /    31 tokens (    9.52 ms per token,   105.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1891.35 ms /    52 runs   (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =    2534.96 ms /    83 tokens\n",
      " 76%|██████████████████████████████████████████████████████████████████████████▏                       | 28/37 [00:54<00:20,  2.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      14.12 ms /    39 runs   (    0.36 ms per token,  2761.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     426.75 ms /    41 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1388.69 ms /    38 runs   (   36.54 ms per token,    27.36 tokens per second)\n",
      "llama_print_timings:       total time =    2074.80 ms /    79 tokens\n",
      " 78%|████████████████████████████████████████████████████████████████████████████▊                     | 29/37 [00:56<00:18,  2.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.97 ms /    50 runs   (    0.36 ms per token,  2782.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     308.12 ms /    32 tokens (    9.63 ms per token,   103.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1803.76 ms /    49 runs   (   36.81 ms per token,    27.17 tokens per second)\n",
      "llama_print_timings:       total time =    2439.62 ms /    81 tokens\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████▍                  | 30/37 [00:59<00:16,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      60.76 ms /   166 runs   (    0.37 ms per token,  2732.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     286.62 ms /    30 tokens (    9.55 ms per token,   104.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6161.50 ms /   165 runs   (   37.34 ms per token,    26.78 tokens per second)\n",
      "llama_print_timings:       total time =    7578.33 ms /   195 tokens\n",
      " 84%|██████████████████████████████████████████████████████████████████████████████████                | 31/37 [01:07<00:23,  3.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    19 runs   (    0.36 ms per token,  2784.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     478.80 ms /    35 tokens (   13.68 ms per token,    73.10 tokens per second)\n",
      "llama_print_timings:        eval time =     668.66 ms /    18 runs   (   37.15 ms per token,    26.92 tokens per second)\n",
      "llama_print_timings:       total time =    1272.72 ms /    53 tokens\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████▊             | 32/37 [01:08<00:15,  3.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      18.36 ms /    50 runs   (    0.37 ms per token,  2723.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.44 ms /    27 tokens (    9.94 ms per token,   100.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1817.71 ms /    49 runs   (   37.10 ms per token,    26.96 tokens per second)\n",
      "llama_print_timings:       total time =    2416.60 ms /    76 tokens\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████▍          | 33/37 [01:10<00:11,  2.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      21.50 ms /    58 runs   (    0.37 ms per token,  2698.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.22 ms /    25 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2166.87 ms /    57 runs   (   38.02 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =    2826.09 ms /    82 tokens\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████        | 34/37 [01:13<00:08,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      19.66 ms /    54 runs   (    0.36 ms per token,  2747.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.60 ms /    45 tokens (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1988.32 ms /    53 runs   (   37.52 ms per token,    26.66 tokens per second)\n",
      "llama_print_timings:       total time =    3091.18 ms /    98 tokens\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████▋     | 35/37 [01:16<00:06,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      17.41 ms /    49 runs   (    0.36 ms per token,  2814.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.57 ms /    45 tokens (    9.52 ms per token,   105.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1804.66 ms /    48 runs   (   37.60 ms per token,    26.60 tokens per second)\n",
      "llama_print_timings:       total time =    2558.45 ms /    93 tokens\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████▎  | 36/37 [01:19<00:02,  2.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6547.34 ms\n",
      "llama_print_timings:      sample time =      68.39 ms /   191 runs   (    0.36 ms per token,  2792.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.20 ms /    37 tokens (   11.46 ms per token,    87.22 tokens per second)\n",
      "llama_print_timings:        eval time =    7237.52 ms /   190 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
      "llama_print_timings:       total time =    8952.86 ms /   227 tokens\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [01:28<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 6.39 s, total: 1min 35s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  retriever_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a1795d7-da79-42b6-9c19-4cf89dc3bea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45abd8d9-7b31-41f5-b9e0-b0c2723322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pretty_print(docs):\n",
    "    for doc in docs:\n",
    "        print(doc.metadata)\n",
    "        print(doc.page_content)\n",
    "        print(\"\\n\" + \"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "251a2fe8-050d-414e-b319-4f3f73e44676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': '孔子', 'date': {'start': '2019-05-16', 'end': None, 'time_zone': None}, 'tags': ['古文'], 'name': '论语', 'id': 'f27c7f42-c7c1-4e24-bee5-0fcbdccd1cd1'}\n",
      "1.6 子曰：“弟子入则孝，出则弟，谨而信，泛爱众，而亲仁。行有余力，则以学文。”\n",
      "\n",
      "1.7 子夏曰：“贤贤易色；事父母，能竭其力；事君，能致其身；与朋友交，言而有信。虽曰未学，吾必谓之学矣。”\n",
      "\n",
      "1.8 子曰：“君子不重则不威，学则不固。主忠信，无友不如己者，过则勿惮改。”\n",
      "【不如己者：与自己志趣不同的人，而不应理解为不如自己的人。这五句话没有什么联系，可能是孔子在不同场合说的。】\n",
      "\n",
      "1.10 子禽问于子贡曰：“夫子至于是邦也，必闻其政，求之与，抑与之与？”子贡曰：“夫子温、良、恭、俭、让以得之。夫子之求之也，其诸异乎人之求之与？”\n",
      "\n",
      "1.12 有子曰：“礼之用，和为贵。先王之道，斯为美，小大由之。有所不行，知和而和，不以礼节之，亦不可行也。”\n",
      "\n",
      "1.14 子曰：“君子食无求饱，居无求安，敏于事而慎于言，就有道而正焉。可谓好学也已。”\n",
      "\n",
      "------------------------------\n",
      "{'author': None, 'date': {'start': '2013-08-12', 'end': None, 'time_zone': None}, 'tags': ['古文'], 'name': '高中古诗文', 'id': '0c77a756-a81d-486d-83de-2de6fb7e9e5d'}\n",
      "《子路、曾皙、冉有、公西华侍坐》（论语）\n",
      "子路、曾皙、冉有、公西华侍坐。子曰：“以吾一日长乎尔，毋吾以也。居则曰：‘不吾知也。’如或知尔，则何以哉？”\n",
      "子路率尔而对曰：“千乘之国，摄乎大国之间，加之以师旅，因之以饥馑；由也为之，比及三年，可使有勇，且知方也。”\n",
      "夫子哂（shěn）之。\n",
      "“求，尔何如？”\n",
      "对曰：“方六七十，如五六十，求也为之，比及三年，可使足民。如其礼乐，以俟君子。”\n",
      "“赤，尔何如？”\n",
      "对曰：“非曰能之，愿学焉。宗庙之事，如会同，端章甫，愿为小相焉。”\n",
      "“点，尔何如？”\n",
      "鼓瑟希，铿尔，舍瑟而作，对曰：“异乎三子者之撰。”\n",
      "子曰：“何伤乎？亦各言其志也！”\n",
      "曰：“莫春者，春服既成，冠者五六人，童子六七人，浴乎沂（yí），风（fèng）乎舞雩（yú），咏而归。”\n",
      "夫子喟然叹曰：“吾与（yǔ）点也。”\n",
      "三子者出，曾皙后。曾皙曰：“夫三子者之言何如？”\n",
      "子曰：“亦各言其志也已矣！”\n",
      "曰：“夫子何哂由也？”\n",
      "曰：“为国以礼，其言不让，是故哂之。唯求则非邦也与？安见方六七十，如五六十而非邦也者？唯赤则非邦也与？宗庙会同，非诸侯而何？赤也为之小，孰能为之大？”\n",
      "\n",
      "------------------------------\n",
      "{'author': '【中】冯友兰', 'date': {'start': '2023-05-06', 'end': None, 'time_zone': None}, 'tags': ['人文'], 'name': '中国哲学简史', 'id': '0419517a-59be-47a2-a4b9-bb6f21630614'}\n",
      "《孟子》中说：“杨子取为我，拔一毛而利天下，不为也。”；《吕氏春秋》中说：“陌生贵己。”；《淮南子》中写：“全性保真，不以物累形：杨子所立也。”这些是同时代的著作中对杨朱思想的记录和反映\n",
      "在道家更后期的《老子》和《庄子》中也有相同的体现。《老子》中写到：“名与身：孰亲？身与货：孰多？”《庄子》中写到：“山木自寇也。膏火自煎也，桂可食，故伐之。漆可用，故割之。”\n",
      "无用是全生的方法。善于全生的人，一定不能多为恶，但也一定不能多为善。他一定要生活在善恶之间，力求无用。到头来，无用却对于他有大用\n",
      "从为我到无我：先秦道家发展三阶段\n",
      "先秦道家都是为我的，但是随着思考的深入，后来的发展使这种为我走向反面，取消了它自身\n",
      "第一阶段杨朱，出发点是全生避害\n",
      "第二阶段老子，开始企图揭示宇宙事物变化的规律。一个人如果懂得了这些规律，并且遵循规律而调整行动，那么他就能够使事物转向对他有利的方向。但即便一个人懂得自然规律，预料之外的因素仍然会发挥作用，并带来可能的危害（“吾所以有大患者，为吾有身，及吾无身，吾有何患！”）\n",
      "\n",
      "------------------------------\n",
      "{'author': '孔子', 'date': {'start': '2019-05-16', 'end': None, 'time_zone': None}, 'tags': ['古文'], 'name': '论语', 'id': 'f27c7f42-c7c1-4e24-bee5-0fcbdccd1cd1'}\n",
      "第一次阅读：2019.05.19 杨伯峻《论语译注》\n",
      "第二次阅读：2023.12.01 罗晓晖《论语译释》\n",
      "\n",
      "\n",
      "学而第一\n",
      "\n",
      "1.1 子曰：“学而时习之，不亦说乎？有朋自远方来，不亦乐乎？人不知而不愠，不亦君子乎？\n",
      "【”说“和“乐”的区别——《说文》：“说，释也。”因此”说“有”说开“、”开解“的意思，”说“通”悦“时，表示心情舒张。而”乐“是乐器，因此这种情绪是被音乐激发的、感动于物的。】\n",
      "\n",
      "1.2 有子曰：“其为人也孝弟，而好犯上者，鲜矣；不好犯上，而好作乱者，未之有也。君子务本，本立而道生。孝弟也者，其为仁之本与！\n",
      "\n",
      "1.3 子曰：“巧言令色，鲜矣仁！”\n",
      "\n",
      "1.4 曾子曰：“吾日三省吾身：为人谋而不忠乎？与朋友交而不信乎？传不习乎？“\n",
      "【曾子对修身的理解谈到了品德和学习。而孔子论学（1.1）的站位更高，指向生命的愉悦和不假外求的自我圆满（“人不知而不愠”）】\n",
      "\n",
      "1.6 子曰：“弟子入则孝，出则弟，谨而信，泛爱众，而亲仁。行有余力，则以学文。”\n",
      "\n",
      "1.7 子夏曰：“贤贤易色；事父母，能竭其力；事君，能致其身；与朋友交，言而有信。虽曰未学，吾必谓之学矣。”\n",
      "\n",
      "------------------------------\n",
      "None\n",
      "{'q': '“子非吾友也”的出处是哪里？', 'a': '“子非吾友也”来自刘义庆所作的《世说新语》。原文为：\\\\n管宁、华歆共园中锄菜，见地有片金，管挥锄与瓦石不异，华捉而掷去之。又尝同席读书，有乘轩冕过门者，宁读如故，歆废书出看。宁割席分坐曰：“子非吾友也。”', 'docs': ['德行第一一一\\\\n管宁、华歆共园中锄菜，见地有片金，管挥锄与瓦石不异，华捉而掷去之。又尝同席读书，有乘轩冕过门者，宁读如故，歆废书出看。宁割席分坐曰：“子非吾友也。”', '世说新语\\n']}\n",
      "--------------------\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "i = -5\n",
    "case = test_cases[i]\n",
    "\n",
    "docs_retrieved = retriever.invoke(case['q'])\n",
    "print(_pretty_print(docs_retrieved))\n",
    "# print(docs_retrieved)\n",
    "print(case)\n",
    "print(\"-\"*20)\n",
    "for ref in case['docs']:\n",
    "    print(match_chinese(ref, docs_retrieved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dbe31-0d66-4d66-8c63-1ed66aba7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
