{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccf3a26-c0f0-4830-bcc3-dc50a316d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54e41e7-6407-4634-aa05-4c82342d8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4419f65f-7af1-4010-8fe4-f9f78b594247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_notion_companion.retriever import SelfQueryAgent, BasicRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e3932c-0c14-4e6f-8f16-1a664d915c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! conversation is not default parameter.\n",
      "                conversation was transferred to model_kwargs.\n",
      "                Please confirm that conversation is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 259 tensors from /Users/fred/Documents/models/Qwen-7B-Chat.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen\n",
      "llama_model_loader: - kv   1:                               general.name str              = Qwen\n",
      "llama_model_loader: - kv   2:                        qwen.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                           qwen.block_count u32              = 32\n",
      "llama_model_loader: - kv   4:                      qwen.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                   qwen.feed_forward_length u32              = 22016\n",
      "llama_model_loader: - kv   6:                        qwen.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv   7:                  qwen.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                  qwen.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:      qwen.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  11:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  12:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  14:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  16:            tokenizer.ggml.unknown_token_id u32              = 151643\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q4_K:  113 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 293/151936 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 22016\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.72 B\n",
      "llm_load_print_meta: model size       = 4.56 GiB (5.07 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen\n",
      "llm_load_print_meta: BOS token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: EOS token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: UNK token        = 151643 '[PAD151643]'\n",
      "llm_load_print_meta: LF token         = 148848 'ÄĬ'\n",
      "llm_load_tensors: ggml ctx size =    0.20 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4666.59 MiB, ( 4666.66 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4450.41 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4666.59 MiB\n",
      ".....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  2048.00 MiB, ( 6716.22 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  2048.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    80.04 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1248.02 MiB, ( 7964.23 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1248.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1251.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 4\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.ggml.unknown_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'qwen.attention.head_count': '32', 'qwen.rope.freq_base': '10000.000000', 'tokenizer.ggml.bos_token_id': '151643', 'qwen.feed_forward_length': '22016', 'qwen.attention.layer_norm_rms_epsilon': '0.000001', 'qwen.embedding_length': '4096', 'qwen.rope.dimension_count': '128', 'qwen.context_length': '32768', 'qwen.block_count': '32', 'general.name': 'Qwen', 'general.architecture': 'qwen'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "import tomllib\n",
    "\n",
    "with open('../.config.toml', 'rb') as f:\n",
    "    _CONFIGS = tomllib.load(f)\n",
    "\n",
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=_CONFIGS['model_path']+'/'+'Qwen-7B-Chat.Q4_K_M.gguf',\n",
    "    name='Qwen/Qwen-7B-Chat', \n",
    "    **_CONFIGS['llm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b276b2-8e7e-442b-b555-ea80adf5cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q': '什么是我国第一部编年史著作？', 'a': '《左传》。', 'docs': ['附：《左传》是我国第一部编年史著作。\\n']},\n",
       " {'q': '什么是我国第一部编年国别史？', 'a': '《国语》。', 'docs': ['附：《国语》是我国第一部编年国别史。\\n']},\n",
       " {'q': '“寡人之于国也”下一句是什么？来自哪里？',\n",
       "  'a': '“寡人之于国也”下一句是“尽心焉耳矣”。这个句子来自《孟子》。',\n",
       "  'docs': ['梁惠王曰：“寡人之于国也，尽心焉耳矣。河内凶，则移其民于河东，移其粟于河内；河东凶亦然。察邻国之政，无如寡人之用心者。邻国之民不加少，寡人之民不加多，何也？”',\n",
       "   '《寡人之于国也》（孟子）\\n']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('../data/test_cases.txt') as f:\n",
    "    test_cases_raw = f.readlines()\n",
    "\n",
    "test_cases_raw = \"\".join(test_cases_raw[0:-1:2]).split('问：')[1:]\n",
    "test_cases_raw = [re.split(r'\\n答：|\\n资料：', x) for x in test_cases_raw]\n",
    "test_cases = [{'q': x[0], 'a': x[1], 'docs': x[2:]} for x in test_cases_raw]\n",
    "\n",
    "test_cases[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a024effd-47ca-48b9-b207-c6d0a7e08a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6d5b25-9140-4510-b48e-3f216881c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_retriever(test_cases, retriever):\n",
    "    score_list = list()\n",
    "\n",
    "    for case in tqdm(test_cases):\n",
    "        docs_retrieved = retriever.invoke(case['q'])\n",
    "        contains_all_ref = list()\n",
    "        for ref in case['docs']:\n",
    "            contains_all_ref.append(any([ref in x.page_content for x in docs_retrieved]))\n",
    "        \n",
    "        score_list.extend(contains_all_ref)\n",
    "\n",
    "    return sum(score_list)/len(score_list), score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e9f309-a4b3-4248-884c-d258b1d4f9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key tags not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_start not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 118 ms, total: 1.25 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  BasicRetriever(llm, _CONFIGS, _TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730781a6-9063-4e40-a130-b318a2fc3b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5cb0a36-373a-461f-a385-5e4f52027467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.75 ms /   256 runs   (    0.36 ms per token,  2790.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8354.64 ms /  1134 tokens (    7.37 ms per token,   135.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12966.16 ms /   255 runs   (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_print_timings:       total time =   23012.52 ms /  1389 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.92 ms /   256 runs   (    0.37 ms per token,  2697.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1999.07 ms /   298 tokens (    6.71 ms per token,   149.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10150.56 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:       total time =   13780.02 ms /   553 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.68 ms /   256 runs   (    0.37 ms per token,  2675.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3388.28 ms /   585 tokens (    5.79 ms per token,   172.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10857.59 ms /   255 runs   (   42.58 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time =   15909.01 ms /   840 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      32.68 ms /    93 runs   (    0.35 ms per token,  2845.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.92 ms /    27 tokens (   10.77 ms per token,    92.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3609.90 ms /    92 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:       total time =    4495.86 ms /   119 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.36 ms /   256 runs   (    0.36 ms per token,  2802.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3536.18 ms /   635 tokens (    5.57 ms per token,   179.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10933.05 ms /   255 runs   (   42.87 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time =   16130.06 ms /   890 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.45 ms /   256 runs   (    0.35 ms per token,  2830.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6032.62 ms /  1134 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11423.53 ms /   255 runs   (   44.80 ms per token,    22.32 tokens per second)\n",
      "llama_print_timings:       total time =   19266.88 ms /  1389 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.28 ms /   256 runs   (    0.36 ms per token,  2744.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5476.65 ms /   922 tokens (    5.94 ms per token,   168.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11146.94 ms /   255 runs   (   43.71 ms per token,    22.88 tokens per second)\n",
      "llama_print_timings:       total time =   18343.28 ms /  1177 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.42 ms /   256 runs   (    0.37 ms per token,  2682.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2640.90 ms /   426 tokens (    6.20 ms per token,   161.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10812.99 ms /   255 runs   (   42.40 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time =   15347.02 ms /   681 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.72 ms /   256 runs   (    0.38 ms per token,  2619.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.76 ms /    27 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10165.12 ms /   255 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:       total time =   12535.33 ms /   282 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.21 ms /   256 runs   (    0.37 ms per token,  2688.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.18 ms /    12 tokens (   17.01 ms per token,    58.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10186.68 ms /   255 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:       total time =   12092.74 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.53 ms /   256 runs   (    0.35 ms per token,  2827.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6193.64 ms /  1140 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
      "llama_print_timings:        eval time =   11549.18 ms /   255 runs   (   45.29 ms per token,    22.08 tokens per second)\n",
      "llama_print_timings:       total time =   19812.30 ms /  1395 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    30 runs   (    0.45 ms per token,  2207.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6203.65 ms /  1180 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1770.51 ms /    29 runs   (   61.05 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:       total time =    8467.44 ms /  1209 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.00 ms /   256 runs   (    0.37 ms per token,  2723.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.47 ms /    11 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =   10175.93 ms /   255 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:       total time =   12049.43 ms /   266 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.75 ms /   256 runs   (    0.37 ms per token,  2673.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2736.48 ms /   451 tokens (    6.07 ms per token,   164.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10725.90 ms /   255 runs   (   42.06 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time =   15424.73 ms /   706 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.58 ms /   256 runs   (    0.37 ms per token,  2735.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.40 ms /   126 tokens (    8.58 ms per token,   116.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10249.72 ms /   255 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:       total time =   12996.24 ms /   381 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.92 ms /   256 runs   (    0.37 ms per token,  2725.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6026.07 ms /  1145 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12051.89 ms /   255 runs   (   47.26 ms per token,    21.16 tokens per second)\n",
      "llama_print_timings:       total time =   19872.04 ms /  1400 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.96 ms /   256 runs   (    0.38 ms per token,  2613.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1961.47 ms /   306 tokens (    6.41 ms per token,   156.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10161.39 ms /   255 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:       total time =   13809.73 ms /   561 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.70 ms /   256 runs   (    0.39 ms per token,  2593.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.78 ms /     6 tokens (   33.46 ms per token,    29.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10170.94 ms /   255 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =   12049.17 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.12 ms /   256 runs   (    0.38 ms per token,  2635.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.98 ms /     6 tokens (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10154.54 ms /   255 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =   11975.41 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.21 ms /   256 runs   (    0.37 ms per token,  2688.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3530.11 ms /   631 tokens (    5.59 ms per token,   178.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10952.92 ms /   255 runs   (   42.95 ms per token,    23.28 tokens per second)\n",
      "llama_print_timings:       total time =   16774.60 ms /   886 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.58 ms /   256 runs   (    0.36 ms per token,  2795.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5995.46 ms /  1142 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11402.47 ms /   255 runs   (   44.72 ms per token,    22.36 tokens per second)\n",
      "llama_print_timings:       total time =   19128.35 ms /  1397 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.84 ms /   256 runs   (    0.38 ms per token,  2643.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2721.30 ms /   476 tokens (    5.72 ms per token,   174.92 tokens per second)\n",
      "llama_print_timings:        eval time =   10374.64 ms /   255 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =   15038.98 ms /   731 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.63 ms /   256 runs   (    0.37 ms per token,  2705.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3945.85 ms /   693 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11234.44 ms /   255 runs   (   44.06 ms per token,    22.70 tokens per second)\n",
      "llama_print_timings:       total time =   16924.13 ms /   948 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.91 ms /   256 runs   (    0.38 ms per token,  2641.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.03 ms /    19 tokens (   13.58 ms per token,    73.64 tokens per second)\n",
      "llama_print_timings:        eval time =   10119.60 ms /   255 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:       total time =   12326.91 ms /   274 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.42 ms /   256 runs   (    0.37 ms per token,  2682.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2171.66 ms /   333 tokens (    6.52 ms per token,   153.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10540.68 ms /   255 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =   14684.79 ms /   588 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.17 ms /   256 runs   (    0.36 ms per token,  2808.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6225.65 ms /  1154 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11962.47 ms /   255 runs   (   46.91 ms per token,    21.32 tokens per second)\n",
      "llama_print_timings:       total time =   20195.03 ms /  1409 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.41 ms /   256 runs   (    0.36 ms per token,  2740.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2985.78 ms /   489 tokens (    6.11 ms per token,   163.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10385.71 ms /   255 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =   15070.63 ms /   744 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.72 ms /   256 runs   (    0.38 ms per token,  2619.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.47 ms /    66 tokens (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10226.32 ms /   255 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:       total time =   12984.45 ms /   321 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.34 ms /   256 runs   (    0.38 ms per token,  2603.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4960.04 ms /   904 tokens (    5.49 ms per token,   182.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11430.29 ms /   255 runs   (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_print_timings:       total time =   18133.84 ms /  1159 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.46 ms /   256 runs   (    0.37 ms per token,  2710.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2669.09 ms /   423 tokens (    6.31 ms per token,   158.48 tokens per second)\n",
      "llama_print_timings:        eval time =   10686.77 ms /   255 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time =   15252.78 ms /   678 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.54 ms /   256 runs   (    0.36 ms per token,  2796.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6101.96 ms /  1133 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11798.39 ms /   255 runs   (   46.27 ms per token,    21.61 tokens per second)\n",
      "llama_print_timings:       total time =   19891.61 ms /  1388 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     102.26 ms /   256 runs   (    0.40 ms per token,  2503.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5354.71 ms /   986 tokens (    5.43 ms per token,   184.14 tokens per second)\n",
      "llama_print_timings:        eval time =   11217.59 ms /   255 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time =   18690.06 ms /  1241 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     134.21 ms /   256 runs   (    0.52 ms per token,  1907.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4270.27 ms /   607 tokens (    7.04 ms per token,   142.15 tokens per second)\n",
      "llama_print_timings:        eval time =   17794.13 ms /   255 runs   (   69.78 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:       total time =   24762.12 ms /   862 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.32 ms /   256 runs   (    0.38 ms per token,  2603.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2368.32 ms /   376 tokens (    6.30 ms per token,   158.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10918.25 ms /   255 runs   (   42.82 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time =   15490.17 ms /   631 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.77 ms /   256 runs   (    0.37 ms per token,  2672.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.11 ms /    21 tokens (   13.05 ms per token,    76.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10352.44 ms /   255 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =   13212.79 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.37 ms /   256 runs   (    0.37 ms per token,  2684.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6893.36 ms /  1137 tokens (    6.06 ms per token,   164.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12274.45 ms /   255 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_print_timings:       total time =   21409.41 ms /  1392 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.08 ms /   256 runs   (    0.35 ms per token,  2841.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     297.59 ms /    17 tokens (   17.51 ms per token,    57.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11249.08 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =   13242.00 ms /   272 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.12 ms /   256 runs   (    0.36 ms per token,  2749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1969.37 ms /   299 tokens (    6.59 ms per token,   151.83 tokens per second)\n",
      "llama_print_timings:        eval time =   10188.67 ms /   255 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:       total time =   13891.73 ms /   554 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.91 ms /   256 runs   (    0.36 ms per token,  2755.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.63 ms /    10 tokens (   19.16 ms per token,    52.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10168.12 ms /   255 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =   12026.53 ms /   265 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.89 ms /   256 runs   (    0.37 ms per token,  2669.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3248.97 ms /   564 tokens (    5.76 ms per token,   173.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10874.81 ms /   255 runs   (   42.65 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time =   16223.44 ms /   819 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.69 ms /   256 runs   (    0.36 ms per token,  2761.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.29 ms /     6 tokens (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10183.40 ms /   255 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
      "llama_print_timings:       total time =   12052.12 ms /   261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.61 ms /   256 runs   (    0.35 ms per token,  2825.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6070.08 ms /  1135 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11863.79 ms /   255 runs   (   46.52 ms per token,    21.49 tokens per second)\n",
      "llama_print_timings:       total time =   19708.48 ms /  1390 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.87 ms /   256 runs   (    0.35 ms per token,  2817.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.00 ms /    23 tokens (   14.35 ms per token,    69.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11214.51 ms /   255 runs   (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13223.51 ms /   278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.74 ms /   256 runs   (    0.35 ms per token,  2821.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.86 ms /    21 tokens (   14.09 ms per token,    70.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11212.39 ms /   255 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13190.00 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.48 ms /   256 runs   (    0.37 ms per token,  2738.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.78 ms /    16 tokens (   17.86 ms per token,    55.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11206.73 ms /   255 runs   (   43.95 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =   13223.79 ms /   271 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.11 ms /   256 runs   (    0.38 ms per token,  2636.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5000.49 ms /   897 tokens (    5.57 ms per token,   179.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11136.68 ms /   255 runs   (   43.67 ms per token,    22.90 tokens per second)\n",
      "llama_print_timings:       total time =   18202.66 ms /  1152 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    27 runs   (    0.39 ms per token,  2583.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.65 ms /   278 tokens (    6.78 ms per token,   147.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1066.84 ms /    26 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =    3184.81 ms /   304 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      21.15 ms /    56 runs   (    0.38 ms per token,  2647.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    21 tokens (   12.03 ms per token,    83.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2174.01 ms /    55 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
      "llama_print_timings:       total time =    2796.18 ms /    76 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.52 ms /   256 runs   (    0.37 ms per token,  2680.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.53 ms /   157 tokens (    6.51 ms per token,   153.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10330.46 ms /   255 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:       total time =   13265.65 ms /   412 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.60 ms /   256 runs   (    0.36 ms per token,  2764.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6120.82 ms /  1149 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12205.45 ms /   255 runs   (   47.86 ms per token,    20.89 tokens per second)\n",
      "llama_print_timings:       total time =   20475.40 ms /  1404 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.31 ms /   256 runs   (    0.37 ms per token,  2686.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5304.61 ms /   981 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11314.26 ms /   255 runs   (   44.37 ms per token,    22.54 tokens per second)\n",
      "llama_print_timings:       total time =   18450.07 ms /  1236 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.09 ms /   256 runs   (    0.38 ms per token,  2636.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3439.46 ms /   598 tokens (    5.75 ms per token,   173.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10946.19 ms /   255 runs   (   42.93 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time =   16106.41 ms /   853 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      17.08 ms /    46 runs   (    0.37 ms per token,  2693.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3383.68 ms /   589 tokens (    5.74 ms per token,   174.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1913.04 ms /    45 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
      "llama_print_timings:       total time =    5609.73 ms /   634 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.11 ms /   256 runs   (    0.38 ms per token,  2609.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2499.34 ms /   396 tokens (    6.31 ms per token,   158.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10679.11 ms /   255 runs   (   41.88 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time =   15252.01 ms /   651 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.03 ms /   256 runs   (    0.36 ms per token,  2812.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6147.25 ms /  1149 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12271.46 ms /   255 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =   20481.37 ms /  1404 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.49 ms /   256 runs   (    0.37 ms per token,  2680.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5119.66 ms /   950 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.78 ms /   255 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time =   18056.50 ms /  1205 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.15 ms /   256 runs   (    0.38 ms per token,  2635.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3383.68 ms /   581 tokens (    5.82 ms per token,   171.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10901.66 ms /   255 runs   (   42.75 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =   15989.68 ms /   836 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.32 ms /   256 runs   (    0.36 ms per token,  2743.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4141.58 ms /   602 tokens (    6.88 ms per token,   145.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12193.82 ms /   255 runs   (   47.82 ms per token,    20.91 tokens per second)\n",
      "llama_print_timings:       total time =   18076.03 ms /   857 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.82 ms /   256 runs   (    0.38 ms per token,  2644.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2751.78 ms /   461 tokens (    5.97 ms per token,   167.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10837.50 ms /   255 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time =   15526.93 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.85 ms /   256 runs   (    0.36 ms per token,  2787.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6406.37 ms /  1152 tokens (    5.56 ms per token,   179.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12428.41 ms /   255 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_print_timings:       total time =   21157.31 ms /  1407 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.44 ms /   256 runs   (    0.38 ms per token,  2654.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4791.05 ms /   788 tokens (    6.08 ms per token,   164.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13069.95 ms /   255 runs   (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:       total time =   20073.82 ms /  1043 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.23 ms /   256 runs   (    0.38 ms per token,  2660.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.29 ms /    97 tokens (   13.97 ms per token,    71.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10370.92 ms /   255 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:       total time =   13823.48 ms /   352 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.06 ms /   256 runs   (    0.37 ms per token,  2692.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2596.72 ms /   396 tokens (    6.56 ms per token,   152.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10807.25 ms /   255 runs   (   42.38 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time =   15279.63 ms /   651 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     103.52 ms /   256 runs   (    0.40 ms per token,  2473.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4626.60 ms /   677 tokens (    6.83 ms per token,   146.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12688.87 ms /   255 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:       total time =   19573.56 ms /   932 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.19 ms /   256 runs   (    0.38 ms per token,  2607.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6797.89 ms /  1156 tokens (    5.88 ms per token,   170.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11680.89 ms /   255 runs   (   45.81 ms per token,    21.83 tokens per second)\n",
      "llama_print_timings:       total time =   21043.11 ms /  1411 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.71 ms /   256 runs   (    0.37 ms per token,  2674.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7101.69 ms /  1006 tokens (    7.06 ms per token,   141.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15145.91 ms /   255 runs   (   59.40 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:       total time =   24460.03 ms /  1261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    34 runs   (    0.41 ms per token,  2467.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1810.83 ms /    56 tokens (   32.34 ms per token,    30.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1614.54 ms /    33 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_print_timings:       total time =    3735.07 ms /    89 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.52 ms /   256 runs   (    0.37 ms per token,  2680.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3293.00 ms /   403 tokens (    8.17 ms per token,   122.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11901.56 ms /   255 runs   (   46.67 ms per token,    21.43 tokens per second)\n",
      "llama_print_timings:       total time =   17341.14 ms /   658 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.01 ms /   256 runs   (    0.38 ms per token,  2666.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.23 ms /    61 tokens (   16.22 ms per token,    61.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10434.19 ms /   255 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   13647.37 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.35 ms /   256 runs   (    0.37 ms per token,  2713.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8080.23 ms /  1157 tokens (    6.98 ms per token,   143.19 tokens per second)\n",
      "llama_print_timings:        eval time =   15016.95 ms /   255 runs   (   58.89 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:       total time =   26086.48 ms /  1412 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    22 runs   (    0.41 ms per token,  2465.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2886.82 ms /   512 tokens (    5.64 ms per token,   177.36 tokens per second)\n",
      "llama_print_timings:        eval time =     859.10 ms /    21 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =    3939.32 ms /   533 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.13 ms /   256 runs   (    0.39 ms per token,  2582.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2530.63 ms /   363 tokens (    6.97 ms per token,   143.44 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.67 ms /   255 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time =   15492.32 ms /   618 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      16.46 ms /    46 runs   (    0.36 ms per token,  2795.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3574.06 ms /   637 tokens (    5.61 ms per token,   178.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1957.45 ms /    45 runs   (   43.50 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =    5941.25 ms /   682 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.21 ms /   256 runs   (    0.38 ms per token,  2660.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2437.81 ms /   397 tokens (    6.14 ms per token,   162.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10827.17 ms /   255 runs   (   42.46 ms per token,    23.55 tokens per second)\n",
      "llama_print_timings:       total time =   15053.50 ms /   652 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.84 ms /   256 runs   (    0.36 ms per token,  2757.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6561.81 ms /  1138 tokens (    5.77 ms per token,   173.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11505.44 ms /   255 runs   (   45.12 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time =   20255.99 ms /  1393 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.60 ms /   256 runs   (    0.38 ms per token,  2622.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7023.22 ms /   900 tokens (    7.80 ms per token,   128.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11147.82 ms /   255 runs   (   43.72 ms per token,    22.87 tokens per second)\n",
      "llama_print_timings:       total time =   20331.78 ms /  1155 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.40 ms /   256 runs   (    0.38 ms per token,  2601.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.18 ms /   274 tokens (    6.80 ms per token,   147.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10572.86 ms /   255 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   14598.22 ms /   529 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     102.42 ms /   256 runs   (    0.40 ms per token,  2499.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3299.00 ms /   576 tokens (    5.73 ms per token,   174.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11062.38 ms /   255 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
      "llama_print_timings:       total time =   16182.01 ms /   831 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.41 ms /   256 runs   (    0.37 ms per token,  2683.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3697.45 ms /   667 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11211.13 ms /   255 runs   (   43.97 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =   16696.83 ms /   922 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.78 ms /   256 runs   (    0.36 ms per token,  2759.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6289.38 ms /  1150 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12263.23 ms /   255 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_print_timings:       total time =   20652.37 ms /  1405 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.43 ms /   256 runs   (    0.37 ms per token,  2682.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4764.87 ms /   833 tokens (    5.72 ms per token,   174.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11890.20 ms /   255 runs   (   46.63 ms per token,    21.45 tokens per second)\n",
      "llama_print_timings:       total time =   18952.25 ms /  1088 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.27 ms /   256 runs   (    0.38 ms per token,  2631.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1701.16 ms /   234 tokens (    7.27 ms per token,   137.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10429.51 ms /   255 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =   14328.92 ms /   489 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    31 runs   (    0.38 ms per token,  2626.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     305.81 ms /    25 tokens (   12.23 ms per token,    81.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.32 ms /    30 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
      "llama_print_timings:       total time =    1753.83 ms /    55 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.87 ms /   256 runs   (    0.38 ms per token,  2642.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.63 ms /   297 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10558.06 ms /   255 runs   (   41.40 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =   13928.97 ms /   552 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.91 ms /   256 runs   (    0.37 ms per token,  2725.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6367.32 ms /  1136 tokens (    5.61 ms per token,   178.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11988.44 ms /   255 runs   (   47.01 ms per token,    21.27 tokens per second)\n",
      "llama_print_timings:       total time =   20546.01 ms /  1391 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.11 ms /   256 runs   (    0.37 ms per token,  2691.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3866.63 ms /   696 tokens (    5.56 ms per token,   180.00 tokens per second)\n",
      "llama_print_timings:        eval time =   10655.67 ms /   255 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =   16238.06 ms /   951 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.78 ms /   256 runs   (    0.38 ms per token,  2645.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2466.34 ms /   413 tokens (    5.97 ms per token,   167.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10654.05 ms /   255 runs   (   41.78 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =   14808.92 ms /   668 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.18 ms /   256 runs   (    0.38 ms per token,  2661.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.98 ms /    21 tokens (   12.19 ms per token,    82.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10158.36 ms /   255 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:       total time =   12494.19 ms /   276 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.07 ms /   256 runs   (    0.37 ms per token,  2692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3750.66 ms /   655 tokens (    5.73 ms per token,   174.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11030.34 ms /   255 runs   (   43.26 ms per token,    23.12 tokens per second)\n",
      "llama_print_timings:       total time =   16729.37 ms /   910 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.32 ms /   256 runs   (    0.36 ms per token,  2743.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6496.24 ms /  1142 tokens (    5.69 ms per token,   175.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12179.27 ms /   255 runs   (   47.76 ms per token,    20.94 tokens per second)\n",
      "llama_print_timings:       total time =   20759.06 ms /  1397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.76 ms /   256 runs   (    0.35 ms per token,  2820.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.99 ms /    17 tokens (   17.41 ms per token,    57.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11212.84 ms /   255 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13183.72 ms /   272 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.16 ms /   256 runs   (    0.38 ms per token,  2662.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3544.57 ms /   623 tokens (    5.69 ms per token,   175.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10571.22 ms /   255 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   16293.50 ms /   878 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.60 ms /   256 runs   (    0.39 ms per token,  2596.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3152.23 ms /   541 tokens (    5.83 ms per token,   171.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10877.76 ms /   255 runs   (   42.66 ms per token,    23.44 tokens per second)\n",
      "llama_print_timings:       total time =   15956.14 ms /   796 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.47 ms /   256 runs   (    0.38 ms per token,  2653.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1986.26 ms /   259 tokens (    7.67 ms per token,   130.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10488.54 ms /   255 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
      "llama_print_timings:       total time =   14302.26 ms /   514 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    25 runs   (    0.37 ms per token,  2670.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3231.03 ms /   557 tokens (    5.80 ms per token,   172.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1016.52 ms /    24 runs   (   42.36 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time =    4419.43 ms /   581 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.13 ms /   256 runs   (    0.36 ms per token,  2748.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6141.61 ms /  1135 tokens (    5.41 ms per token,   184.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11399.00 ms /   255 runs   (   44.70 ms per token,    22.37 tokens per second)\n",
      "llama_print_timings:       total time =   19630.32 ms /  1390 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.60 ms /   256 runs   (    0.38 ms per token,  2650.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1979.50 ms /   295 tokens (    6.71 ms per token,   149.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10159.80 ms /   255 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:       total time =   14316.78 ms /   550 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.66 ms /   256 runs   (    0.37 ms per token,  2733.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.64 ms /     6 tokens (   36.94 ms per token,    27.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10130.46 ms /   255 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:       total time =   12044.01 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.74 ms /   256 runs   (    0.36 ms per token,  2760.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     166.87 ms /     6 tokens (   27.81 ms per token,    35.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10150.73 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:       total time =   11972.93 ms /   261 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.33 ms /   256 runs   (    0.37 ms per token,  2713.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.41 ms /     9 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10173.20 ms /   255 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =   12084.02 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.24 ms /   256 runs   (    0.36 ms per token,  2745.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6067.86 ms /  1141 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12274.73 ms /   255 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_print_timings:       total time =   20178.44 ms /  1396 tokens\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.38 ms /   256 runs   (    0.38 ms per token,  2656.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2795.67 ms /   475 tokens (    5.89 ms per token,   169.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10329.58 ms /   255 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time =   15141.76 ms /   730 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     100.62 ms /   256 runs   (    0.39 ms per token,  2544.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3803.41 ms /   675 tokens (    5.63 ms per token,   177.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11172.34 ms /   255 runs   (   43.81 ms per token,    22.82 tokens per second)\n",
      "llama_print_timings:       total time =   17349.70 ms /   930 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.44 ms /   256 runs   (    0.37 ms per token,  2682.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.44 ms /   102 tokens (   10.70 ms per token,    93.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10377.65 ms /   255 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =   13306.01 ms /   357 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.01 ms /   256 runs   (    0.38 ms per token,  2611.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2216.31 ms /   339 tokens (    6.54 ms per token,   152.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.95 ms /   255 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time =   14915.36 ms /   594 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.84 ms /   256 runs   (    0.37 ms per token,  2727.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6705.47 ms /  1135 tokens (    5.91 ms per token,   169.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12348.84 ms /   255 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_print_timings:       total time =   21346.70 ms /  1390 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.93 ms /   256 runs   (    0.36 ms per token,  2784.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.16 ms /    21 tokens (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11342.38 ms /   255 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =   13420.89 ms /   276 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.77 ms /   256 runs   (    0.37 ms per token,  2673.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2045.47 ms /   312 tokens (    6.56 ms per token,   152.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10282.30 ms /   255 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =   14503.01 ms /   567 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.24 ms /   256 runs   (    0.37 ms per token,  2687.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.51 ms /   126 tokens (    9.78 ms per token,   102.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10434.46 ms /   255 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   13580.80 ms /   381 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.62 ms /   256 runs   (    0.38 ms per token,  2649.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3090.16 ms /   532 tokens (    5.81 ms per token,   172.16 tokens per second)\n",
      "llama_print_timings:        eval time =   10961.92 ms /   255 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time =   16197.66 ms /   787 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.37 ms /   256 runs   (    0.37 ms per token,  2684.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3130.55 ms /   499 tokens (    6.27 ms per token,   159.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11081.93 ms /   255 runs   (   43.46 ms per token,    23.01 tokens per second)\n",
      "llama_print_timings:       total time =   16078.62 ms /   754 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.62 ms /   256 runs   (    0.36 ms per token,  2794.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6788.21 ms /  1140 tokens (    5.95 ms per token,   167.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13215.53 ms /   255 runs   (   51.83 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:       total time =   22167.69 ms /  1395 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.66 ms /   256 runs   (    0.37 ms per token,  2704.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4194.01 ms /   755 tokens (    5.55 ms per token,   180.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10815.14 ms /   255 runs   (   42.41 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time =   17142.82 ms /  1010 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.18 ms /   256 runs   (    0.36 ms per token,  2777.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.26 ms /    17 tokens (   17.66 ms per token,    56.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10225.62 ms /   255 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:       total time =   12617.80 ms /   272 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.29 ms /   256 runs   (    0.38 ms per token,  2631.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3580.47 ms /   626 tokens (    5.72 ms per token,   174.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11114.61 ms /   255 runs   (   43.59 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time =   16748.93 ms /   881 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.04 ms /   256 runs   (    0.38 ms per token,  2611.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3296.59 ms /   561 tokens (    5.88 ms per token,   170.18 tokens per second)\n",
      "llama_print_timings:        eval time =   10963.28 ms /   255 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time =   16008.69 ms /   816 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.23 ms /   256 runs   (    0.36 ms per token,  2775.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6619.25 ms /  1150 tokens (    5.76 ms per token,   173.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12499.23 ms /   255 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:       total time =   21250.52 ms /  1405 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key author not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.71 ms /   256 runs   (    0.37 ms per token,  2731.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5324.20 ms /   833 tokens (    6.39 ms per token,   156.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11141.03 ms /   255 runs   (   43.69 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time =   18666.61 ms /  1088 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      94.33 ms /   256 runs   (    0.37 ms per token,  2713.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.28 ms /   182 tokens (    8.12 ms per token,   123.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10436.93 ms /   255 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =   14053.89 ms /   437 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.10 ms /   256 runs   (    0.37 ms per token,  2691.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3887.67 ms /   693 tokens (    5.61 ms per token,   178.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11248.07 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =   17247.07 ms /   948 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.03 ms /   256 runs   (    0.39 ms per token,  2585.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3429.81 ms /   592 tokens (    5.79 ms per token,   172.60 tokens per second)\n",
      "llama_print_timings:        eval time =   11262.11 ms /   255 runs   (   44.17 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time =   16517.51 ms /   847 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.39 ms /   256 runs   (    0.37 ms per token,  2683.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6517.17 ms /  1141 tokens (    5.71 ms per token,   175.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12217.76 ms /   255 runs   (   47.91 ms per token,    20.87 tokens per second)\n",
      "llama_print_timings:       total time =   20923.93 ms /  1396 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.52 ms /   256 runs   (    0.38 ms per token,  2652.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5715.03 ms /  1077 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11341.91 ms /   255 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =   18903.40 ms /  1332 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.06 ms /   256 runs   (    0.38 ms per token,  2665.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2302.06 ms /   376 tokens (    6.12 ms per token,   163.33 tokens per second)\n",
      "llama_print_timings:        eval time =   10593.03 ms /   255 runs   (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time =   15049.94 ms /   631 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.78 ms /   256 runs   (    0.39 ms per token,  2591.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5084.57 ms /   893 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11521.22 ms /   255 runs   (   45.18 ms per token,    22.13 tokens per second)\n",
      "llama_print_timings:       total time =   18444.57 ms /  1148 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     100.18 ms /   256 runs   (    0.39 ms per token,  2555.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4334.63 ms /   796 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11363.55 ms /   255 runs   (   44.56 ms per token,    22.44 tokens per second)\n",
      "llama_print_timings:       total time =   17588.06 ms /  1051 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      92.54 ms /   256 runs   (    0.36 ms per token,  2766.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6152.75 ms /  1139 tokens (    5.40 ms per token,   185.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.26 ms /   255 runs   (   44.94 ms per token,    22.25 tokens per second)\n",
      "llama_print_timings:       total time =   19472.75 ms /  1394 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.25 ms /   256 runs   (    0.38 ms per token,  2632.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5369.98 ms /  1009 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
      "llama_print_timings:        eval time =   11235.23 ms /   255 runs   (   44.06 ms per token,    22.70 tokens per second)\n",
      "llama_print_timings:       total time =   18567.85 ms /  1264 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      95.09 ms /   256 runs   (    0.37 ms per token,  2692.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     312.93 ms /    21 tokens (   14.90 ms per token,    67.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10110.53 ms /   255 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:       total time =   12564.56 ms /   276 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.86 ms /   256 runs   (    0.38 ms per token,  2642.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    19 tokens (   13.17 ms per token,    75.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10169.40 ms /   255 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =   12071.17 ms /   274 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      98.41 ms /   256 runs   (    0.38 ms per token,  2601.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.37 ms /   698 tokens (    5.59 ms per token,   179.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11054.52 ms /   255 runs   (   43.35 ms per token,    23.07 tokens per second)\n",
      "llama_print_timings:       total time =   16730.74 ms /   953 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.38 ms /   256 runs   (    0.36 ms per token,  2801.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6102.94 ms /  1144 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11839.01 ms /   255 runs   (   46.43 ms per token,    21.54 tokens per second)\n",
      "llama_print_timings:       total time =   19809.89 ms /  1399 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      91.92 ms /   256 runs   (    0.36 ms per token,  2784.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.81 ms /    15 tokens (   18.52 ms per token,    53.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11203.15 ms /   255 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time =   13195.21 ms /   270 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =     101.27 ms /   256 runs   (    0.40 ms per token,  2527.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6151.94 ms /  1157 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11509.76 ms /   255 runs   (   45.14 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time =   19569.51 ms /  1412 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      97.90 ms /   256 runs   (    0.38 ms per token,  2614.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4586.94 ms /   850 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.71 ms /   255 runs   (   44.23 ms per token,    22.61 tokens per second)\n",
      "llama_print_timings:       total time =   17601.13 ms /  1105 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      99.23 ms /   256 runs   (    0.39 ms per token,  2579.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4210.83 ms /   752 tokens (    5.60 ms per token,   178.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.56 ms /   255 runs   (   44.31 ms per token,    22.57 tokens per second)\n",
      "llama_print_timings:       total time =   17371.65 ms /  1007 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.48 ms /   256 runs   (    0.35 ms per token,  2829.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5996.09 ms /  1134 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
      "llama_print_timings:        eval time =   11412.19 ms /   255 runs   (   44.75 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time =   19181.20 ms /  1389 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.21 ms /   256 runs   (    0.35 ms per token,  2837.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.03 ms /    33 tokens (   26.24 ms per token,    38.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11215.21 ms /   255 runs   (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =   13762.14 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      90.80 ms /   256 runs   (    0.35 ms per token,  2819.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     503.99 ms /    33 tokens (   15.27 ms per token,    65.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.44 ms /   255 runs   (   44.27 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time =   13484.53 ms /   288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      89.91 ms /   256 runs   (    0.35 ms per token,  2847.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.50 ms /    25 tokens (   13.22 ms per token,    75.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.84 ms /   255 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time =   13247.35 ms /   280 tokens\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "Metadata key date_end not found in metadata. Setting to None. \n",
      "Metadata fields defined for this instance: ['author', 'id', 'name', 'source', 'tags', 'date_start', 'date_end']\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.82 ms /   256 runs   (    0.38 ms per token,  2644.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4908.47 ms /   921 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11138.02 ms /   255 runs   (   43.68 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time =   17955.49 ms /  1176 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.10 ms /   256 runs   (    0.38 ms per token,  2663.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3071.59 ms /   523 tokens (    5.87 ms per token,   170.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10818.84 ms /   255 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time =   15796.21 ms /   778 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      93.86 ms /   256 runs   (    0.37 ms per token,  2727.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3733.25 ms /   645 tokens (    5.79 ms per token,   172.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11082.98 ms /   255 runs   (   43.46 ms per token,    23.01 tokens per second)\n",
      "llama_print_timings:       total time =   16606.42 ms /   900 tokens\n",
      "/Users/fred/micromamba/envs/my-notion-companion/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    8357.14 ms\n",
      "llama_print_timings:      sample time =      96.75 ms /   256 runs   (    0.38 ms per token,  2645.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.49 ms /   126 tokens (    8.85 ms per token,   113.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10288.98 ms /   255 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
      "llama_print_timings:       total time =   13640.64 ms /   381 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 16s, sys: 3min 26s, total: 29min 43s\n",
      "Wall time: 39min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  SelfQueryAgent(llm, _CONFIGS, _TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475fcf3a-64f8-4f97-91a4-82a620f2e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c453c796-218e-4101-9a43-022aceb8453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/notion_offline.pkl', 'rb') as f:\n",
    "    docs_from_notion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf772e4-7a89-48e3-a346-c8c354ad6099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='师说\\n\\n序\\n我怀疑……我得了甲流。\\n\\n\\n（一）\\n此地有崇山峻岭茂林修竹\\n是能读三坟五典八索九丘\\n\\n我有三本教辅。\\n《高效阅读与写作》、《高中古典诗歌教程》、《高考作文经典材料百变通》。\\n我有三札摘抄。\\n“写得好”“阅”“这是我近来看到的最好的诗。继续写下去，加油！”\\n我记得三句话。\\n“人无权反对他不了解的事物。”\\n“被选择的真实等于谎言。”\\n“人生就是奋斗。”\\n\\n\\n（二）\\n闻姊家有阁子，且何谓阁子也？\\n\\n0.0\\n夏令营时每天都去学术报告厅听课。\\n脑子里一直是奥林匹克、竞赛金牌、优秀的学长和高中的目标。同学们都好强啊…还要洗衣服…今天晚上又没有水果吃……\\n好满、好压抑，人生好失败。\\n然后突然出现这么一个人。他没有谈在七中成长的十点建议。没有讲成为优秀的人的十种习惯。没有说自主学习的重要性、也不教导你做最好的自己。\\n他跟你讲论语。\\n八佾第三。孔子对曰：\\n“君使臣以礼，臣事君以忠。”\\n我知道啊，我知道啊。所以您永远是我们的罗皇。\\n\\n1.0\\n第一次站起来回答问题的时候我坐在8-1。那时我们在讲卞之琳。\\n“你站在桥上看风景，看风景人在楼上看你。”\\n——杨同学，请你来分析一下这首这句话的哲理。\\n血压一下子生得好高。\\n语文老师请我回答问题！他知道我名字！\\n……\\n接下来就是一片空白。因为我压根儿就在开小差。\\n——呃，一个事物在某种条件下可以转化为另一种事物……大概是，这样吧。\\n皇上笑笑让我坐下，所以你这是指A=B于是B=A么？\\n侨妹站起来了。\\n——这是主客体之间的相互转化。\\n感觉自己瞬间就低端了。\\n拜托啊せんせい，您可千万别放弃我。\\n我真的是很崇拜您的呢。\\n\\n2.0\\n新妇初来时，小姑始扶床；今日被驱遣，小姑如我长。\\n原来兰芝只有这么高啊。\\n惟草木之零落兮，恐美人之迟暮。\\n原来有人说屈原是XXX啊。\\n刘少奇被钉在历史的耻辱柱上；\\n没钉稳，结果掉了下来。\\n原来这就是近代史啊。\\n科学家张衡，在史书上是个官员。\\n原来这就是中国啊。\\n“奇穿偶不变，符号看象限。”\\n——原来这就是我们的皇后啊！\\n\\n3.0\\n那一堂课的内容是《杜十娘怒沉百宝箱》。\\n因为无聊和不想睡觉，我们班那个没有脖颈的男生写了一首七绝。\\n因为无聊和挑战自我，我添入了颔联。\\n我又让孟一写了颈联。\\n因为无聊，它成了一首七律：\\n李甲坐监恋十娘，财尽人穷同返乡。\\n千山万水情依依，美人歌赋路长长。\\n姻缘退潮情褪色，贪婪生花欲生香。\\n见利忘情伤尽心，十娘怒沉百宝箱。\\n那时的我们多么文艺啊。当我们在朗读全唐诗研究儒释道或者梦想当一个少年维特的时候，我们并没有被视为异类。我想我再也找不到这么文艺的集体了。\\n那时我的区位优势多么明显啊。我的同桌是链妈，我的后面有邱季和爱唱军歌的铁人。我的前面是小小的青颖和永远都卷舌的正娃。\\n\\n4.0\\n成可心这个二货竟然找我要我的作文。\\n他愣头愣脑地告诉我说，“因为你得了五十二分！”\\n又说，“好多人都看了呢！”\\n我才发现那几张用来写作的草稿纸传到我手上的时候已经是皱巴巴的。\\n那次的作文题目叫做《回家》。体裁自选诗歌除外。这是罗皇头一遭叫我们写模拟卷上的作文题目。\\n“啊-哈，那你们就顺便就把卷子后面的作文写了吧。哦哈。辅导课后交。”\\n52分是什么档次？对于罗皇来说，他觉得是好的文章，给48分。上了50分的，寥寥而已。\\n而我是52分。\\n我记得我描写的回家的其中一种感觉就是“在飞机上望向天穹即将幻灭的晨星和地上盛开的城市灯火时产生的奇妙对称感”。\\n这是罗皇第二次肯定我。\\n罗皇是我的启蒙老师，这话一点不假，虽然我最终还是没能学会熟练掌握“作文材料百变通”和“诗歌鉴赏要义”。\\n但是我也可以说我是文艺的。在我因现实的浓黑而呛住喉咙的时候，唯有他给了我一只桨，教我划水，还鼓励我逆流而上。\\n\\n5.0\\n我走之前曾专门拜访了罗皇一次。\\n他舒服地翘在椅子上，粗短的手指架在一起，说我要多看西方的现代主义文学。\\n之后我每次离家带的行李里面，都会有不同的9本书。\\n而我只是愈加知道了自己的浅薄。\\n我总是计划着，这一生中必须去了解的领域有：文学，音乐，心理，历史，哲学。\\n别处的生活都是自己创造的。在奋斗之外，我们都应该有其他进步的空间。我把这称作真正的生活。\\n\\n6.0\\n听说在高考前的动员会上，罗皇差点把衣服脱了。\\n据说是有同学怂恿说要看皇帝的新衣。然后皇帝就把衣服撩起来露出一排瘦干干的肋骨。', metadata={'date': {'start': '2013-10-26', 'end': '2013-10-26', 'time_zone': None}, 'name': '2013-OCT-26 师说', 'tags': ['日常记趣'], 'id': '273ea76f-a35c-474e-bfe0-41a3daae5c96'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_from_notion['写作'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b28648e-825d-460c-b33e-7d1d8cc07dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = list()\n",
    "for k, v in docs_from_notion.items():\n",
    "    docs.extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ae5791-79c1-4a3e-9c6f-980aa5a1035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe5bfef-7030-4b60-9ad3-009ccedd2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0e3356f-cf1e-492a-acea-b56c38fedf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 7400.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 ms, sys: 14.7 ms, total: 22.4 ms\n",
      "Wall time: 59 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats, score_list = evaluate_retriever(test_cases,  retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4462f7-320f-4bd8-8e1e-97cc1d6a8fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats # doesn't work well with Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8980e3-19c8-432a-8a79-16a4672313be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
