{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2d2109-38df-4a0a-9c4b-36da0e93d356",
   "metadata": {},
   "source": [
    "# Quick & Dirty e2e pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cda038-5245-4158-b294-4d94537d56ac",
   "metadata": {},
   "source": [
    "## Test NotionDB connection\n",
    "ref: https://python.langchain.com/docs/integrations/document_loaders/notiondb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d896a4-9baa-4fa7-961d-7307eb6eeacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15b8721-7393-4b7d-adb4-fa380c0d225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import NotionDBLoader\n",
    "import tomllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cad0dd5-3811-4982-b4fe-c8a184cd8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.tokens.toml', 'rb') as f:\n",
    "    _TOKENS = tomllib.load(f)\n",
    "\n",
    "with open('../.notion_databases.toml', 'rb') as f:\n",
    "    _DATABASES_NOTION = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554c9352-2bec-4bb7-884c-f6c38b1e82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'笔记（非文学）': '7443174d151342458fb7e47acdbb0c64',\n",
       " '读书笔记（文学）': '808e50735cce4c66a151f3e8b79c8d9d',\n",
       " '写作': '8b81c07089344d8d95ddba22bafb8c12',\n",
       " '格言小集': '04d75f24b9544f3f8b220d5e7d87b7c3'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DATABASES_NOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfcbbcb-1739-4065-95b6-57a7fa592e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDBLoader(\n",
    "    integration_token=_TOKENS['notion'],\n",
    "    database_id=_DATABASES_NOTION['格言小集'],\n",
    "    request_timeout_sec=30,  # optional, defaults to 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8775f5-201b-451f-a6fd-89db127a3d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 180 ms, sys: 20.9 ms, total: 201 ms\n",
      "Wall time: 5.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001cc04c-7342-495f-8fd3-1c99ce5716f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='人生四不捡：塔吊下边冰红茶，铁轨上边牛肉干，过山车下八宝粥，课桌后边葡萄干', metadata={'name': '笑死', 'id': '2303056b-72f1-4f9a-b377-cf6b12a0d424'}), Document(page_content='\\n名为太阳的溶剂\\n\\n楼群之中，乌鸦堕落为一种失去预言性的可厌生物\\n\\n对大多数人来说，他们所抱定的观念只是为他们生存方式做辩护的使用说明书而已。\\n\\n颤抖的彩虹其实是光的边角余料。\\n\\n以前的建筑是不透明的甲壳类，现在的建筑是透光的腔肠类。\\n\\n射电望远镜就是宇宙射线的向日葵。\\n\\n电线像静脉一样生长着。\\n\\n绝望的尽头并非对绝望感到绝望，而是对绝望感到厌烦。相对地，希望的尽头也只是对希望的疲倦而已。与一般的见解不同，绝望和希望是生活的激发态。\\n', metadata={'name': '沃滋集朔德', 'id': '340f4781-1042-4534-b286-b758b0ca09a4'})]\n"
     ]
    }
   ],
   "source": [
    "print(docs[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146d6ca-a6a8-4912-a680-f43394265283",
   "metadata": {},
   "source": [
    "## Conversational RAG with memory\n",
    "https://python.langchain.com/docs/expression_language/cookbook/retrieval\n",
    "\n",
    "- llm-aided retrieval\n",
    "- ReAct framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961333f5-7bd4-46e2-8a10-c1f2bb6b6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54f1166-c13b-4129-b049-5f0228477597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=_TOKENS['huggingface'], \n",
    "    # https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2#sentence-transformersparaphrase-multilingual-minilm-l12-v2\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbf9038-b776-4827-919a-bc31a3755670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 313 ms, sys: 46.2 ms, total: 359 ms\n",
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embeddings, \n",
    "    persist_directory='../database/playground_test'\n",
    ")\n",
    "\n",
    "# TODO: use SelfQueryRetriever to allow in metadata context\n",
    "# https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd4f9bcb-db26-4f5b-8cc5-d025db0d78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this uses huggingfacehub to compute\n",
    "# # free but can be very slow\n",
    "# from langchain import HuggingFaceHub\n",
    "\n",
    "# llm = HuggingFaceHub(\n",
    "#     huggingfacehub_api_token=_TOKENS['huggingface'],\n",
    "#     repo_id='01-ai/Yi-6B-Chat', \n",
    "#     # https://huggingface.co/transformers/v4.9.2/main_classes/model.html#transformers.generation_utils.GenerationMixin.generate\n",
    "#     model_kwargs={\"temperature\": 0.1},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69cf7198-347d-416b-a0ca-58483cc2f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use local model\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7831c0-f98e-41a0-9ca2-47ba125f27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "069d1543-710f-4cd0-9f42-dbd890306491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e42a8f2-cebd-419b-8767-b9dba8ae8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd96b7f3-e686-4f14-b1aa-06db1d831f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 ms, sys: 6.06 ms, total: 25.4 ms\n",
      "Wall time: 9.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAh, a curious human! *adjusts glasses* I am a world-class technical documentation writer, here to enlighten you on the intricacies of documenting complex systems in a clear and concise manner. My expertise spans a wide range of industries, from software development to medical devices, and everything in between.\\n\\nAs a technical writer, my job is to create user manuals, guides, and other documentation that help users understand how to use a product or system. I work closely with engineers, designers, and other stakeholders to ensure that the documentation is accurate, up-to-date, and meets the needs of the target audience.\\n\\nMy toolkit includes a variety of technical writing tools, such as MadCap Flare, Adobe FrameMaker, and Confluence. I am well-versed in creating modular, reusable content that can be easily updated and maintained over time. My documentation styles are clean, consistent, and easy to follow, with clear headings, concise language, and intuitive navigation.\\n\\nIn addition to my technical writing skills, I am also proficient in project management and collaboration tools like Jira, Asana, and Trello. I work well under tight deadlines and can handle multiple projects simultaneously while maintaining excellent attention to detail and quality standards.\\n\\nSo, there you have it! That's me in a nutshell – a world-class technical documentation writer with a passion for creating user-friendly content that helps people understand complex systems. *smiling* Feel free to ask me any questions or shoot me a project inquiry anytime!\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm \n",
    "\n",
    "chain.invoke({\"input\": \"who are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7efa1d6f-e88f-47c5-ac91-e531871dc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema import format_document\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt template\n",
    "# https://github.com/langchain-ai/langchain/tree/master/templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d214c68-c6bc-4745-98a7-3c57c239b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bb6667c-af32-4530-9b02-ab23ce854e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"请将以下对话翻译成中文，并将后续问题以原语言改写为一个新的独立的问题。\n",
    "\n",
    "\n",
    "对话记录：\n",
    "{chat_history}\n",
    "后续问题：{question}\n",
    "新的问题：\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "template = \"\"\"请仅仅根据以下资料回答问题。请用中文回答：\n",
    "{context}\n",
    "\n",
    "问：{question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e76af9b-b6f7-42af-b082-de6cbfc04a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "\n",
    "# Now we calculate the standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "\n",
    "# Now we retrieve the documents\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "# And now we put it all together!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33512d9e-729f-4035-89a7-2818060881c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.9 ms, sys: 12.2 ms, total: 67.1 ms\n",
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': \" Based on the quotes you provided, here are some new questions that can be asked:\\n\\n1. How do you think people's personalities are shaped by their experiences and environments?\\n2. What do you think is the most important quality for a person to have in order to achieve their goals?\\n3. In your opinion, what is the key to success in life?\\n4. How do you think people can overcome their fears and insecurities to reach their full potential?\\n5. What do you think is the biggest challenge that people face in their daily lives, and how can they overcome it?\\n6. In your opinion, what is the most difficult thing for a person to change about themselves?\\n7. How do you think people can maintain their motivation and drive to pursue their passions and interests over time?\\n8. What do you think is the biggest source of happiness and fulfillment in life?\\n9. In your opinion, what is the most important thing for a person to learn in order to live a meaningful and fulfilling life?\\n10. How do you think people can make the most of their time and resources to achieve their goals and dreams?\",\n",
       " 'docs': [Document(page_content='勤钳工，懒车工，吊儿郎当做电工。\\n看到贼娃子吃鸡，没看到贼娃子挨打。\\n一等才智知道下一步做什么；二等才智会自律和自习；三等才智会适应一切事情。\\n河水冲倒龙王庙——浪到家了。\\n说你瓜你就瓜，半夜起来扫院坝，别个婆娘你喊妈。\\n人可以不成功，但一定要成才。\\n天下未乱蜀先乱，天下已治蜀后治\\nqiāng金线镶银线，是个胡豆镶边边\\n鼻正口方，牙排翠玉\\n亲为亲，邻为邻，和尚为几个出家人\\n为人不做亏心事，半夜敲门心不惊。不惧虎生三只眼，就怕人起两样心。\\n东恍西恍，吃起不长。\\n老子在外头恍，娃儿在屋头长。\\n婆娘人家的好，娃儿自己的乖。\\n乌龟爬门槛——要栽了！\\n人上一百，形形色色。\\n别人劝得好，自己搁（kō）不平。\\n猴子抱到狗打啵儿，寡骨脸儿对寡骨脸儿。\\n一分钱一分货，稀饭吃了不抵饿。\\n火眼嗝\\n男头女腰\\n上芯子，上釉子。\\npēn（靠）电灯杆杆\\n又不忧又不愁，裤儿拿来做枕头。\\n人不出门身不贵，火不烧山地不肥\\n妻贤夫祸少，子孝父心宽。\\n黄糖饼子白糖糕，个人的码头个人超。\\n剪眉（mí）毛\\n想得童子福，紧怕背老年时。\\n清炖子鸡红烧鱼，天亮的瞌睡、小姨妹儿的嘴。\\n外头绷面子，屋头káo酱子\\n弄死当睡戳，等于掉工作。\\n叫花子还嫌馊稀饭\\n是非只是多开口，挨打皆因强出头。\\n蚊虫遭扇打，只怪嘴伤人。\\n男人三碗面：脸面，情面，台面\\n弹琴伤指甲，说话费精神\\n逢人减寿，遇货添钱\\n会耍不在家豪富\\n风流不在着衣多。\\n小单方能治大病\\n海上方气死名医\\n老狗能记千年事\\n红颜女子多薄命，淑女常伴丑夫眠\\n出门一张帕 洗脸加抹胩\\n露天坝的饭，大家腾到吃\\n官声在离任后，人品在闲谈中\\n君子耍奸不耍赖', metadata={'id': '785ebd75-73ab-4a4a-a772-5b98e3c69ce3', 'name': '李伯伯语录'}),\n",
       "  Document(page_content='勤钳工，懒车工，吊儿郎当做电工。\\n看到贼娃子吃鸡，没看到贼娃子挨打。\\n一等才智知道下一步做什么；二等才智会自律和自习；三等才智会适应一切事情。\\n河水冲倒龙王庙——浪到家了。\\n说你瓜你就瓜，半夜起来扫院坝，别个婆娘你喊妈。\\n人可以不成功，但一定要成才。\\n天下未乱蜀先乱，天下已治蜀后治\\nqiāng金线镶银线，是个胡豆镶边边\\n鼻正口方，牙排翠玉\\n亲为亲，邻为邻，和尚为几个出家人\\n为人不做亏心事，半夜敲门心不惊。不惧虎生三只眼，就怕人起两样心。\\n东恍西恍，吃起不长。\\n老子在外头恍，娃儿在屋头长。\\n婆娘人家的好，娃儿自己的乖。\\n乌龟爬门槛——要栽了！\\n人上一百，形形色色。\\n别人劝得好，自己搁（kō）不平。\\n猴子抱到狗打啵儿，寡骨脸儿对寡骨脸儿。\\n一分钱一分货，稀饭吃了不抵饿。\\n火眼嗝\\n男头女腰\\n上芯子，上釉子。\\npēn（靠）电灯杆杆\\n又不忧又不愁，裤儿拿来做枕头。\\n人不出门身不贵，火不烧山地不肥\\n妻贤夫祸少，子孝父心宽。\\n黄糖饼子白糖糕，个人的码头个人超。\\n剪眉（mí）毛\\n想得童子福，紧怕背老年时。\\n清炖子鸡红烧鱼，天亮的瞌睡、小姨妹儿的嘴。\\n外头绷面子，屋头káo酱子\\n弄死当睡戳，等于掉工作。\\n叫花子还嫌馊稀饭\\n是非只是多开口，挨打皆因强出头。\\n蚊虫遭扇打，只怪嘴伤人。\\n男人三碗面：脸面，情面，台面\\n弹琴伤指甲，说话费精神\\n逢人减寿，遇货添钱\\n会耍不在家豪富\\n风流不在着衣多。\\n小单方能治大病\\n海上方气死名医\\n老狗能记千年事\\n红颜女子多薄命，淑女常伴丑夫眠\\n出门一张帕 洗脸加抹胩\\n露天坝的饭，大家腾到吃\\n官声在离任后，人品在闲谈中\\n君子耍奸不耍赖', metadata={'id': '785ebd75-73ab-4a4a-a772-5b98e3c69ce3', 'name': '李伯伯语录'}),\n",
       "  Document(page_content='勤钳工，懒车工，吊儿郎当做电工。\\n看到贼娃子吃鸡，没看到贼娃子挨打。\\n一等才智知道下一步做什么；二等才智会自律和自习；三等才智会适应一切事情。\\n河水冲倒龙王庙——浪到家了。\\n说你瓜你就瓜，半夜起来扫院坝，别个婆娘你喊妈。\\n人可以不成功，但一定要成才。\\n天下未乱蜀先乱，天下已治蜀后治\\nqiāng金线镶银线，是个胡豆镶边边\\n鼻正口方，牙排翠玉\\n亲为亲，邻为邻，和尚为几个出家人\\n为人不做亏心事，半夜敲门心不惊。不惧虎生三只眼，就怕人起两样心。\\n东恍西恍，吃起不长。\\n老子在外头恍，娃儿在屋头长。\\n婆娘人家的好，娃儿自己的乖。\\n乌龟爬门槛——要栽了！\\n人上一百，形形色色。\\n别人劝得好，自己搁（kō）不平。\\n猴子抱到狗打啵儿，寡骨脸儿对寡骨脸儿。\\n一分钱一分货，稀饭吃了不抵饿。\\n火眼嗝\\n男头女腰\\n上芯子，上釉子。\\npēn（靠）电灯杆杆\\n又不忧又不愁，裤儿拿来做枕头。\\n人不出门身不贵，火不烧山地不肥\\n妻贤夫祸少，子孝父心宽。\\n黄糖饼子白糖糕，个人的码头个人超。\\n剪眉（mí）毛\\n想得童子福，紧怕背老年时。\\n清炖子鸡红烧鱼，天亮的瞌睡、小姨妹儿的嘴。\\n外头绷面子，屋头káo酱子\\n弄死当睡戳，等于掉工作。\\n叫花子还嫌馊稀饭\\n是非只是多开口，挨打皆因强出头。\\n蚊虫遭扇打，只怪嘴伤人。\\n男人三碗面：脸面，情面，台面\\n弹琴伤指甲，说话费精神\\n逢人减寿，遇货添钱\\n会耍不在家豪富\\n风流不在着衣多。\\n小单方能治大病\\n海上方气死名医\\n老狗能记千年事\\n红颜女子多薄命，淑女常伴丑夫眠\\n出门一张帕 洗脸加抹胩\\n露天坝的饭，大家腾到吃\\n官声在离任后，人品在闲谈中\\n君子耍奸不耍赖', metadata={'id': '785ebd75-73ab-4a4a-a772-5b98e3c69ce3', 'name': '李伯伯语录'}),\n",
       "  Document(page_content='赫尔曼·黑塞：那些不适应这个世界的人，其实已经快要找到自我了。 \\n\\n王阳明：持志如心痛\\n\\n曼德拉：我没有失败过，要么赢得胜利，要么学到东西。\\n\\n巴菲特：我担心的不是自己的无知，而是担心自己对知道的东西确信无疑。\\n\\n麻将的哲学：如果你不能在开局之后尽快找到那个菜鸟，那么你就是那个菜鸟。\\n\\nTokyo Ghoul：真相有多锋利，精心编织的谎言就有多细腻。\\n\\n中岛敦《山月记》：因为害怕自己并非明珠而不敢刻苦琢磨，又因为有几分相信自己是明珠，而不能与瓦砾碌碌为伍，遂远离世间，避开人群，结果在内心不断地用愤懑和羞怒饲育着自己懦弱的自尊心。世上每个人都是驯兽师，而那匹猛兽，就是每人各自的性情。对我而言，猛兽就是着自大的羞耻心了。老虎正是它。我折损自己，施苦妻儿，伤害朋友。末了，我就变成了这副与内心一致的模样。如今想起来，我真是空费了自己那仅有的才能，徒然在口头上卖弄着什么“人生一事不为则太长，欲为一事则太短”的警句，可事实是，唯恐暴露才华不足的卑怯的畏惧，和厌恶钻研刻苦的怠惰，这就是我的全部了。但远比我缺乏才华，可由于专念磨砺而成就堂堂诗家的，也颇不乏其人。成为老虎后的今天，我才总算看到了这一点。\\n\\n梵高《亲爱的提奥》：当我画一个太阳，我希望人们感觉它在以惊人的速度旋转，正在发出骇人的光热巨浪。当我画一片麦田，我希望人们感觉到麦子正朝着它们最后的成熟和绽放努力。当我画一棵苹果树，我希望人们能感觉到苹果里面的果汁正把苹果皮撑开，果核中的种子正在为结出果实奋进。当我画一个男人，我就要画出他滔滔的一生。如果生活中不再有某种无限的、深刻的、真实的东西，我将不再眷恋人间。\\n\\n路遥：我认为，每个人都有一个觉醒期，但觉醒的早晚决定个人命运。\\n\\n马克·奥勒留：你的心也许会破碎，但人们却依旧会像从前一样生活。\\n\\n马克·斯特兰德 -《故事》：一个男人凝视他的影子/说那是他自己的灰烬在消散/说他的日子是宇宙中真正的黑洞。/但这都不是真的。\\n\\n埃兹拉·庞德：我知道一个关于分散的奥秘：彼此了解的人在地理上是分散分布的。\\n\\n不是所有人都以自己希望的方式被人所需要。\\n\\n列夫·托尔斯泰：他的堕落甚至没有强烈的欲望作借口，而是由于意志薄弱。\\n\\n杨·马特尔：当你在生活中经历了很多痛苦折磨之后，每一次新的痛苦都既令人无法忍受又让人感到微不足道。\\n\\n海明威：他们喜欢战争的一切，就是不喜欢作战。', metadata={'id': '1b0b9f3a-5c82-4682-abb7-a66fa6854166', 'name': 'Misc.'})]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inputs = {\"question\": '\"勤钳工，懒车工\"后面是什么？'}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066cc25-6c4b-4198-8e85-73793b5ed4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "您是一款人工智能语言模型助手。您的任务是根据以下相关资料找到问题的答案。如果你不知道答案，请问答“我不知道。”\n",
    "\n",
    "资料：{context}\n",
    "\n",
    "问：{query}\n",
    "答：\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
